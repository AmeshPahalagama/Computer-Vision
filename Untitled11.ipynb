{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mh0ZkKtL850c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GirlfriendDataset(Dataset):\n",
        "  def __init__(self,img_dir,transform = None):\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.img_names = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir,f))]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir,self.img_names[idx])\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    label = 1 # Label the image of Nethmi\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0Swv7V20CX2D",
        "outputId": "c2f2398c-2cd7-4f14-9a18-53632bd1484d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-760e28ff-fe8b-4904-8f85-b8a72ca512a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-760e28ff-fe8b-4904-8f85-b8a72ca512a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Nethmi.zip to Nethmi.zip\n",
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "#working with zip files\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Upload the zip file\n",
        "uploaded = files.upload()\n",
        "\n",
        "zip_file_name = \"Nethmi.zip\"\n",
        "output_dir = \"Nethmi\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "# Verify extraction\n",
        "print(\"Extraction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "dvVSrmySPK60",
        "outputId": "e6db164c-f5f9-43e1-f61e-c994966bcc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the directory: ['Nethmi']\n",
            "Files in the subdirectory: ['face4_4226.jpg', 'face4_12518.jpg', 'face3_719.jpg', 'face4_11849.jpg', 'face4_8528.jpg', 'face_190.jpg', 'face4_7466.jpg', 'face4_1266.jpg', 'face4_11015.jpg', 'face4_9805.jpg', 'face4_9852.jpg', 'face4_10089.jpg', 'face4_12945.jpg', 'face4_11108.jpg', 'face4_10931.jpg', 'face4_3731.jpg', 'face4_11758.jpg', 'face4_5372.jpg', 'face_172.jpg', 'face4_6931.jpg', 'face4_2661.jpg', 'face4_2184.jpg', 'face2_656.jpg', 'face4_2320.jpg', 'face3_1624.jpg', 'face4_13071.jpg', 'face4_6441.jpg', 'face4_4725.jpg', 'face4_5731.jpg', 'face4_6014.jpg', 'face4_12274.jpg', 'face4_3798.jpg', 'face4_3539.jpg', 'face4_9003.jpg', 'face4_9653.jpg', 'face4_7850.jpg', 'face3_1052.jpg', 'face4_7474.jpg', 'face4_2929.jpg', 'face4_4764.jpg', 'face4_8116.jpg', 'face4_965.jpg', 'face4_11789.jpg', 'face_66.jpg', 'face4_12179.jpg', 'face4_4483.jpg', 'face4_4949.jpg', 'face4_1998.jpg', 'face4_13023.jpg', 'face4_11730.jpg', 'face4_7583.jpg', 'face4_1027.jpg', 'face4_11901.jpg', 'face4_2884.jpg', 'face4_8618.jpg', 'face4_9978.jpg', 'face3_914.jpg', 'face4_9833.jpg', 'face4_7027.jpg', 'face4_13019.jpg', 'face4_3363.jpg', 'face4_706.jpg', 'face4_12384.jpg', 'face_194.jpg', 'face4_6765.jpg', 'face4_12543.jpg', 'face4_8543.jpg', 'face4_6975.jpg', 'face4_9856.jpg', 'face4_97.jpg', 'face4_315.jpg', 'face4_2051.jpg', 'face4_12530.jpg', 'face4_2001.jpg', 'face4_3250.jpg', 'face3_1260.jpg', 'face4_7617.jpg', 'face4_9468.jpg', 'face4_6358.jpg', 'face4_12779.jpg', 'face4_12942.jpg', 'face4_12388.jpg', 'face4_1720.jpg', 'face4_13602.jpg', 'face4_1311.jpg', 'face4_1258.jpg', 'face4_1886.jpg', 'face2_823.jpg', 'face4_13548.jpg', 'face3_437.jpg', 'face4_715.jpg', 'face4_5385.jpg', 'face4_9842.jpg', 'face4_4354.jpg', 'face4_4776.jpg', 'face3_210.jpg', 'face4_8642.jpg', 'face4_2194.jpg', 'face4_12358.jpg', 'face3_583.jpg', 'face4_3694.jpg', 'face4_2832.jpg', 'face4_1753.jpg', 'face4_11125.jpg', 'face4_6395.jpg', 'face4_10913.jpg', 'face4_11728.jpg', 'face4_3527.jpg', 'face4_3866.jpg', 'face4_937.jpg', 'face4_8667.jpg', 'face4_3023.jpg', 'face4_1107.jpg', 'face4_4082.jpg', 'face4_2163.jpg', 'face4_2656.jpg', 'face4_3354.jpg', 'face4_3735.jpg', 'face4_5210.jpg', 'face4_387.jpg', 'face4_3535.jpg', 'face4_2197.jpg', 'face4_6434.jpg', 'face4_3092.jpg', 'face3_1227.jpg', 'face4_2717.jpg', 'face4_6432.jpg', 'face4_7633.jpg', 'face4_798.jpg', 'face4_8532.jpg', 'face4_2873.jpg', 'face4_2467.jpg', 'face4_8546.jpg', 'face4_1984.jpg', 'face4_13199.jpg', 'face4_2741.jpg', 'face4_7653.jpg', 'face4_1192.jpg', 'face3_783.jpg', 'face4_12844.jpg', 'face4_10541.jpg', 'face4_3415.jpg', 'face4_5058.jpg', 'face4_7852.jpg', 'face4_5940.jpg', 'face4_9980.jpg', 'face4_342.jpg', 'face4_8735.jpg', 'face4_4029.jpg', 'face4_3980.jpg', 'face4_11478.jpg', 'face4_6613.jpg', 'face3_104.jpg', 'face3_396.jpg', 'face4_11952.jpg', 'face4_2928.jpg', 'face4_9630.jpg', 'face4_6523.jpg', 'face4_6573.jpg', 'face4_5233.jpg', 'face4_9995.jpg', 'face4_13192.jpg', 'face4_11202.jpg', 'face4_16.jpg', 'face4_2331.jpg', 'face4_4743.jpg', 'face4_1664.jpg', 'face4_6888.jpg', 'face4_6969.jpg', 'face4_5371.jpg', 'face4_3702.jpg', 'face4_4197.jpg', 'face4_6305.jpg', 'face4_9209.jpg', 'face3_854.jpg', 'face3_887.jpg', 'face4_2298.jpg', 'face4_4317.jpg', 'face4_145.jpg', 'face4_3315.jpg', 'face3_1652.jpg', 'face4_5546.jpg', 'face4_5539.jpg', 'face3_1405.jpg', 'face4_263.jpg', 'face3_827.jpg', 'face4_5361.jpg', 'face4_4703.jpg', 'face4_11329.jpg', 'face4_12145.jpg', 'face3_897.jpg', 'face4_10260.jpg', 'face4_3034.jpg', 'face4_2754.jpg', 'face4_962.jpg', 'face2_838.jpg', 'face4_5010.jpg', 'face4_2706.jpg', 'face4_7778.jpg', 'face4_5212.jpg', 'face_82.jpg', 'face4_2698.jpg', 'face4_3999.jpg', 'face4_3194.jpg', 'face4_7468.jpg', 'face_122.jpg', 'face4_3979.jpg', 'face4_2752.jpg', 'face4_4276.jpg', 'face4_2054.jpg', 'face4_3098.jpg', 'face4_13425.jpg', 'face4_11754.jpg', 'face4_5472.jpg', 'face_99.jpg', 'face3_1152.jpg', 'face4_1104.jpg', 'face4_9590.jpg', 'face3_1121.jpg', 'face4_1862.jpg', 'face3_1233.jpg', 'face4_9788.jpg', 'face4_2772.jpg', 'face4_3939.jpg', 'face2_745.jpg', 'face4_3942.jpg', 'face4_1154.jpg', 'face3_155.jpg', 'face4_7660.jpg', 'face4_10239.jpg', 'face4_2733.jpg', 'face4_2250.jpg', 'face4_2748.jpg', 'face4_7625.jpg', 'face3_16.jpg', 'face4_4962.jpg', 'face4_3985.jpg', 'face4_4065.jpg', 'face4_3252.jpg', 'face2_143.jpg', 'face4_10098.jpg', 'face3_1576.jpg', 'face4_5107.jpg', 'face4_12250.jpg', 'face4_10741.jpg', 'face4_3831.jpg', 'face_36.jpg', 'face4_1788.jpg', 'face4_8021.jpg', 'face4_5310.jpg', 'face3_1412.jpg', 'face4_6936.jpg', 'face4_1757.jpg', 'face4_4021.jpg', 'face4_9778.jpg', 'face4_8612.jpg', 'face3_284.jpg', 'face3_172.jpg', 'face4_2522.jpg', 'face4_10590.jpg', 'face4_2013.jpg', 'face2_55.jpg', 'face4_2166.jpg', 'face4_289.jpg', 'face4_4042.jpg', 'face4_3126.jpg', 'face4_5002.jpg', 'face4_4846.jpg', 'face4_7135.jpg', 'face4_6509.jpg', 'face4_5097.jpg', 'face4_1273.jpg', 'face4_7899.jpg', 'face4_10607.jpg', 'face3_1213.jpg', 'face4_857.jpg', 'face4_3051.jpg', 'face4_10952.jpg', 'face4_6285.jpg', 'face4_11843.jpg', 'face4_7009.jpg', 'face4_28.jpg', 'face4_1764.jpg', 'face4_5045.jpg', 'face4_2797.jpg', 'face4_3785.jpg', 'face4_7359.jpg', 'face4_8752.jpg', 'face4_9288.jpg', 'face4_9215.jpg', 'face4_3170.jpg', 'face4_4304.jpg', 'face4_12705.jpg', 'face4_12994.jpg', 'face4_8327.jpg', 'face4_3086.jpg', 'face4_12565.jpg', 'face4_6288.jpg', 'face_153.jpg', 'face4_3094.jpg', 'face4_6462.jpg', 'face3_111.jpg', 'face4_6131.jpg', 'face4_5378.jpg', 'face4_6569.jpg', 'face4_11387.jpg', 'face_56.jpg', 'face4_7681.jpg', 'face4_11765.jpg', 'face4_12788.jpg', 'face4_6604.jpg', 'face4_12363.jpg', 'face3_1393.jpg', 'face4_5229.jpg', 'face4_3486.jpg', 'face4_11280.jpg', 'face4_2337.jpg', 'face4_1785.jpg', 'face4_2751.jpg', 'face4_10294.jpg', 'face3_1136.jpg', 'face4_3339.jpg', 'face4_7773.jpg', 'face3_601.jpg', 'face4_2939.jpg', 'face4_446.jpg', 'face4_11022.jpg', 'face4_8792.jpg', 'face4_2316.jpg', 'face2_41.jpg', 'face4_4965.jpg', 'face3_1654.jpg', 'face2_13.jpg', 'face2_95.jpg', 'face4_2414.jpg', 'face4_8802.jpg', 'face4_177.jpg', 'face4_1095.jpg', 'face4_3122.jpg', 'face4_12497.jpg', 'face4_12182.jpg', 'face4_1869.jpg', 'face_131.jpg', 'face2_56.jpg', 'face3_1379.jpg', 'face4_7405.jpg', 'face4_8029.jpg', 'face4_8115.jpg', 'face4_12315.jpg', 'face4_12139.jpg', 'face4_8140.jpg', 'face3_604.jpg', 'face4_1248.jpg', 'face4_2630.jpg', 'face4_2239.jpg', 'face4_9296.jpg', 'face4_11177.jpg', 'face4_12729.jpg', 'face4_4328.jpg', 'face4_7436.jpg', 'face4_4224.jpg', 'face_21.jpg', 'face4_9819.jpg', 'face4_303.jpg', 'face_128.jpg', 'face4_2072.jpg', 'face4_12097.jpg', 'face4_5586.jpg', 'face2_682.jpg', 'face4_6343.jpg', 'face4_2677.jpg', 'face4_3031.jpg', 'face4_2431.jpg', 'face4_2553.jpg', 'face4_6553.jpg', 'face4_1643.jpg', 'face4_4043.jpg', 'face3_847.jpg', 'face4_11647.jpg', 'face_205.jpg', 'face4_10905.jpg', 'face4_12254.jpg', 'face4_11650.jpg', 'face4_3243.jpg', 'face4_6878.jpg', 'face4_12154.jpg', 'face4_1581.jpg', 'face4_3424.jpg', 'face4_7422.jpg', 'face4_9814.jpg', 'face4_2629.jpg', 'face4_6102.jpg', 'face4_12958.jpg', 'face4_4074.jpg', 'face4_5308.jpg', 'face3_1191.jpg', 'face4_12521.jpg', 'face4_6123.jpg', 'face4_13038.jpg', 'face4_2837.jpg', 'face4_2712.jpg', 'face3_36.jpg', 'face4_8362.jpg', 'face4_5341.jpg', 'face4_9731.jpg', 'face4_121.jpg', 'face4_7939.jpg', 'face4_2084.jpg', 'face4_11273.jpg', 'face4_12094.jpg', 'face4_13127.jpg', 'face4_13587.jpg', 'face4_4858.jpg', 'face4_12133.jpg', 'face4_11791.jpg', 'face4_8205.jpg', 'face4_5250.jpg', 'face4_7756.jpg', 'face4_8265.jpg', 'face4_5901.jpg', 'face4_312.jpg', 'face4_274.jpg', 'face4_3260.jpg', 'face4_11995.jpg', 'face4_7823.jpg', 'face4_3789.jpg', 'face4_5054.jpg', 'face4_8645.jpg', 'face4_5089.jpg', 'face3_289.jpg', 'face_78.jpg', 'face4_1307.jpg', 'face3_1608.jpg', 'face4_11030.jpg', 'face4_12901.jpg', 'face_106.jpg', 'face4_1790.jpg', 'face4_1888.jpg', 'face4_9895.jpg', 'face4_6105.jpg', 'face4_9831.jpg', 'face4_9519.jpg', 'face4_2481.jpg', 'face4_466.jpg', 'face4_12732.jpg', 'face4_2402.jpg', 'face3_1160.jpg', 'face4_6456.jpg', 'face4_194.jpg', 'face4_2676.jpg', 'face4_7451.jpg', 'face4_4351.jpg', 'face4_5263.jpg', 'face4_4448.jpg', 'face4_2190.jpg', 'face4_3117.jpg', 'face4_5496.jpg', 'face4_6322.jpg', 'face4_3045.jpg', 'face4_9626.jpg', 'face4_2226.jpg', 'face4_3128.jpg', 'face4_9828.jpg', 'face4_5302.jpg', 'face4_10596.jpg', 'face4_4230.jpg', 'face3_272.jpg', 'face4_7629.jpg', 'face4_3687.jpg', 'face4_8211.jpg', 'face3_895.jpg', 'face4_1062.jpg', 'face4_6842.jpg', 'face4_1589.jpg', 'face4_3050.jpg', 'face4_3253.jpg', 'face4_9554.jpg', 'face4_3115.jpg', 'face4_12905.jpg', 'face_208.jpg', 'face4_8176.jpg', 'face4_1000.jpg', 'face4_4420.jpg', 'face4_8135.jpg', 'face4_6520.jpg', 'face3_1185.jpg', 'face3_455.jpg', 'face4_782.jpg', 'face3_384.jpg', 'face4_9460.jpg', 'face4_10229.jpg', 'face4_7398.jpg', 'face4_3186.jpg', 'face4_9210.jpg', 'face4_6404.jpg', 'face4_8018.jpg', 'face2_130.jpg', 'face4_8028.jpg', 'face4_13149.jpg', 'face4_12820.jpg', 'face4_2991.jpg', 'face2_724.jpg', 'face4_8077.jpg', 'face4_1186.jpg', 'face4_5497.jpg', 'face4_2078.jpg', 'face2_43.jpg', 'face_149.jpg', 'face4_208.jpg', 'face4_1246.jpg', 'face4_2672.jpg', 'face4_7007.jpg', 'face4_7930.jpg', 'face_22.jpg', 'face4_9936.jpg', 'face4_1995.jpg', 'face4_3977.jpg', 'face4_9697.jpg', 'face4_7409.jpg', 'face4_10264.jpg', 'face2_694.jpg', 'face4_11672.jpg', 'face4_12319.jpg', 'face4_2756.jpg', 'face4_12893.jpg', 'face4_12953.jpg', 'face4_7376.jpg', 'face4_5697.jpg', 'face4_5681.jpg', 'face_107.jpg', 'face4_4589.jpg', 'face4_6564.jpg', 'face4_13593.jpg', 'face4_8162.jpg', 'face4_135.jpg', 'face_158.jpg', 'face4_7317.jpg', 'face4_4408.jpg', 'face4_5977.jpg', 'face4_3774.jpg', 'face4_6368.jpg', 'face4_11265.jpg', 'face4_11150.jpg', 'face4_4787.jpg', 'face3_1473.jpg', 'face4_12865.jpg', 'face4_6470.jpg', 'face4_8626.jpg', 'face4_4495.jpg', 'face_45.jpg', 'face4_7848.jpg', 'face2_676.jpg', 'face4_4528.jpg', 'face4_5557.jpg', 'face4_11704.jpg', 'face4_5661.jpg', 'face4_12979.jpg', 'face4_12553.jpg', 'face4_8552.jpg', 'face4_1890.jpg', 'face4_5474.jpg', 'face4_6760.jpg', 'face3_715.jpg', 'face4_13083.jpg', 'face4_54.jpg', 'face4_239.jpg', 'face4_9940.jpg', 'face4_6448.jpg', 'face_69.jpg', 'face2_791.jpg', 'face4_2723.jpg', 'face4_7520.jpg', 'face4_2265.jpg', 'face4_5039.jpg', 'face4_4692.jpg', 'face4_9773.jpg', 'face4_1303.jpg', 'face4_4311.jpg', 'face4_6543.jpg', 'face4_499.jpg', 'face4_9832.jpg', 'face4_12151.jpg', 'face3_1600.jpg', 'face_46.jpg', 'face4_1671.jpg', 'face4_6238.jpg', 'face4_13170.jpg', 'face4_9735.jpg', 'face4_5411.jpg', 'face4_6173.jpg', 'face3_415.jpg', 'face4_6156.jpg', 'face4_9458.jpg', 'face4_11121.jpg', 'face4_9687.jpg', 'face4_2201.jpg', 'face4_530.jpg', 'face4_4647.jpg', 'face4_8871.jpg', 'face4_3740.jpg', 'face4_5322.jpg', 'face2_789.jpg', 'face4_4723.jpg', 'face4_2559.jpg', 'face4_6274.jpg', 'face4_13512.jpg', 'face4_5561.jpg', 'face4_2116.jpg', 'face4_8288.jpg', 'face4_9313.jpg', 'face4_6348.jpg', 'face4_9844.jpg', 'face4_5383.jpg', 'face4_12598.jpg', 'face4_11756.jpg', 'face4_887.jpg', 'face4_6501.jpg', 'face_191.jpg', 'face4_5671.jpg', 'face4_7549.jpg', 'face2_118.jpg', 'face4_1901.jpg', 'face4_3130.jpg', 'face4_3189.jpg', 'face4_8080.jpg', 'face4_7363.jpg', 'face4_2679.jpg', 'face_68.jpg', 'face3_1041.jpg', 'face4_11740.jpg', 'face4_3964.jpg', 'face4_8886.jpg', 'face4_10489.jpg', 'face4_10556.jpg', 'face4_9514.jpg', 'face4_1917.jpg', 'face4_12242.jpg', 'face4_7795.jpg', 'face3_1417.jpg', 'face4_5715.jpg', 'face4_8007.jpg', 'face4_5306.jpg', 'face4_2793.jpg', 'face4_3293.jpg', 'face4_4741.jpg', 'face4_13310.jpg', 'face4_2498.jpg', 'face4_6081.jpg', 'face4_1881.jpg', 'face4_953.jpg', 'face4_2695.jpg', 'face4_7351.jpg', 'face4_4302.jpg', 'face4_4348.jpg', 'face4_5335.jpg', 'face4_3689.jpg', 'face4_8685.jpg', 'face4_1239.jpg', 'face4_9448.jpg', 'face4_4030.jpg', 'face4_1270.jpg', 'face3_1224.jpg', 'face4_3708.jpg', 'face4_288.jpg', 'face4_9564.jpg', 'face4_12372.jpg', 'face3_147.jpg', 'face4_10945.jpg', 'face4_2863.jpg', 'face4_10069.jpg', 'face4_8877.jpg', 'face4_7768.jpg', 'face4_4817.jpg', 'face4_13030.jpg', 'face3_807.jpg', 'face4_9470.jpg', 'face4_2136.jpg', 'face4_420.jpg', 'face4_3986.jpg', 'face4_2825.jpg', 'face3_823.jpg', 'face4_8372.jpg', 'face4_6483.jpg', 'face4_9338.jpg', 'face4_4974.jpg', 'face3_911.jpg', 'face2_727.jpg', 'face4_2034.jpg', 'face4_6318.jpg', 'face4_5359.jpg', 'face3_277.jpg', 'face3_590.jpg', 'face4_5648.jpg', 'face4_12811.jpg', 'face4_3338.jpg', 'face4_5459.jpg', 'face4_4251.jpg', 'face3_212.jpg', 'face4_2823.jpg', 'face4_7739.jpg', 'face_175.jpg', 'face4_1701.jpg', 'face4_11801.jpg', 'face3_919.jpg', 'face4_10974.jpg', 'face4_5709.jpg', 'face4_11248.jpg', 'face4_9767.jpg', 'face4_10563.jpg', 'face4_3113.jpg', 'face4_12985.jpg', 'face4_11207.jpg', 'face4_6753.jpg', 'face4_11493.jpg', 'face4_2680.jpg', 'face4_5354.jpg', 'face4_13500.jpg', 'face4_4808.jpg', 'face4_4570.jpg', 'face4_5723.jpg', 'face4_1079.jpg', 'face4_4387.jpg', 'face4_12386.jpg', 'face4_4710.jpg', 'face4_8840.jpg', 'face4_9677.jpg', 'face3_271.jpg', 'face4_13138.jpg', 'face4_7804.jpg', 'face4_12070.jpg', 'face4_12256.jpg', 'face4_9840.jpg', 'face4_7640.jpg', 'face4_5348.jpg', 'face4_7089.jpg', 'face4_13116.jpg', 'face_89.jpg', 'face4_5543.jpg', 'face4_2257.jpg', 'face4_12469.jpg', 'face4_9444.jpg', 'face4_4159.jpg', 'face4_3185.jpg', 'face4_6340.jpg', 'face4_3160.jpg', 'face4_1641.jpg', 'face4_8214.jpg', 'face3_388.jpg', 'face4_4608.jpg', 'face4_5373.jpg', 'face4_6595.jpg', 'face4_10275.jpg', 'face4_5484.jpg', 'face4_2067.jpg', 'face4_5413.jpg', 'face4_13551.jpg', 'face4_4989.jpg', 'face4_10694.jpg', 'face4_9329.jpg', 'face4_8541.jpg', 'face4_2399.jpg', 'face4_12769.jpg', 'face4_3273.jpg', 'face4_493.jpg', 'face4_9771.jpg', 'face3_851.jpg', 'face4_9850.jpg', 'face4_12341.jpg', 'face4_1962.jpg', 'face4_2580.jpg', 'face4_12763.jpg', 'face4_11315.jpg', 'face4_8601.jpg', 'face4_4394.jpg', 'face_42.jpg', 'face4_3461.jpg', 'face4_2940.jpg', 'face4_6597.jpg', 'face3_881.jpg', 'face4_8986.jpg', 'face2_668.jpg', 'face4_7941.jpg', 'face4_2633.jpg', 'face4_885.jpg', 'face4_8173.jpg', 'face4_2596.jpg', 'face3_913.jpg', 'face4_8014.jpg', 'face4_9486.jpg', 'face4_5362.jpg', 'face4_3510.jpg', 'face4_11829.jpg', 'face4_2693.jpg', 'face4_4788.jpg', 'face3_1463.jpg', 'face4_13.jpg', 'face4_4715.jpg', 'face4_11291.jpg', 'face4_11916.jpg', 'face3_1158.jpg', 'face4_5206.jpg', 'face4_7040.jpg', 'face3_849.jpg', 'face3_845.jpg', 'face4_12972.jpg', 'face4_8263.jpg', 'face4_8983.jpg', 'face4_8196.jpg', 'face4_4357.jpg', 'face4_12955.jpg', 'face4_8819.jpg', 'face4_2476.jpg', 'face4_3947.jpg', 'face4_12138.jpg', 'face4_5478.jpg', 'face4_1810.jpg', 'face4_6042.jpg', 'face4_8127.jpg', 'face4_9446.jpg', 'face4_9877.jpg', 'face4_1826.jpg', 'face4_2276.jpg', 'face3_595.jpg', 'face4_12396.jpg', 'face3_1649.jpg', 'face4_5278.jpg', 'face4_3197.jpg', 'face4_9900.jpg', 'face4_9743.jpg', 'face4_10016.jpg', 'face4_3750.jpg', 'face4_12313.jpg', 'face4_13142.jpg', 'face4_13407.jpg', 'face4_6307.jpg', 'face4_9668.jpg', 'face4_9221.jpg', 'face4_9501.jpg', 'face4_2988.jpg', 'face4_2474.jpg', 'face4_7800.jpg', 'face4_3135.jpg', 'face4_2451.jpg', 'face4_2736.jpg', 'face4_11776.jpg', 'face4_5833.jpg', 'face4_4336.jpg', 'face4_3026.jpg', 'face4_6276.jpg', 'face4_3492.jpg', 'face4_10409.jpg', 'face3_426.jpg', 'face4_10434.jpg', 'face4_11667.jpg', 'face4_8184.jpg', 'face4_6879.jpg', 'face4_7914.jpg', 'face3_1201.jpg', 'face4_4994.jpg', 'face4_6443.jpg', 'face4_5218.jpg', 'face4_9601.jpg', 'face4_10895.jpg', 'face4_8572.jpg', 'face4_1165.jpg', 'face4_1630.jpg', 'face4_2347.jpg', 'face4_2872.jpg', 'face4_8589.jpg', 'face3_281.jpg', 'face4_8195.jpg', 'face4_10601.jpg', 'face4_12186.jpg', 'face4_9982.jpg', 'face4_13218.jpg', 'face4_12938.jpg', 'face4_3298.jpg', 'face4_3760.jpg', 'face2_832.jpg', 'face_32.jpg', 'face4_9647.jpg', 'face4_11738.jpg', 'face3_58.jpg', 'face4_2795.jpg', 'face4_3773.jpg', 'face4_9270.jpg', 'face4_8138.jpg', 'face3_1031.jpg', 'face2_29.jpg', 'face4_7962.jpg', 'face4_1264.jpg', 'face3_253.jpg', 'face4_2709.jpg', 'face4_11800.jpg', 'face3_51.jpg', 'face4_10561.jpg', 'face4_2288.jpg', 'face4_9525.jpg', 'face4_12878.jpg', 'face4_6245.jpg', 'face4_7766.jpg', 'face4_13190.jpg', 'face4_10555.jpg', 'face4_2341.jpg', 'face4_1960.jpg', 'face4_125.jpg', 'face4_13280.jpg', 'face4_5083.jpg', 'face4_6468.jpg', 'face4_1880.jpg', 'face4_11088.jpg', 'face4_2690.jpg', 'face4_3103.jpg', 'face4_285.jpg', 'face4_7083.jpg', 'face4_1358.jpg', 'face4_2705.jpg', 'face4_11186.jpg', 'face4_8866.jpg', 'face4_5563.jpg', 'face4_2652.jpg', 'face4_9880.jpg', 'face4_7603.jpg', 'face4_843.jpg', 'face4_8280.jpg', 'face4_5494.jpg', 'face2_733.jpg', 'face4_12703.jpg', 'face4_1899.jpg', 'face4_867.jpg', 'face4_1585.jpg', 'face4_7634.jpg', 'face3_511.jpg', 'face4_1674.jpg', 'face4_6408.jpg', 'face4_6360.jpg', 'face3_4.jpg', 'face4_1135.jpg', 'face4_5574.jpg', 'face4_3143.jpg', 'face4_9692.jpg', 'face4_13013.jpg', 'face4_7068.jpg', 'face4_4761.jpg', 'face4_5855.jpg', 'face_171.jpg', 'face4_8192.jpg', 'face4_9921.jpg', 'face4_4294.jpg', 'face4_8215.jpg', 'face4_4493.jpg', 'face4_3123.jpg', 'face4_237.jpg', 'face4_836.jpg', 'face3_1182.jpg', 'face4_8114.jpg', 'face4_3283.jpg', 'face4_6555.jpg', 'face2_683.jpg', 'face4_4152.jpg', 'face2_681.jpg', 'face4_153.jpg', 'face4_7003.jpg', 'face4_13532.jpg', 'face2_647.jpg', 'face4_11847.jpg', 'face3_598.jpg', 'face4_2344.jpg', 'face4_7649.jpg', 'face3_135.jpg', 'face4_261.jpg', 'face4_7923.jpg', 'face4_8134.jpg', 'face4_11688.jpg', 'face4_5243.jpg', 'face4_2005.jpg', 'face4_6779.jpg', 'face4_4054.jpg', 'face3_610.jpg', 'face4_1848.jpg', 'face2_736.jpg', 'face_203.jpg', 'face4_2685.jpg', 'face4_6087.jpg', 'face4_1174.jpg', 'face4_5086.jpg', 'face4_4286.jpg', 'face4_2923.jpg', 'face4_11388.jpg', 'face4_6608.jpg', 'face4_3793.jpg', 'face4_8665.jpg', 'face4_1667.jpg', 'face4_855.jpg', 'face4_5711.jpg', 'face3_3.jpg', 'face4_4666.jpg', 'face4_3695.jpg', 'face3_411.jpg', 'face4_3082.jpg', 'face4_6419.jpg', 'face4_11809.jpg', 'face4_4244.jpg', 'face4_6170.jpg', 'face4_2472.jpg', 'face4_3429.jpg', 'face4_8229.jpg', 'face4_2978.jpg', 'face4_12992.jpg', 'face4_4116.jpg', 'face4_11.jpg', 'face4_6391.jpg', 'face4_2285.jpg', 'face4_7417.jpg', 'face4_36.jpg', 'face4_8664.jpg', 'face4_362.jpg', 'face4_6032.jpg', 'face4_1612.jpg', 'face4_4801.jpg', 'face4_2556.jpg', 'face4_6324.jpg', 'face4_7807.jpg', 'face4_8201.jpg', 'face4_2279.jpg', 'face3_1498.jpg', 'face4_413.jpg', 'face4_1161.jpg', 'face4_2858.jpg', 'face2_734.jpg', 'face4_256.jpg', 'face4_2686.jpg', 'face2_108.jpg', 'face4_10465.jpg', 'face4_5590.jpg', 'face4_4040.jpg', 'face4_4507.jpg', 'face4_1832.jpg', 'face4_6598.jpg', 'face4_8235.jpg', 'face4_4941.jpg', 'face2_671.jpg', 'face4_12912.jpg', 'face4_230.jpg', 'face4_10877.jpg', 'face4_12251.jpg', 'face3_76.jpg', 'face4_7665.jpg', 'face4_9225.jpg', 'face4_4145.jpg', 'face4_5275.jpg', 'face4_9504.jpg', 'face4_2757.jpg', 'face4_5220.jpg', 'face4_889.jpg', 'face2_755.jpg', 'face4_2691.jpg', 'face4_2244.jpg', 'face4_6909.jpg', 'face4_6964.jpg', 'face4_2087.jpg', 'face4_5388.jpg', 'face4_5458.jpg', 'face4_9671.jpg', 'face4_4022.jpg', 'face4_11662.jpg', 'face2_115.jpg', 'face4_5741.jpg', 'face4_6886.jpg', 'face4_4091.jpg', 'face4_12532.jpg', 'face4_11805.jpg', 'face4_12247.jpg', 'face4_10768.jpg', 'face4_1943.jpg', 'face4_9811.jpg', 'face4_4079.jpg', 'face3_1373.jpg', 'face4_2515.jpg', 'face4_5952.jpg', 'face4_2848.jpg', 'face4_4175.jpg', 'face3_276.jpg', 'face4_5993.jpg', 'face4_2957.jpg', 'face4_11502.jpg', 'face4_2110.jpg', 'face4_4713.jpg', 'face2_697.jpg', 'face4_7872.jpg', 'face4_2791.jpg', 'face4_364.jpg', 'face4_8797.jpg', 'face2_45.jpg', 'face4_12324.jpg', 'face4_2598.jpg', 'face4_2917.jpg', 'face4_12804.jpg', 'face3_572.jpg', 'face4_197.jpg', 'face4_2255.jpg', 'face4_13074.jpg', 'face4_6770.jpg', 'face4_2143.jpg', 'face4_11965.jpg', 'face_39.jpg', 'face4_5326.jpg', 'face4_10618.jpg', 'face4_12932.jpg', 'face4_2404.jpg', 'face4_7915.jpg', 'face4_9485.jpg', 'face4_2944.jpg', 'face4_107.jpg', 'face4_9509.jpg', 'face4_8167.jpg', 'face4_3188.jpg', 'face3_841.jpg', 'face4_2026.jpg', 'face4_10999.jpg', 'face4_6043.jpg', 'face4_4049.jpg', 'face4_473.jpg', 'face4_6381.jpg', 'face4_6854.jpg', 'face4_5923.jpg', 'face4_6383.jpg', 'face4_4118.jpg', 'face3_488.jpg', 'face4_3217.jpg', 'face4_1655.jpg', 'face4_1714.jpg', 'face4_1032.jpg', 'face4_2480.jpg', 'face3_132.jpg', 'face4_9640.jpg', 'face4_2703.jpg', 'face4_6227.jpg', 'face3_824.jpg', 'face4_914.jpg', 'face4_5473.jpg', 'face4_13130.jpg', 'face4_9784.jpg', 'face4_2167.jpg', 'face4_13448.jpg', 'face4_7546.jpg', 'face4_12019.jpg', 'face3_1364.jpg', 'face_64.jpg', 'face4_2147.jpg', 'face4_4577.jpg', 'face3_1592.jpg', 'face4_1908.jpg', 'face4_8118.jpg', 'face3_1056.jpg', 'face4_5125.jpg', 'face4_3949.jpg', 'face4_7117.jpg', 'face4_6118.jpg', 'face4_8681.jpg', 'face4_702.jpg', 'face4_6586.jpg', 'face4_7052.jpg', 'face4_5559.jpg', 'face4_7937.jpg', 'face4_2091.jpg', 'face4_4192.jpg', 'face4_1295.jpg', 'face4_6875.jpg', 'face4_12824.jpg', 'face_48.jpg', 'face4_13572.jpg', 'face4_3822.jpg', 'face4_10967.jpg', 'face4_7909.jpg', 'face4_9660.jpg', 'face3_729.jpg', 'face4_3447.jpg', 'face4_5475.jpg', 'face4_8592.jpg', 'face4_5099.jpg', 'face4_1705.jpg', 'face4_2216.jpg', 'face4_3685.jpg', 'face4_4700.jpg', 'face4_13214.jpg', 'face4_62.jpg', 'face4_12563.jpg', 'face4_11945.jpg', 'face4_7607.jpg', 'face4_4381.jpg', 'face4_3199.jpg', 'face3_282.jpg', 'face4_2839.jpg', 'face4_6345.jpg', 'face4_160.jpg', 'face4_8194.jpg', 'face4_13010.jpg', 'face4_5314.jpg', 'face3_1341.jpg', 'face4_328.jpg', 'face4_1895.jpg', 'face4_4848.jpg', 'face4_747.jpg', 'face4_3845.jpg', 'face4_1340.jpg', 'face4_2040.jpg', 'face4_1331.jpg', 'face4_1777.jpg', 'face4_12112.jpg', 'face4_7820.jpg', 'face4_12869.jpg', 'face4_5100.jpg', 'face4_10084.jpg', 'face4_7309.jpg', 'face4_6186.jpg', 'face2_49.jpg', 'face4_6146.jpg', 'face4_12717.jpg', 'face4_3206.jpg', 'face4_6883.jpg', 'face4_9516.jpg', 'face4_2799.jpg', 'face4_1927.jpg', 'face4_6353.jpg', 'face2_653.jpg', 'face4_1679.jpg', 'face4_2715.jpg', 'face4_8226.jpg', 'face3_795.jpg', 'face4_252.jpg', 'face3_1054.jpg', 'face4_8020.jpg', 'face4_12974.jpg', 'face3_1445.jpg', 'face4_7349.jpg', 'face4_10274.jpg', 'face4_13068.jpg', 'face4_7029.jpg', 'face4_8169.jpg', 'face_60.jpg', 'face4_12506.jpg', 'face4_7592.jpg', 'face4_4161.jpg', 'face4_5027.jpg', 'face4_8863.jpg', 'face_70.jpg', 'face4_13180.jpg', 'face4_4640.jpg', 'face2_123.jpg', 'face4_6839.jpg', 'face4_2716.jpg', 'face4_1980.jpg', 'face_108.jpg', 'face4_12463.jpg', 'face4_9503.jpg', 'face4_8879.jpg', 'face4_12577.jpg', 'face4_1773.jpg', 'face4_9727.jpg', 'face4_4187.jpg', 'face4_13600.jpg', 'face4_11005.jpg', 'face4_7657.jpg', 'face4_6940.jpg', 'face2_830.jpg', 'face4_4385.jpg', 'face4_2617.jpg', 'face4_2621.jpg', 'face4_11941.jpg', 'face4_12382.jpg', 'face4_7742.jpg', 'face4_11978.jpg', 'face4_7322.jpg', 'face4_13492.jpg', 'face4_4126.jpg', 'face4_8019.jpg', 'face4_1015.jpg', 'face2_737.jpg', 'face4_11676.jpg', 'face4_4636.jpg', 'face4_13007.jpg', 'face2_22.jpg', 'face4_12536.jpg', 'face2_718.jpg', 'face4_2119.jpg', 'face4_672.jpg', 'face4_324.jpg', 'face4_5337.jpg', 'face4_5112.jpg', 'face4_11268.jpg', 'face4_8820.jpg', 'face4_4652.jpg', 'face4_6076.jpg', 'face4_7370.jpg', 'face3_421.jpg', 'face_91.jpg', 'face4_5404.jpg', 'face4_691.jpg', 'face4_757.jpg', 'face4_7797.jpg', 'face4_9944.jpg', 'face4_3015.jpg', 'face4_8285.jpg', 'face4_1596.jpg', 'face4_6857.jpg', 'face4_8617.jpg', 'face4_9679.jpg', 'face3_1033.jpg', 'face2_708.jpg', 'face4_2694.jpg', 'face4_11645.jpg', 'face4_3715.jpg', 'face4_916.jpg', 'face4_435.jpg', 'face4_5488.jpg', 'face4_1313.jpg', 'face4_10825.jpg', 'face4_2291.jpg', 'face4_12589.jpg', 'face4_40.jpg', 'face_129.jpg', 'face3_106.jpg', 'face3_297.jpg', 'face4_5345.jpg', 'face3_1660.jpg', 'face4_3116.jpg', 'face4_12047.jpg', 'face3_916.jpg', 'face4_3870.jpg', 'face4_7670.jpg', 'face4_5184.jpg', 'face4_8590.jpg', 'face4_1352.jpg', 'face4_7815.jpg', 'face4_2608.jpg', 'face4_8120.jpg', 'face3_296.jpg', 'face4_7966.jpg', 'face4_8683.jpg', 'face4_5469.jpg', 'face4_3445.jpg', 'face4_1613.jpg', 'face4_7902.jpg', 'face4_2770.jpg', 'face4_8582.jpg', 'face2_820.jpg', 'face4_8224.jpg', 'face4_12347.jpg', 'face4_1882.jpg', 'face4_8804.jpg', 'face3_64.jpg', 'face4_7533.jpg', 'face4_7855.jpg', 'face4_4319.jpg', 'face4_7913.jpg', 'face4_750.jpg', 'face4_8638.jpg', 'face4_10577.jpg', 'face4_1051.jpg', 'face2_859.jpg', 'face4_4873.jpg', 'face4_6269.jpg', 'face4_2047.jpg', 'face4_815.jpg', 'face4_13211.jpg', 'face4_2789.jpg', 'face4_1626.jpg', 'face4_12041.jpg', 'face4_2883.jpg', 'face4_12091.jpg', 'face3_468.jpg', 'face4_5565.jpg', 'face4_217.jpg', 'face3_1187.jpg', 'face4_5937.jpg', 'face4_6563.jpg', 'face4_5480.jpg', 'face4_6078.jpg', 'face4_9846.jpg', 'face4_6161.jpg', 'face4_2449.jpg', 'face4_4219.jpg', 'face4_6838.jpg', 'face4_3838.jpg', 'face4_11831.jpg', 'face4_12369.jpg', 'face4_3157.jpg', 'face4_1669.jpg', 'face3_197.jpg', 'face4_4729.jpg', 'face4_2540.jpg', 'face4_7495.jpg', 'face4_3063.jpg', 'face3_1432.jpg', 'face4_3954.jpg', 'face4_3133.jpg', 'face_193.jpg', 'face4_892.jpg', 'face4_5910.jpg', 'face4_9918.jpg', 'face4_12922.jpg', 'face4_5227.jpg', 'face4_5248.jpg', 'face4_4515.jpg', 'face4_8156.jpg', 'face2_835.jpg', 'face4_8145.jpg', 'face4_5117.jpg', 'face4_2969.jpg', 'face4_9636.jpg', 'face4_1915.jpg', 'face_38.jpg', 'face4_3235.jpg', 'face3_293.jpg', 'face3_599.jpg', 'face4_6030.jpg', 'face4_8687.jpg', 'face4_7445.jpg', 'face4_2037.jpg', 'face4_2828.jpg', 'face4_4504.jpg', 'face4_6220.jpg', 'face4_12988.jpg', 'face_73.jpg', 'face3_100.jpg', 'face4_8569.jpg', 'face4_12777.jpg', 'face2_768.jpg', 'face4_5349.jpg', 'face4_11233.jpg', 'face4_96.jpg', 'face4_2358.jpg', 'face4_4171.jpg', 'face4_1024.jpg', 'face4_712.jpg', 'face4_10584.jpg', 'face4_429.jpg', 'face4_7638.jpg', 'face4_898.jpg', 'face_135.jpg', 'face_67.jpg', 'face4_9541.jpg', 'face4_1770.jpg', 'face4_4573.jpg', 'face4_3138.jpg', 'face4_2392.jpg', 'face3_1584.jpg', 'face4_12492.jpg', 'face4_13153.jpg', 'face4_2455.jpg', 'face4_1305.jpg', 'face4_1752.jpg', 'face4_8231.jpg', 'face4_1768.jpg', 'face4_9905.jpg', 'face4_13004.jpg', 'face4_7946.jpg', 'face4_1124.jpg', 'face4_1813.jpg', 'face_169.jpg', 'face_187.jpg', 'face4_11474.jpg', 'face4_12467.jpg', 'face4_3474.jpg', 'face4_6092.jpg', 'face4_12141.jpg', 'face4_3765.jpg', 'face4_12710.jpg', 'face4_6053.jpg', 'face4_13507.jpg', 'face3_406.jpg', 'face4_1069.jpg', 'face4_5332.jpg', 'face4_131.jpg', 'face_52.jpg', 'face_81.jpg', 'face4_6446.jpg', 'face4_13527.jpg', 'face4_6374.jpg', 'face4_6314.jpg', 'face4_1762.jpg', 'face4_5358.jpg', 'face3_1032.jpg', 'face3_399.jpg', 'face3_834.jpg', 'face4_12334.jpg', 'face4_2852.jpg', 'face4_9583.jpg', 'face4_6536.jpg', 'face4_9599.jpg', 'face_44.jpg', 'face3_402.jpg', 'face4_7863.jpg', 'face4_9863.jpg', 'face4_4410.jpg', 'face4_6451.jpg', 'face3_871.jpg', 'face2_11.jpg', 'face4_9298.jpg', 'face4_12282.jpg', 'face4_1092.jpg', 'face4_11948.jpg', 'face4_2636.jpg', 'face3_285.jpg', 'face4_7514.jpg', 'face4_4166.jpg', 'face4_13077.jpg', 'face4_4734.jpg', 'face2_723.jpg', 'face4_10881.jpg', 'face4_3705.jpg', 'face4_5340.jpg', 'face4_12284.jpg', 'face4_1903.jpg', 'face4_6428.jpg', 'face4_13089.jpg', 'face4_7428.jpg', 'face4_254.jpg', 'face3_168.jpg', 'face4_2100.jpg', 'face2_808.jpg', 'face4_4138.jpg', 'face4_24.jpg', 'face4_4262.jpg', 'face4_4203.jpg', 'face4_9708.jpg', 'face2_742.jpg', 'face3_1290.jpg', 'face4_6505.jpg', 'face4_8578.jpg', 'face4_5012.jpg', 'face4_5194.jpg', 'face4_5281.jpg', 'face4_7589.jpg', 'face4_5204.jpg', 'face4_66.jpg', 'face_100.jpg', 'face4_12332.jpg', 'face4_5608.jpg', 'face4_2235.jpg', 'face4_8292.jpg', 'face4_4519.jpg', 'face4_1867.jpg', 'face4_3428.jpg', 'face4_12747.jpg', 'face4_2899.jpg', 'face4_12197.jpg', 'face4_7973.jpg', 'face4_1937.jpg', 'face4_1628.jpg', 'face3_1042.jpg', 'face4_3090.jpg', 'face4_406.jpg', 'face4_12960.jpg', 'face4_11231.jpg', 'face4_8684.jpg', 'face4_1732.jpg', 'face4_8142.jpg', 'face4_7430.jpg', 'face2_105.jpg', 'face4_10277.jpg', 'face4_2651.jpg', 'face4_11721.jpg', 'face4_6776.jpg', 'face4_5695.jpg', 'face4_11648.jpg', 'face4_4698.jpg', 'face3_232.jpg', 'face4_991.jpg', 'face4_9560.jpg', 'face4_3958.jpg', 'face4_12193.jpg', 'face4_5021.jpg', 'face4_2173.jpg', 'face4_2865.jpg', 'face4_4925.jpg', 'face4_13046.jpg', 'face3_1547.jpg', 'face4_13394.jpg', 'face4_11675.jpg', 'face4_6439.jpg', 'face4_10551.jpg', 'face4_10595.jpg', 'face4_3700.jpg', 'face4_11325.jpg', 'face4_1074.jpg', 'face3_1519.jpg', 'face4_7940.jpg', 'face4_6614.jpg', 'face4_780.jpg', 'face4_185.jpg', 'face4_12968.jpg', 'face4_542.jpg', 'face2_31.jpg', 'face4_4529.jpg', 'face3_504.jpg', 'face4_5082.jpg', 'face4_8233.jpg', 'face4_8733.jpg', 'face4_8678.jpg', 'face4_6316.jpg', 'face4_5549.jpg', 'face4_12487.jpg', 'face_182.jpg', 'face4_12065.jpg', 'face4_5859.jpg', 'face4_3743.jpg', 'face4_5285.jpg', 'face4_4404.jpg', 'face4_11711.jpg', 'face4_8146.jpg', 'face4_4155.jpg', 'face4_6611.jpg', 'face4_8982.jpg', 'face4_13201.jpg', 'face4_3681.jpg', 'face4_2887.jpg', 'face4_486.jpg', 'face4_3064.jpg', 'face4_4649.jpg', 'face_126.jpg', 'face4_6098.jpg', 'face4_5005.jpg', 'face4_12088.jpg', 'face4_9643.jpg', 'face4_2668.jpg', 'face3_1131.jpg', 'face4_812.jpg', 'face4_8318.jpg', 'face4_6070.jpg', 'face4_5998.jpg', 'face4_6310.jpg', 'face4_4954.jpg', 'face4_7727.jpg', 'face4_2175.jpg', 'face4_2457.jpg', 'face4_4603.jpg', 'face3_870.jpg', 'face4_12858.jpg', 'face4_9324.jpg', 'face4_3193.jpg', 'face4_3452.jpg', 'face4_10767.jpg', 'face4_11286.jpg', 'face4_11673.jpg', 'face4_7147.jpg', 'face4_10613.jpg', 'face4_3692.jpg', 'face4_2139.jpg', 'face_51.jpg', 'face4_3834.jpg', 'face4_12715.jpg', 'face4_5355.jpg', 'face4_8550.jpg', 'face4_8587.jpg', 'face4_2895.jpg', 'face4_13054.jpg', 'face4_453.jpg', 'face3_1544.jpg', 'face4_13065.jpg', 'face4_8575.jpg', 'face4_2876.jpg', 'face4_805.jpg', 'face4_7598.jpg', 'face4_9529.jpg', 'face4_5719.jpg', 'face3_171.jpg', 'face4_2022.jpg', 'face4_1343.jpg', 'face4_9818.jpg', 'face4_1747.jpg', 'face4_5064.jpg', 'face4_2247.jpg', 'face_72.jpg', 'face3_1141.jpg', 'face4_9335.jpg', 'face4_9456.jpg', 'face4_2182.jpg', 'face4_10460.jpg', 'face4_6066.jpg', 'face_19.jpg', 'face4_4621.jpg', 'face4_2611.jpg', 'face4_2510.jpg', 'face4_2936.jpg', 'face4_12377.jpg', 'face4_12306.jpg', 'face4_13162.jpg', 'face4_4001.jpg', 'face4_809.jpg', 'face_202.jpg', 'face4_6150.jpg', 'face4_9705.jpg', 'face4_8888.jpg', 'face4_8243.jpg', 'face4_8649.jpg', 'face4_2395.jpg', 'face4_2410.jpg', 'face_165.jpg', 'face4_2600.jpg', 'face4_5745.jpg', 'face4_3435.jpg', 'face4_6481.jpg', 'face2_827.jpg', 'face4_8992.jpg', 'face4_1003.jpg', 'face4_13168.jpg', 'face4_3101.jpg', 'face4_7753.jpg', 'face4_6413.jpg', 'face2_686.jpg', 'face4_7810.jpg', 'face3_1049.jpg', 'face4_6605.jpg', 'face4_7542.jpg', 'face4_9483.jpg', 'face4_7021.jpg', 'face4_1879.jpg', 'face4_9761.jpg', 'face4_3852.jpg', 'face4_1893.jpg', 'face4_11786.jpg', 'face4_1921.jpg', 'face4_5186.jpg', 'face4_11690.jpg', 'face4_3432.jpg', 'face4_12846.jpg', 'face3_228.jpg', 'face4_5963.jpg', 'face4_10910.jpg', 'face4_3008.jpg', 'face_105.jpg', 'face3_381.jpg', 'face2_731.jpg', 'face4_8623.jpg', 'face4_2024.jpg', 'face4_4981.jpg', 'face3_930.jpg', 'face4_8884.jpg', 'face4_1170.jpg', 'face4_676.jpg', 'face4_12452.jpg', 'face4_9625.jpg', 'face4_4057.jpg', 'face4_10067.jpg', 'face_119.jpg', 'face4_3289.jpg', 'face_139.jpg', 'face4_6491.jpg', 'face4_2816.jpg', 'face4_8816.jpg', 'face4_1855.jpg', 'face4_2468.jpg', 'face4_1707.jpg', 'face_101.jpg', 'face3_812.jpg', 'face4_9279.jpg', 'face4_2664.jpg', 'face4_5960.jpg', 'face2_805.jpg', 'face4_6514.jpg', 'face3_390.jpg', 'face4_6877.jpg', 'face4_8197.jpg', 'face4_5389.jpg', 'face3_862.jpg', 'face4_12361.jpg', 'face4_2537.jpg', 'face4_4140.jpg', 'face2_738.jpg', 'face4_11063.jpg', 'face4_4814.jpg', 'face4_6459.jpg', 'face4_2777.jpg', 'face4_11112.jpg', 'face4_1337.jpg', 'face4_895.jpg', 'face4_7150.jpg', 'face4_8133.jpg', 'face4_4423.jpg', 'face4_11221.jpg', 'face4_6579.jpg', 'face4_11929.jpg', 'face4_12808.jpg', 'face4_4168.jpg', 'face4_7942.jpg', 'face4_1177.jpg', 'face4_2199.jpg', 'face4_8129.jpg', 'face4_3994.jpg', 'face4_13341.jpg', 'face3_594.jpg', 'face4_5008.jpg', 'face4_10546.jpg', 'face4_2261.jpg', 'face4_6829.jpg', 'face4_6389.jpg', 'face4_4009.jpg', 'face4_6376.jpg', 'face4_1953.jpg', 'face4_2232.jpg', 'face4_5110.jpg', 'face4_4694.jpg', 'face4_12126.jpg', 'face4_941.jpg', 'face4_4527.jpg', 'face2_826.jpg', 'face4_2483.jpg', 'face4_2732.jpg', 'face4_4883.jpg', 'face4_12919.jpg', 'face4_5537.jpg', 'face4_10958.jpg', 'face2_51.jpg', 'face4_4727.jpg', 'face4_13417.jpg', 'face_152.jpg', 'face4_8661.jpg', 'face4_8753.jpg', 'face4_5615.jpg', 'face4_846.jpg', 'face3_1622.jpg', 'face4_9796.jpg', 'face4_4593.jpg', 'face4_6121.jpg', 'face4_4417.jpg', 'face4_3891.jpg', 'face4_10545.jpg', 'face4_9205.jpg', 'face4_2909.jpg', 'face3_476.jpg', 'face4_10092.jpg', 'face4_1085.jpg', 'face4_5180.jpg', 'face3_826.jpg', 'face4_761.jpg', 'face4_3368.jpg', 'face4_319.jpg', 'face4_5367.jpg', 'face4_11484.jpg', 'face2_740.jpg', 'face4_9056.jpg', 'face4_4785.jpg', 'face4_13113.jpg', 'face4_2714.jpg', 'face4_9618.jpg', 'face4_5611.jpg', 'face4_12753.jpg', 'face2_783.jpg', 'face4_3781.jpg', 'face_34.jpg', 'face4_10238.jpg', 'face4_6096.jpg', 'face2_691.jpg', 'face4_2875.jpg', 'face4_1940.jpg', 'face4_4951.jpg', 'face3_917.jpg', 'face4_9662.jpg', 'face_47.jpg', 'face4_698.jpg', 'face4_3305.jpg', 'face4_1846.jpg', 'face4_7733.jpg', 'face4_6059.jpg', 'face4_10006.jpg', 'face4_8092.jpg', 'face4_5729.jpg', 'face4_12261.jpg', 'face4_2128.jpg', 'face4_8749.jpg', 'face4_2493.jpg', 'face4_4517.jpg', 'face4_111.jpg', 'face4_2387.jpg', 'face4_11649.jpg', 'face4_4626.jpg', 'face3_1651.jpg', 'face4_939.jpg', 'face4_2107.jpg', 'face4_7035.jpg', 'face4_12277.jpg', 'face4_849.jpg', 'face4_5735.jpg', 'face4_12120.jpg', 'face4_2470.jpg', 'face4_9829.jpg', 'face4_1665.jpg', 'face4_8535.jpg', 'face4_11693.jpg', 'face4_5572.jpg', 'face4_9482.jpg', 'face4_47.jpg', 'face4_2640.jpg', 'face4_7938.jpg', 'face4_945.jpg', 'face3_1453.jpg', 'face4_3521.jpg', 'face4_6055.jpg', 'face4_13414.jpg', 'face4_10226.jpg', 'face4_3494.jpg', 'face4_3422.jpg', 'face4_7024.jpg', 'face4_12886.jpg', 'face4_5265.jpg', 'face4_5069.jpg', 'face4_738.jpg', 'face4_6166.jpg', 'face4_13219.jpg', 'face3_1045.jpg', 'face4_7539.jpg', 'face4_6466.jpg', 'face4_5197.jpg', 'face4_5926.jpg', 'face4_1591.jpg', 'face4_6546.jpg', 'face4_3053.jpg', 'face3_144.jpg', 'face4_3698.jpg', 'face4_6517.jpg', 'face4_9185.jpg', 'face4_13123.jpg', 'face4_2368.jpg', 'face4_12510.jpg', 'face3_392.jpg', 'face4_11762.jpg', 'face2_786.jpg', 'face4_2810.jpg', 'face_146.jpg', 'face3_42.jpg', 'face4_8555.jpg', 'face4_2169.jpg', 'face4_3310.jpg', 'face4_10995.jpg', 'face4_2590.jpg', 'face3_1208.jpg', 'face4_3426.jpg', 'face_93.jpg', 'face4_3153.jpg', 'face4_2133.jpg', 'face3_1161.jpg', 'face3_1605.jpg', 'face4_4347.jpg', 'face4_1657.jpg', 'face3_790.jpg', 'face4_12568.jpg', 'face4_3489.jpg', 'face4_3332.jpg', 'face4_9597.jpg', 'face4_9551.jpg', 'face4_818.jpg', 'face4_357.jpg', 'face4_6606.jpg', 'face4_13144.jpg', 'face4_12338.jpg', 'face4_12786.jpg', 'face4_9488.jpg', 'face4_13595.jpg', 'face4_3683.jpg', 'face4_6022.jpg', 'face4_7730.jpg', 'face4_7783.jpg', 'face4_5479.jpg', 'face4_2491.jpg', 'face4_12790.jpg', 'face4_13216.jpg', 'face4_5192.jpg', 'face4_10552.jpg', 'face4_1242.jpg', 'face4_10068.jpg', 'face4_2350.jpg', 'face4_3972.jpg', 'face4_3900.jpg', 'face4_13205.jpg', 'face2_125.jpg', 'face4_3359.jpg', 'face4_4241.jpg', 'face4_4867.jpg', 'face_162.jpg', 'face4_11481.jpg', 'face4_8242.jpg', 'face4_10070.jpg', 'face4_5687.jpg', 'face4_9358.jpg', 'face4_7696.jpg', 'face4_8186.jpg', 'face4_3073.jpg', 'face4_3169.jpg', 'face_132.jpg', 'face_65.jpg', 'face4_9721.jpg', 'face4_11970.jpg', 'face4_5256.jpg', 'face4_11991.jpg', 'face4_2.jpg', 'face4_7076.jpg', 'face4_11321.jpg', 'face4_10567.jpg', 'face4_12965.jpg', 'face4_4236.jpg', 'face4_4998.jpg', 'face4_12345.jpg', 'face4_2658.jpg', 'face4_4414.jpg', 'face3_67.jpg', 'face3_1271.jpg', 'face4_6085.jpg', 'face3_1237.jpg', 'face4_12990.jpg', 'face3_1139.jpg', 'face4_919.jpg', 'face4_6341.jpg', 'face4_3828.jpg', 'face4_1815.jpg', 'face3_1653.jpg', 'face4_2870.jpg', 'face4_271.jpg', 'face4_3285.jpg', 'face4_9724.jpg', 'face4_12560.jpg', 'face4_7668.jpg', 'face3_889.jpg', 'face4_6535.jpg', 'face4_10553.jpg', 'face4_9303.jpg', 'face4_8845.jpg', 'face4_1336.jpg', 'face2_142.jpg', 'face3_1159.jpg', 'face3_291.jpg', 'face4_8221.jpg', 'face4_7424.jpg', 'face4_7034.jpg', 'face4_4130.jpg', 'face4_1807.jpg', 'face4_501.jpg', 'face4_9628.jpg', 'face4_1830.jpg', 'face4_9689.jpg', 'face_160.jpg', 'face4_5618.jpg', 'face4_720.jpg', 'face4_7313.jpg', 'face4_8174.jpg', 'face4_678.jpg', 'face3_883.jpg', 'face4_8124.jpg', 'face4_11236.jpg', 'face4_8286.jpg', 'face4_3132.jpg', 'face4_9502.jpg', 'face4_1800.jpg', 'face4_2587.jpg', 'face3_121.jpg', 'face4_8136.jpg', 'face4_12435.jpg', 'face4_5476.jpg', 'face4_13043.jpg', 'face4_4489.jpg', 'face3_269.jpg', 'face4_7878.jpg', 'face4_12076.jpg', 'face4_12169.jpg', 'face4_10548.jpg', 'face4_10917.jpg', 'face4_12735.jpg', 'face4_5381.jpg', 'face4_8038.jpg', 'face3_201.jpg', 'face4_4272.jpg', 'face4_3024.jpg', 'face4_12981.jpg', 'face4_3690.jpg', 'face4_5482.jpg', 'face4_2688.jpg', 'face4_2787.jpg', 'face4_9475.jpg', 'face4_6915.jpg', 'face3_547.jpg', 'face3_215.jpg', 'face4_4669.jpg', 'face4_6911.jpg', 'face4_7498.jpg', 'face3_479.jpg', 'face4_6164.jpg', 'face4_3430.jpg', 'face4_7472.jpg', 'face4_8016.jpg', 'face4_6387.jpg', 'face4_3308.jpg', 'face4_12842.jpg', 'face4_830.jpg', 'face3_273.jpg', 'face4_7395.jpg', 'face4_2574.jpg', 'face3_1154.jpg', 'face4_9533.jpg', 'face4_1793.jpg', 'face4_1298.jpg', 'face4_2542.jpg', 'face4_4185.jpg', 'face4_2727.jpg', 'face4_6072.jpg', 'face4_2365.jpg', 'face4_12035.jpg', 'face4_3228.jpg', 'face3_1302.jpg', 'face4_3975.jpg', 'face3_418.jpg', 'face4_8595.jpg', 'face4_2561.jpg', 'face4_4036.jpg', 'face4_2371.jpg', 'face4_4615.jpg', 'face4_3093.jpg', 'face4_12317.jpg', 'face4_4685.jpg', 'face4_2447.jpg', 'face4_6397.jpg', 'face4_997.jpg', 'face4_1871.jpg', 'face4_1041.jpg', 'face4_5093.jpg', 'face3_387.jpg', 'face4_1683.jpg', 'face4_8152.jpg', 'face4_4071.jpg', 'face2_36.jpg', 'face4_9607.jpg', 'face4_200.jpg', 'face4_12999.jpg', 'face4_11934.jpg', 'face4_1892.jpg', 'face4_8593.jpg', 'face4_13062.jpg', 'face2_127.jpg', 'face4_12812.jpg', 'face4_5461.jpg', 'face4_4308.jpg', 'face4_5018.jpg', 'face3_1437.jpg', 'face4_10052.jpg', 'face4_2417.jpg', 'face4_8584.jpg', 'face3_472.jpg', 'face4_11923.jpg', 'face4_2649.jpg', 'face_166.jpg', 'face4_3738.jpg', 'face4_4163.jpg', 'face4_2943.jpg', 'face4_2253.jpg', 'face4_12557.jpg', 'face4_6258.jpg', 'face4_4933.jpg', 'face3_1524.jpg', 'face4_3167.jpg', 'face3_923.jpg', 'face3_298.jpg', 'face3_1180.jpg', 'face4_3068.jpg', 'face_87.jpg', 'face4_8677.jpg', 'face4_5806.jpg', 'face4_686.jpg', 'face3_221.jpg', 'face4_3783.jpg', 'face4_3099.jpg', 'face4_8653.jpg', 'face4_8259.jpg', 'face4_1587.jpg', 'face4_2878.jpg', 'face4_10724.jpg', 'face2_720.jpg', 'face4_11984.jpg', 'face4_7623.jpg', 'face4_182.jpg', 'face4_10009.jpg', 'face4_2464.jpg', 'face4_1653.jpg', 'face4_7594.jpg', 'face4_2749.jpg', 'face4_4731.jpg', 'face4_959.jpg', 'face4_7030.jpg', 'face4_4326.jpg', 'face4_1958.jpg', 'face3_1129.jpg', 'face3_73.jpg', 'face4_10823.jpg', 'face4_11267.jpg', 'face4_11803.jpg', 'face4_10921.jpg', 'face4_4956.jpg', 'face4_10832.jpg', 'face3_265.jpg', 'face4_6578.jpg', 'face4_6242.jpg', 'face4_2623.jpg', 'face4_3224.jpg', 'face_94.jpg', 'face4_11257.jpg', 'face_37.jpg', 'face3_1170.jpg', 'face4_13440.jpg', 'face4_2492.jpg', 'face4_4148.jpg', 'face4_2881.jpg', 'face4_2379.jpg', 'face4_2507.jpg', 'face4_6596.jpg', 'face4_4026.jpg', 'face4_4313.jpg', 'face3_1038.jpg', 'face4_8570.jpg', 'face3_146.jpg', 'face4_2172.jpg', 'face3_1441.jpg', 'face4_9306.jpg', 'face_75.jpg', 'face4_2785.jpg', 'face4_4365.jpg', 'face4_5399.jpg', 'face4_8841.jpg', 'face_125.jpg', 'face4_10970.jpg', 'face4_4124.jpg', 'face4_8252.jpg', 'face4_5932.jpg', 'face4_3146.jpg', 'face4_536.jpg', 'face4_5555.jpg', 'face4_10676.jpg', 'face4_8182.jpg', 'face4_11814.jpg', 'face3_380.jpg', 'face3_257.jpg', 'face4_4268.jpg', 'face4_5485.jpg', 'face4_8805.jpg', 'face4_10272.jpg', 'face4_10865.jpg', 'face4_4580.jpg', 'face4_9868.jpg', 'face4_5074.jpg', 'face4_9836.jpg', 'face4_11921.jpg', 'face4_879.jpg', 'face4_12323.jpg', 'face4_416.jpg', 'face4_8994.jpg', 'face4_8117.jpg', 'face4_3903.jpg', 'face4_12861.jpg', 'face_136.jpg', 'face2_23.jpg', 'face4_4749.jpg', 'face4_8538.jpg', 'face4_2675.jpg', 'face4_5899.jpg', 'face4_926.jpg', 'face4_3440.jpg', 'face4_2702.jpg', 'face4_8808.jpg', 'face4_13034.jpg', 'face4_4257.jpg', 'face4_5336.jpg', 'face_31.jpg', 'face4_7070.jpg', 'face4_8166.jpg', 'face4_2920.jpg', 'face4_7741.jpg', 'face4_2519.jpg', 'face4_12300.jpg', 'face4_10390.jpg', 'face4_7573.jpg', 'face4_7489.jpg', 'face4_514.jpg', 'face4_9988.jpg', 'face4_5683.jpg', 'face4_1147.jpg', 'face_143.jpg', 'face4_2962.jpg', 'face4_3952.jpg', 'face4_9685.jpg', 'face4_2433.jpg', 'face4_6291.jpg', 'face4_5675.jpg', 'face4_5639.jpg', 'face4_5129.jpg', 'face4_12513.jpg', 'face3_239.jpg', 'face4_4180.jpg', 'face4_11714.jpg', 'face4_1251.jpg', 'face4_8239.jpg', 'face2_144.jpg', 'face4_7784.jpg', 'face4_12006.jpg', 'face4_8585.jpg', 'face4_4343.jpg', 'face4_4565.jpg', 'face4_6588.jpg', 'face4_9802.jpg', 'face4_4525.jpg', 'face4_4055.jpg', 'face4_13582.jpg', 'face2_90.jpg', 'face4_683.jpg', 'face4_5704.jpg', 'face4_4173.jpg', 'face4_905.jpg', 'face4_9657.jpg', 'face4_8600.jpg', 'face2_777.jpg', 'face4_3484.jpg', 'face4_9740.jpg', 'face4_7530.jpg', 'face4_1965.jpg', 'face4_2435.jpg', 'face4_5178.jpg', 'face4_1656.jpg', 'face4_10708.jpg', 'face3_1541.jpg', 'face4_8034.jpg', 'face4_13569.jpg', 'face3_60.jpg', 'face4_7552.jpg', 'face4_11699.jpg', 'face4_2897.jpg', 'face2_854.jpg', 'face4_6330.jpg', 'face4_2893.jpg', 'face3_236.jpg', 'face4_13080.jpg', 'face4_2746.jpg', 'face4_8185.jpg', 'face4_9578.jpg', 'face2_684.jpg', 'face4_6503.jpg', 'face4_872.jpg', 'face4_2527.jpg', 'face4_1143.jpg', 'face4_7139.jpg', 'face_84.jpg', 'face4_7152.jpg', 'face4_5613.jpg', 'face4_399.jpg', 'face4_9651.jpg', 'face4_11160.jpg', 'face4_11962.jpg', 'face4_7441.jpg', 'face4_13133.jpg', 'face4_4323.jpg', 'face3_431.jpg', 'face4_12129.jpg', 'face4_3729.jpg', 'face4_4234.jpg', 'face4_213.jpg', 'face4_4006.jpg', 'face2_651.jpg', 'face3_830.jpg', 'face4_7989.jpg', 'face4_7921.jpg', 'face4_1723.jpg', 'face4_5119.jpg', 'face4_13333.jpg', 'face4_8680.jpg', 'face4_4316.jpg', 'face4_8.jpg', 'face4_10012.jpg', 'face4_1945.jpg', 'face_124.jpg', 'face4_1066.jpg', 'face3_1134.jpg', 'face4_8815.jpg', 'face3_1422.jpg', 'face4_307.jpg', 'face3_1296.jpg', 'face_199.jpg', 'face4_10837.jpg', 'face4_10429.jpg', 'face4_12926.jpg', 'face4_3319.jpg', 'face4_4017.jpg', 'face_79.jpg', 'face4_3717.jpg', 'face4_8807.jpg', 'face4_2518.jpg', 'face2_645.jpg', 'face4_12163.jpg', 'face4_1804.jpg', 'face4_246.jpg', 'face4_2524.jpg', 'face4_6109.jpg', 'face4_3873.jpg', 'face4_12838.jpg', 'face4_5222.jpg', 'face4_9476.jpg', 'face4_6011.jpg', 'face4_4660.jpg', 'face3_1618.jpg', 'face3_1589.jpg', 'face4_7523.jpg', 'face4_5200.jpg', 'face3_533.jpg', 'face4_9604.jpg', 'face4_4705.jpg', 'face4_226.jpg', 'face4_935.jpg', 'face4_6528.jpg', 'face4_9673.jpg', 'face4_4157.jpg', 'face4_6125.jpg', 'face4_13016.jpg', 'face4_11306.jpg', 'face4_9586.jpg', 'face4_7355.jpg', 'face4_5408.jpg', 'face4_9332.jpg', 'face3_592.jpg', 'face4_10558.jpg', 'face4_3145.jpg', 'face4_2205.jpg', 'face4_7947.jpg', 'face4_2711.jpg', 'face4_4781.jpg', 'face2_704.jpg', 'face4_7918.jpg', 'face4_301.jpg', 'face4_10583.jpg', 'face4_12443.jpg', 'face4_5330.jpg', 'face4_11283.jpg', 'face4_4068.jpg', 'face4_1166.jpg', 'face4_6452.jpg', 'face4_12796.jpg', 'face4_5320.jpg', 'face4_8743.jpg', 'face4_5300.jpg', 'face4_4296.jpg', 'face4_10298.jpg', 'face4_8673.jpg', 'face4_7114.jpg', 'face4_9666.jpg', 'face4_6410.jpg', 'face3_1532.jpg', 'face4_1837.jpg', 'face4_7401.jpg', 'face4_1152.jpg', 'face3_580.jpg', 'face4_9534.jpg', 'face4_13563.jpg', 'face4_7776.jpg', 'face4_8207.jpg', 'face4_60.jpg', 'face4_2104.jpg', 'face3_1267.jpg', 'face3_299.jpg', 'face_115.jpg', 'face4_1932.jpg', 'face2_15.jpg', 'face4_5195.jpg', 'face4_4307.jpg', 'face3_204.jpg', 'face4_10846.jpg', 'face4_6134.jpg', 'face4_3826.jpg', 'face4_7136.jpg', 'face4_8213.jpg', 'face4_5357.jpg', 'face4_8210.jpg', 'face4_12699.jpg', 'face4_4755.jpg', 'face4_3084.jpg', 'face3_1449.jpg', 'face4_7928.jpg', 'face4_4717.jpg', 'face2_765.jpg', 'face4_876.jpg', 'face2_801.jpg', 'face4_3208.jpg', 'face4_462.jpg', 'face3_817.jpg', 'face4_12353.jpg', 'face3_198.jpg', 'face4_3727.jpg', 'face4_6834.jpg', 'face4_6311.jpg', 'face4_2334.jpg', 'face4_2123.jpg', 'face3_70.jpg', 'face4_907.jpg', 'face4_1615.jpg', 'face4_3855.jpg', 'face4_277.jpg', 'face3_1508.jpg', 'face4_7562.jpg', 'face4_11744.jpg', 'face4_12867.jpg', 'face4_4330.jpg', 'face4_11926.jpg', 'face4_2192.jpg', 'face4_2549.jpg', 'face4_1904.jpg', 'face4_1118.jpg', 'face4_8591.jpg', 'face4_12473.jpg', 'face4_3221.jpg', 'face4_942.jpg', 'face4_4382.jpg', 'face2_27.jpg', 'face4_2408.jpg', 'face2_3.jpg', 'face4_204.jpg', 'face4_87.jpg', 'face4_6127.jpg', 'face3_1612.jpg', 'face4_438.jpg', 'face4_4375.jpg', 'face4_12793.jpg', 'face4_11845.jpg', 'face4_4678.jpg', 'face4_9884.jpg', 'face4_967.jpg', 'face4_12263.jpg', 'face4_12738.jpg', 'face4_9254.jpg', 'face4_10283.jpg', 'face4_8191.jpg', 'face4_376.jpg', 'face4_1878.jpg', 'face4_5462.jpg', 'face4_9480.jpg', 'face4_3288.jpg', 'face4_2158.jpg', 'face4_5538.jpg', 'face4_3537.jpg', 'face4_7502.jpg', 'face4_4513.jpg', 'face4_1234.jpg', 'face4_9241.jpg', 'face4_6057.jpg', 'face4_13601.jpg', 'face4_12847.jpg', 'face4_7888.jpg', 'face2_19.jpg', 'face4_5418.jpg', 'face4_12302.jpg', 'face3_792.jpg', 'face2_652.jpg', 'face4_932.jpg', 'face3_739.jpg', 'face4_10610.jpg', 'face4_10697.jpg', 'face4_7529.jpg', 'face4_12896.jpg', 'face4_680.jpg', 'face4_4215.jpg', 'face4_4977.jpg', 'face4_7566.jpg', 'face4_733.jpg', 'face4_1614.jpg', 'face4_7332.jpg', 'face4_2960.jpg', 'face4_4707.jpg', 'face4_3996.jpg', 'face4_2217.jpg', 'face4_5316.jpg', 'face3_1220.jpg', 'face3_1048.jpg', 'face2_702.jpg', 'face3_386.jpg', 'face3_263.jpg', 'face4_2842.jpg', 'face3_200.jpg', 'face4_3201.jpg', 'face4_5104.jpg', 'face4_13151.jpg', 'face_114.jpg', 'face4_7074.jpg', 'face4_6253.jpg', 'face4_8800.jpg', 'face4_9538.jpg', 'face4_3021.jpg', 'face4_11822.jpg', 'face4_2682.jpg', 'face3_1658.jpg', 'face3_1039.jpg', 'face4_4426.jpg', 'face4_7919.jpg', 'face4_1180.jpg', 'face4_9998.jpg', 'face3_278.jpg', 'face4_12351.jpg', 'face4_2237.jpg', 'face4_12605.jpg', 'face4_2459.jpg', 'face4_3862.jpg', 'face3_294.jpg', 'face4_8055.jpg', 'face4_3105.jpg', 'face3_559.jpg', 'face4_4399.jpg', 'face4_11914.jpg', 'face4_8218.jpg', 'face4_1686.jpg', 'face4_5386.jpg', 'face4_4531.jpg', 'face4_9806.jpg', 'face4_1925.jpg', 'face4_6153.jpg', 'face4_9986.jpg', 'face3_1174.jpg', 'face4_12477.jpg', 'face4_12073.jpg', 'face4_5501.jpg', 'face4_9350.jpg', 'face4_11666.jpg', 'face4_909.jpg', 'face4_8084.jpg', 'face4_2206.jpg', 'face4_517.jpg', 'face4_7650.jpg', 'face4_9180.jpg', 'face4_9751.jpg', 'face4_1728.jpg', 'face4_7678.jpg', 'face4_8811.jpg', 'face4_6571.jpg', 'face_41.jpg', 'face4_4928.jpg', 'face4_10539.jpg', 'face4_10550.jpg', 'face2_751.jpg', 'face4_3966.jpg', 'face_86.jpg', 'face4_115.jpg', 'face4_8608.jpg', 'face4_8234.jpg', 'face3_541.jpg', 'face4_6100.jpg', 'face4_7434.jpg', 'face4_12001.jpg', 'face4_4384.jpg', 'face3_191.jpg', 'face4_5904.jpg', 'face4_3172.jpg', 'face4_5984.jpg', 'face4_1865.jpg', 'face4_1035.jpg', 'face4_2576.jpg', 'face4_1292.jpg', 'face4_4284.jpg', 'face4_11253.jpg', 'face4_6547.jpg', 'face4_6400.jpg', 'face4_4281.jpg', 'face3_95.jpg', 'face4_5668.jpg', 'face4_1817.jpg', 'face4_2178.jpg', 'face4_5460.jpg', 'face4_7560.jpg', 'face4_11660.jpg', 'face4_12783.jpg', 'face4_12379.jpg', 'face3_908.jpg', 'face4_10582.jpg', 'face4_5466.jpg', 'face3_39.jpg', 'face4_710.jpg', 'face4_8594.jpg', 'face4_3322.jpg', 'face4_2145.jpg', 'face4_8209.jpg', 'face4_1824.jpg', 'face4_5632.jpg', 'face3_569.jpg', 'face4_3144.jpg', 'face3_591.jpg', 'face4_4205.jpg', 'face4_426.jpg', 'face4_2604.jpg', 'face4_5252.jpg', 'face4_2783.jpg', 'face4_2619.jpg', 'face4_3125.jpg', 'face4_4142.jpg', 'face4_7432.jpg', 'face4_12172.jpg', 'face4_6437.jpg', 'face4_2724.jpg', 'face4_12296.jpg', 'face4_12799.jpg', 'face4_6496.jpg', 'face4_5050.jpg', 'face2_700.jpg', 'face4_2530.jpg', 'face4_4406.jpg', 'face4_11180.jpg', 'face4_6530.jpg', 'face4_5091.jpg', 'face4_7952.jpg', 'face4_3179.jpg', 'face4_823.jpg', 'face4_5014.jpg', 'face3_229.jpg', 'face4_9835.jpg', 'face_90.jpg', 'face4_7676.jpg', 'face4_5500.jpg', 'face_63.jpg', 'face4_5690.jpg', 'face4_10244.jpg', 'face3_864.jpg', 'face_111.jpg', 'face4_11750.jpg', 'face_134.jpg', 'face4_2593.jpg', 'face4_5448.jpg', 'face4_13147.jpg', 'face3_56.jpg', 'face4_2273.jpg', 'face4_3036.jpg', 'face2_748.jpg', 'face4_13092.jpg', 'face3_123.jpg', 'face4_8827.jpg', 'face4_11275.jpg', 'face4_7378.jpg', 'face4_7609.jpg', 'face2_753.jpg', 'face4_1859.jpg', 'face_95.jpg', 'face2_701.jpg', 'face4_4945.jpg', 'face4_12157.jpg', 'face4_4289.jpg', 'face4_2462.jpg', 'face4_1348.jpg', 'face4_321.jpg', 'face4_6623.jpg', 'face4_9681.jpg', 'face4_6061.jpg', 'face4_11834.jpg', 'face4_5190.jpg', 'face4_928.jpg', 'face4_4536.jpg', 'face4_12067.jpg', 'face3_1278.jpg', 'face4_12271.jpg', 'face4_6223.jpg', 'face4_7346.jpg', 'face4_9267.jpg', 'face4_3328.jpg', 'face4_5988.jpg', 'face4_9326.jpg', 'face4_9300.jpg', 'face4_1697.jpg', 'face4_297.jpg', 'face4_490.jpg', 'face2_17.jpg', 'face4_3317.jpg', 'face4_3991.jpg', 'face3_394.jpg', 'face4_1045.jpg', 'face4_7011.jpg', 'face4_2057.jpg', 'face4_511.jpg', 'face3_109.jpg', 'face4_2953.jpg', 'face4_6261.jpg', 'face3_1564.jpg', 'face3_1282.jpg', 'face4_5343.jpg', 'face3_279.jpg', 'face3_162.jpg', 'face3_452.jpg', 'face4_6094.jpg', 'face4_6927.jpg', 'face4_13554.jpg', 'face3_268.jpg', 'face4_11656.jpg', 'face4_5209.jpg', 'face4_2730.jpg', 'face4_6021.jpg', 'face4_7977.jpg', 'face4_4383.jpg', 'face4_2300.jpg', 'face4_6570.jpg', 'face4_6934.jpg', 'face4_8571.jpg', 'face4_9213.jpg', 'face4_2284.jpg', 'face4_12848.jpg', 'face4_244.jpg', 'face4_12929.jpg', 'face4_1889.jpg', 'face3_878.jpg', 'face4_12835.jpg', 'face3_262.jpg', 'face4_6476.jpg', 'face4_1254.jpg', 'face4_8132.jpg', 'face4_7015.jpg', 'face4_2830.jpg', 'face3_1556.jpg', 'face4_4024.jpg', 'face4_7454.jpg', 'face4_4121.jpg', 'face4_2113.jpg', 'face3_859.jpg', 'face4_3714.jpg', 'face3_596.jpg', 'face_40.jpg', 'face4_9317.jpg', 'face4_7065.jpg', 'face3_554.jpg', 'face4_10784.jpg', 'face4_9738.jpg', 'face4_2760.jpg', 'face4_12908.jpg', 'face4_3076.jpg', 'face4_6264.jpg', 'face4_2374.jpg', 'face4_2911.jpg', 'face_156.jpg', 'face4_10547.jpg', 'face4_4774.jpg', 'face4_5254.jpg', 'face4_4103.jpg', 'face3_275.jpg', 'face4_402.jpg', 'face4_84.jpg', 'face4_2670.jpg', 'face4_11919.jpg', 'face4_5016.jpg', 'face4_6892.jpg', 'face4_12264.jpg', 'face4_7066.jpg', 'face4_6916.jpg', 'face4_8747.jpg', 'face4_1689.jpg', 'face3_821.jpg', 'face4_12123.jpg', 'face4_5655.jpg', 'face4_4341.jpg', 'face4_7550.jpg', 'face4_1987.jpg', 'face4_3882.jpg', 'face4_10960.jpg', 'face4_791.jpg', 'face4_6249.jpg', 'face4_2631.jpg', 'face4_1640.jpg', 'face2_59.jpg', 'face4_317.jpg', 'face3_869.jpg', 'face4_13027.jpg', 'face4_11655.jpg', 'face4_2017.jpg', 'face4_11297.jpg', 'face4_6033.jpg', 'face4_7655.jpg', 'face4_11155.jpg', 'face4_6576.jpg', 'face2_797.jpg', 'face4_10744.jpg', 'face4_6498.jpg', 'face4_3682.jpg', 'face4_8860.jpg', 'face4_12756.jpg', 'face4_7508.jpg', 'face4_988.jpg', 'face4_12760.jpg', 'face4_9479.jpg', 'face3_142.jpg', 'face4_1115.jpg', 'face4_3183.jpg', 'face4_1974.jpg', 'face4_1618.jpg', 'face4_11498.jpg', 'face4_7821.jpg', 'face4_3896.jpg', 'face4_220.jpg', 'face3_270.jpg', 'face4_6300.jpg', 'face4_4011.jpg', 'face4_6457.jpg', 'face4_1279.jpg', 'face4_9080.jpg', 'face4_13221.jpg', 'face4_4753.jpg', 'face4_90.jpg', 'face4_5907.jpg', 'face4_8125.jpg', 'face4_10399.jpg', 'face4_9664.jpg', 'face4_827.jpg', 'face4_6453.jpg', 'face4_3725.jpg', 'face3_1420.jpg', 'face4_10257.jpg', 'face4_1634.jpg', 'face4_7016.jpg', 'face4_6417.jpg', 'face4_5717.jpg', 'face4_4246.jpg', 'face4_11191.jpg', 'face4_3787.jpg', 'face4_3110.jpg', 'face4_7834.jpg', 'face4_6455.jpg', 'face4_4167.jpg', 'face2_26.jpg', 'face4_7615.jpg', 'face2_774.jpg', 'face4_717.jpg', 'face4_5825.jpg', 'face4_9544.jpg', 'face4_9932.jpg', 'face4_10605.jpg', 'face4_13597.jpg', 'face4_1694.jpg', 'face4_9539.jpg', 'face3_866.jpg', 'face4_5807.jpg', 'face4_7944.jpg', 'face4_2314.jpg', 'face4_9947.jpg', 'face2_38.jpg', 'face4_5957.jpg', 'face4_7579.jpg', 'face4_1841.jpg', 'face2_687.jpg', 'face4_9474.jpg', 'face4_2856.jpg', 'face4_3842.jpg', 'face4_12482.jpg', 'face4_6531.jpg', 'face4_12744.jpg', 'face4_4690.jpg', 'face_161.jpg', 'face4_173.jpg', 'face4_4396.jpg', 'face4_3468.jpg', 'face4_8119.jpg', 'face4_7335.jpg', 'face2_135.jpg', 'face4_8620.jpg', 'face4_772.jpg', 'face4_2152.jpg', 'face4_8523.jpg', 'face4_9491.jpg', 'face4_4376.jpg', 'face4_1038.jpg', 'face4_2666.jpg', 'face4_118.jpg', 'face4_11723.jpg', 'face4_8041.jpg', 'face4_12161.jpg', 'face4_8228.jpg', 'face4_2306.jpg', 'face4_3074.jpg', 'face4_2385.jpg', 'face4_6355.jpg', 'face4_3686.jpg', 'face4_2382.jpg', 'face4_13095.jpg', 'face4_3517.jpg', 'face4_11309.jpg', 'face4_13575.jpg', 'face4_6603.jpg', 'face3_1144.jpg', 'face4_9208.jpg', 'face4_10242.jpg', 'face4_33.jpg', 'face4_11799.jpg', 'face4_7413.jpg', 'face4_7798.jpg', 'face3_894.jpg', 'face4_6602.jpg', 'face4_7447.jpg', 'face3_758.jpg', 'face4_10102.jpg', 'face4_13578.jpg', 'face4_6051.jpg', 'face4_4201.jpg', 'face4_11697.jpg', 'face4_9915.jpg', 'face4_13207.jpg', 'face4_4264.jpg', 'face4_5182.jpg', 'face4_2478.jpg', 'face4_4487.jpg', 'face4_10963.jpg', 'face4_3142.jpg', 'face4_4738.jpg', 'face4_2867.jpg', 'face4_3212.jpg', 'face4_7085.jpg', 'face3_566.jpg', 'face4_9341.jpg', 'face4_9694.jpg', 'face4_4683.jpg', 'face2_662.jpg', 'face4_8806.jpg', 'face3_932.jpg', 'face4_12719.jpg', 'face3_507.jpg', 'face4_2759.jpg', 'face4_4793.jpg', 'face4_4630.jpg', 'face4_13504.jpg', 'face4_2721.jpg', 'face4_2949.jpg', 'face4_12394.jpg', 'face4_2008.jpg', 'face4_10499.jpg', 'face4_2329.jpg', 'face3_46.jpg', 'face3_1615.jpg', 'face4_5628.jpg', 'face4_8573.jpg', 'face4_2934.jpg', 'face4_13585.jpg', 'face4_12109.jpg', 'face4_12189.jpg', 'face4_9250.jpg', 'face4_4853.jpg', 'face4_6920.jpg', 'face4_13467.jpg', 'face4_1947.jpg', 'face4_9307.jpg', 'face3_1274.jpg', 'face4_4338.jpg', 'face4_2803.jpg', 'face4_7420.jpg', 'face4_9790.jpg', 'face4_8675.jpg', 'face2_53.jpg', 'face2_20.jpg', 'face4_839.jpg', 'face3_1513.jpg', 'face4_5393.jpg', 'face2_47.jpg', 'face3_7.jpg', 'face4_6908.jpg', 'face4_4093.jpg', 'face4_1820.jpg', 'face4_13101.jpg', 'face3_91.jpg', 'face4_853.jpg', 'face4_11229.jpg', 'face4_1710.jpg', 'face4_4143.jpg', 'face4_5949.jpg', 'face3_868.jpg', 'face3_82.jpg', 'face4_1189.jpg', 'face4_5605.jpg', 'face3_537.jpg', 'face4_9622.jpg', 'face4_2813.jpg', 'face3_874.jpg', 'face_98.jpg', 'face4_9596.jpg', 'face4_13139.jpg', 'face_54.jpg', 'face4_1083.jpg', 'face4_3532.jpg', 'face4_3294.jpg', 'face4_3012.jpg', 'face4_2096.jpg', 'face4_13086.jpg', 'face4_8628.jpg', 'face4_7636.jpg', 'face4_10581.jpg', 'face3_843.jpg', 'face4_4450.jpg', 'face_35.jpg', 'face4_2663.jpg', 'face4_1891.jpg', 'face2_657.jpg', 'face_80.jpg', 'face4_3418.jpg', 'face4_6574.jpg', 'face4_6559.jpg', 'face3_255.jpg', 'face4_5030.jpg', 'face3_230.jpg', 'face4_3373.jpg', 'face4_3343.jpg', 'face4_2424.jpg', 'face4_11091.jpg', 'face4_12554.jpg', 'face4_9489.jpg', 'face4_4643.jpg', 'face4_6539.jpg', 'face4_11488.jpg', 'face4_1913.jpg', 'face4_1822.jpg', 'face4_8568.jpg', 'face3_803.jpg', 'face4_372.jpg', 'face4_9865.jpg', 'face4_1897.jpg', 'face4_2931.jpg', 'face4_1766.jpg', 'face2_814.jpg', 'face4_974.jpg', 'face4_12721.jpg', 'face2_722.jpg', 'face4_2161.jpg', 'face4_6272.jpg', 'face3_1264.jpg', 'face4_3758.jpg', 'face4_7556.jpg', 'face4_2801.jpg', 'face2_640.jpg', 'face4_6040.jpg', 'face2_735.jpg', 'face3_1650.jpg', 'face4_12726.jpg', 'face4_10270.jpg', 'face4_382.jpg', 'face4_6327.jpg', 'face4_4770.jpg', 'face4_6837.jpg', 'face4_10278.jpg', 'face_130.jpg', 'face4_1839.jpg', 'face4_4936.jpg', 'face4_1139.jpg', 'face4_5487.jpg', 'face4_75.jpg', 'face4_11798.jpg', 'face4_13566.jpg', 'face4_6575.jpg', 'face4_12143.jpg', 'face3_492.jpg', 'face_117.jpg', 'face4_2304.jpg', 'face4_2149.jpg', 'face4_7951.jpg', 'face4_7974.jpg', 'face4_8267.jpg', 'face4_9713.jpg', 'face4_11198.jpg', 'face4_449.jpg', 'face_49.jpg', 'face4_2512.jpg', 'face4_385.jpg', 'face3_528.jpg', 'face4_3269.jpg', 'face4_1244.jpg', 'face4_3538.jpg', 'face4_10020.jpg', 'face2_688.jpg', 'face3_1560.jpg', 'face4_5370.jpg', 'face4_8984.jpg', 'face4_5121.jpg', 'face4_168.jpg', 'face4_3423.jpg', 'face4_7385.jpg', 'face4_2850.jpg', 'face4_5041.jpg', 'face4_12084.jpg', 'face4_4880.jpg', 'face4_9950.jpg', 'face4_7048.jpg', 'face4_6951.jpg', 'face3_238.jpg', 'face4_9710.jpg', 'face3_1567.jpg', 'face4_3967.jpg', 'face4_6548.jpg', 'face4_8873.jpg', 'face4_3420.jpg', 'face4_93.jpg', 'face_188.jpg', 'face4_1949.jpg', 'face4_3796.jpg', 'face4_7845.jpg', 'face4_3791.jpg', 'face3_1400.jpg', 'face4_2323.jpg', 'face4_5287.jpg', 'face4_12832.jpg', 'face4_13523.jpg', 'face4_695.jpg', 'face4_7449.jpg', 'face4_11958.jpg', 'face4_11795.jpg', 'face4_8882.jpg', 'face4_2926.jpg', 'face4_455.jpg', 'face4_8561.jpg', 'face4_1048.jpg', 'face4_5942.jpg', 'face4_9908.jpg', 'face4_6487.jpg', 'face4_5982.jpg', 'face4_2502.jpg', 'face4_3778.jpg', 'face4_863.jpg', 'face4_3177.jpg', 'face4_9229.jpg', 'face4_3276.jpg', 'face2_39.jpg', 'face4_2269.jpg', 'face4_1884.jpg', 'face3_174.jpg', 'face4_12827.jpg', 'face4_5188.jpg', 'face4_2993.jpg', 'face4_13050.jpg', 'face4_3767.jpg', 'face4_1323.jpg', 'face4_2669.jpg', 'face3_1034.jpg', 'face4_10273.jpg', 'face4_9887.jpg', 'face4_13633.jpg', 'face2_25.jpg', 'face4_10462.jpg', 'face4_6235.jpg', 'face4_13104.jpg', 'face4_2421.jpg', 'face4_164.jpg', 'face4_6847.jpg', 'face3_251.jpg', 'face4_3162.jpg', 'face4_12855.jpg', 'face4_1887.jpg', 'face4_3255.jpg', 'face4_8219.jpg', 'face4_10815.jpg', 'face3_587.jpg', 'face3_93.jpg', 'face4_9804.jpg', 'face4_4211.jpg', 'face4_2495.jpg', 'face4_3983.jpg', 'face3_1425.jpg', 'face4_7917.jpg', 'face4_8009.jpg', 'face4_13163.jpg', 'face_109.jpg', 'face4_5312.jpg', 'face4_6402.jpg', 'face4_10056.jpg', 'face3_875.jpg', 'face4_7411.jpg', 'face4_787.jpg', 'face4_2719.jpg', 'face4_13462.jpg', 'face4_12826.jpg', 'face3_1396.jpg', 'face4_156.jpg', 'face4_8795.jpg', 'face4_8254.jpg', 'face4_11118.jpg', 'face_24.jpg', 'face4_3525.jpg', 'face4_983.jpg', 'face4_3087.jpg', 'face3_433.jpg', 'face3_1030.jpg', 'face4_3151.jpg', 'face4_8179.jpg', 'face4_12882.jpg', 'face4_5241.jpg', 'face4_3817.jpg', 'face4_7673.jpg', 'face4_4736.jpg', 'face4_6464.jpg', 'face4_5636.jpg', 'face3_163.jpg', 'face4_128.jpg', 'face4_3248.jpg', 'face4_12374.jpg', 'face4_13146.jpg', 'face4_10588.jpg', 'face4_8188.jpg', 'face4_8160.jpg', 'face4_11827.jpg', 'face4_3164.jpg', 'face4_821.jpg', 'face4_2722.jpg', 'face4_9256.jpg', 'face3_787.jpg', 'face4_7911.jpg', 'face3_182.jpg', 'face4_12030.jpg', 'face4_326.jpg', 'face_200.jpg', 'face4_7558.jpg', 'face4_12239.jpg', 'face3_1149.jpg', 'face4_3330.jpg', 'face4_4191.jpg', 'face4_3071.jpg', 'face4_5066.jpg', 'face4_11084.jpg', 'face4_5324.jpg', 'face4_5377.jpg', 'face4_9219.jpg', 'face4_2514.jpg', 'face4_3267.jpg', 'face4_2487.jpg', 'face4_3089.jpg', 'face4_4182.jpg', 'face4_4538.jpg', 'face4_1076.jpg', 'face4_8547.jpg', 'face4_5492.jpg', 'face4_12540.jpg', 'face4_12941.jpg', 'face4_9683.jpg', 'face4_2075.jpg', 'face4_6876.jpg', 'face4_12535.jpg', 'face3_223.jpg', 'face4_3518.jpg', 'face4_970.jpg', 'face4_3182.jpg', 'face4_6873.jpg', 'face4_8598.jpg', 'face4_5246.jpg', 'face4_5350.jpg', 'face2_760.jpg', 'face4_1885.jpg', 'face4_3357.jpg', 'face4_8640.jpg', 'face4_4013.jpg', 'face4_3236.jpg', 'face4_8586.jpg', 'face4_8023.jpg', 'face4_8087.jpg', 'face4_8122.jpg', 'face4_8365.jpg', 'face4_4134.jpg', 'face4_4862.jpg', 'face4_7415.jpg', 'face4_6756.jpg', 'face4_4586.jpg', 'face4_7905.jpg', 'face4_3042.jpg', 'face4_6406.jpg', 'face4_1730.jpg', 'face4_1309.jpg', 'face4_5967.jpg', 'face4_8149.jpg', 'face4_7627.jpg', 'face4_9871.jpg', 'face4_2355.jpg', 'face4_12818.jpg', 'face4_4778.jpg', 'face4_9581.jpg', 'face4_471.jpg', 'face4_9781.jpg', 'face4_2282.jpg', 'face_97.jpg', 'face4_1623.jpg', 'face4_3108.jpg', 'face4_1736.jpg', 'face4_7647.jpg', 'face4_2774.jpg', 'face3_208.jpg', 'face4_2903.jpg', 'face4_12581.jpg', 'face4_1898.jpg', 'face4_3233.jpg', 'face4_2260.jpg', 'face4_4967.jpg', 'face3_1504.jpg', 'face4_12701.jpg', 'face4_309.jpg', 'face3_747.jpg', 'face4_4228.jpg', 'face4_5290.jpg', 'face4_3313.jpg', 'face4_9758.jpg', 'face4_4746.jpg', 'face4_4232.jpg', 'face4_42.jpg', 'face4_7386.jpg', 'face4_5645.jpg', 'face4_2684.jpg', 'face4_4374.jpg', 'face4_5483.jpg', 'face4_3425.jpg', 'face4_6901.jpg', 'face4_12174.jpg', 'face4_4805.jpg', 'face4_265.jpg', 'face4_11960.jpg', 'face4_9573.jpg', 'face4_7081.jpg', 'face3_410.jpg', 'face4_3712.jpg', 'face3_227.jpg', 'face4_9320.jpg', 'face4_2157.jpg', 'face4_3984.jpg', 'face4_2729.jpg', 'face2_87.jpg', 'face4_11781.jpg', 'face4_11299.jpg', 'face4_9633.jpg', 'face4_3038.jpg', 'face3_872.jpg', 'face4_5235.jpg', 'face4_12056.jpg', 'face4_5318.jpg', 'face4_11807.jpg', 'face2_67.jpg', 'face4_102.jpg', 'face4_2326.jpg', 'face4_12951.jpg', 'face4_9769.jpg', 'face4_5568.jpg', 'face3_752.jpg', 'face4_6006.jpg', 'face4_9247.jpg', 'face2_845.jpg', 'face3_1247.jpg', 'face4_12817.jpg', 'face4_4887.jpg', 'face4_1934.jpg', 'face4_2485.jpg', 'face4_8636.jpg', 'face4_5048.jpg', 'face4_13136.jpg', 'face2_762.jpg', 'face4_3287.jpg', 'face4_539.jpg', 'face4_12025.jpg', 'face2_732.jpg', 'face4_9543.jpg', 'face4_4478.jpg', 'face4_12270.jpg', 'face3_1338.jpg', 'face4_693.jpg', 'face3_445.jpg', 'face4_12426.jpg', 'face4_10542.jpg', 'face4_6583.jpg', 'face4_12392.jpg', 'face4_2302.jpg', 'face4_5502.jpg', 'face2_643.jpg', 'face4_7460.jpg', 'face4_768.jpg', 'face4_12915.jpg', 'face_174.jpg', 'face4_9611.jpg', 'face4_13176.jpg', 'face4_13561.jpg', 'face4_13107.jpg', 'face4_10014.jpg', 'face4_1894.jpg', 'face4_1874.jpg', 'face4_2551.jpg', 'face4_4085.jpg', 'face2_705.jpg', 'face4_5356.jpg', 'face4_2364.jpg', 'face3_909.jpg', 'face4_7955.jpg', 'face4_9053.jpg', 'face4_2311.jpg', 'face4_258.jpg', 'face4_4523.jpg', 'face4_1978.jpg', 'face4_2242.jpg', 'face4_6393.jpg', 'face4_8750.jpg', 'face4_484.jpg', 'face4_1781.jpg', 'face4_7570.jpg', 'face3_501.jpg', 'face4_2983.jpg', 'face3_117.jpg', 'face4_9763.jpg', 'face4_6.jpg', 'face3_1353.jpg', 'face4_2070.jpg', 'face4_13098.jpg', 'face4_13421.jpg', 'face3_837.jpg', 'face4_1261.jpg', 'face4_3519.jpg', 'face4_12440.jpg', 'face4_4320.jpg', 'face4_6444.jpg', 'face4_396.jpg', 'face4_5406.jpg', 'face4_12875.jpg', 'face4_3508.jpg', 'face4_10830.jpg', 'face_83.jpg', 'face4_13637.jpg', 'face4_9242.jpg', 'face4_3300.jpg', 'face4_13178.jpg', 'face4_11746.jpg', 'face4_7619.jpg', 'face4_13345.jpg', 'face4_13599.jpg', 'face4_2976.jpg', 'face2_715.jpg', 'face_62.jpg', 'face4_8225.jpg', 'face4_3291.jpg', 'face3_1046.jpg', 'face4_13203.jpg', 'face4_8869.jpg', 'face4_11651.jpg', 'face4_6840.jpg', 'face4_5536.jpg', 'face4_1593.jpg', 'face4_12575.jpg', 'face4_2720.jpg', 'face4_9929.jpg', 'face4_7127.jpg', 'face4_1738.jpg', 'face4_4991.jpg', 'face2_795.jpg', 'face4_796.jpg', 'face4_8203.jpg', 'face3_1620.jpg', 'face4_1621.jpg', 'face4_11140.jpg', 'face4_8872.jpg', 'face4_13145.jpg', 'face4_13496.jpg', 'face4_5375.jpg', 'face4_8193.jpg', 'face3_865.jpg', 'face_113.jpg', 'face2_661.jpg', 'face4_3457.jpg', 'face4_11652.jpg', 'face4_4045.jpg', 'face4_8632.jpg', 'face4_7535.jpg', 'face4_9512.jpg', 'face4_6943.jpg', 'face3_1044.jpg', 'face4_9048.jpg', 'face4_10370.jpg', 'face4_11116.jpg', 'face4_1268.jpg', 'face4_5701.jpg', 'face4_6556.jpg', 'face4_8822.jpg', 'face4_12044.jpg', 'face4_477.jpg', 'face4_3175.jpg', 'face3_187.jpg', 'face2_811.jpg', 'face3_1198.jpg', 'face_189.jpg', 'face4_9820.jpg', 'face4_7857.jpg', 'face3_283.jpg', 'face4_2713.jpg', 'face4_222.jpg', 'face4_764.jpg', 'face4_280.jpg', 'face4_1072.jpg', 'face3_28.jpg', 'face4_2971.jpg', 'face4_12329.jpg', 'face4_7621.jpg', 'face4_3121.jpg', 'face4_4256.jpg', 'face4_2981.jpg', 'face_29.jpg', 'face4_4870.jpg', 'face4_11223.jpg', 'face4_3812.jpg', 'face3_158.jpg', 'face4_4849.jpg', 'face4_7587.jpg', 'face4_12460.jpg', 'face4_249.jpg', 'face4_3417.jpg', 'face4_11904.jpg', 'face4_12546.jpg', 'face4_3478.jpg', 'face4_8867.jpg', 'face4_6924.jpg', 'face_180.jpg', 'face4_13519.jpg', 'face3_54.jpg', 'face4_7145.jpg', 'face3_900.jpg', 'face4_5365.jpg', 'face4_8199.jpg', 'face4_1906.jpg', 'face4_1089.jpg', 'face4_2907.jpg', 'face3_1146.jpg', 'face4_5583.jpg', 'face4_7781.jpg', 'face4_2665.jpg', 'face4_4672.jpg', 'face4_392.jpg', 'face4_8662.jpg', 'face4_11819.jpg', 'face4_5339.jpg', 'face4_3959.jpg', 'face4_7569.jpg', 'face4_44.jpg', 'face4_3112.jpg', 'face2_50.jpg', 'face3_178.jpg', 'face4_8631.jpg', 'face4_8780.jpg', 'face4_12433.jpg', 'face4_6090.jpg', 'face4_5224.jpg', 'face4_7119.jpg', 'face3_577.jpg', 'face4_1883.jpg', 'face4_2768.jpg', 'face4_8150.jpg', 'face4_3886.jpg', 'face2_757.jpg', 'face4_9343.jpg', 'face4_994.jpg', 'face4_12550.jpg', 'face3_839.jpg', 'face4_4634.jpg', 'face4_9510.jpg', 'face4_13557.jpg', 'face3_1483.jpg', 'face4_2565.jpg', 'face4_13431.jpg', 'face4_5402.jpg', 'face4_3733.jpg', 'face4_9911.jpg', 'face2_100.jpg', 'face4_10598.jpg', 'face4_4688.jpg', 'face4_56.jpg', 'face4_1112.jpg', 'face4_1677.jpg', 'face4_6426.jpg', 'face4_11665.jpg', 'face2_138.jpg', 'face4_3140.jpg', 'face4_6333.jpg', 'face3_234.jpg', 'face4_9310.jpg', 'face4_13475.jpg', 'face4_6775.jpg', 'face4_6560.jpg', 'face3_873.jpg', 'face4_10532.jpg', 'face4_12889.jpg', 'face4_3118.jpg', 'face4_12774.jpg', 'face_58.jpg', 'face4_13451.jpg', 'face4_4208.jpg', 'face4_7748.jpg', 'face4_979.jpg', 'face4_9594.jpg', 'face4_10393.jpg', 'face4_8988.jpg', 'face4_2701.jpg', 'face4_2030.jpg', 'face4_12741.jpg', 'face4_3529.jpg', 'face4_12527.jpg', 'face4_6525.jpg', 'face2_660.jpg', 'face4_4790.jpg', 'face4_189.jpg', 'face2_141.jpg', 'face4_6449.jpg', 'face4_4518.jpg', 'face4_4783.jpg', 'face4_4799.jpg', 'face4_10589.jpg', 'face4_3056.jpg', 'face4_4213.jpg', 'face3_1204.jpg', 'face4_5368.jpg', 'face4_9798.jpg', 'face4_4315.jpg', 'face3_1196.jpg', 'face4_1276.jpg', 'face4_4291.jpg', 'face4_9494.jpg', 'face3_1579.jpg', 'face4_2546.jpg', 'face4_7381.jpg', 'face2_696.jpg', 'face3_1489.jpg', 'face4_3351.jpg', 'face4_1159.jpg', 'face4_2010.jpg', 'face4_6772.jpg', 'face4_26.jpg', 'face4_1853.jpg', 'face4_2567.jpg', 'face3_903.jpg', 'face4_5304.jpg', 'face4_753.jpg', 'face4_10573.jpg', 'face4_1970.jpg', 'face4_3225.jpg', 'face4_8597.jpg', 'face4_2210.jpg', 'face4_3265.jpg', 'face4_2683.jpg', 'face3_1402.jpg', 'face4_1741.jpg', 'face2_24.jpg', 'face4_8580.jpg', 'face4_6047.jpg', 'face4_5713.jpg', 'face4_4983.jpg', 'face4_3746.jpg', 'face4_4344.jpg', 'face4_2626.jpg', 'face4_1018.jpg', 'face4_4389.jpg', 'face4_68.jpg', 'face4_6511.jpg', 'face4_1329.jpg', 'face3_785.jpg', 'face4_4298.jpg', 'face4_5025.jpg', 'face4_458.jpg', 'face4_1054.jpg', 'face4_2818.jpg', 'face2_703.jpg', 'face4_2094.jpg', 'face4_7581.jpg', 'face4_2700.jpg', 'face4_5570.jpg', 'face3_810.jpg', 'face4_6027.jpg', 'face4_8004.jpg', 'face4_3060.jpg', 'face2_33.jpg', 'face2_674.jpg', 'face4_8368.jpg', 'face4_11034.jpg', 'face3_1242.jpg', 'face4_4751.jpg', 'face4_8001.jpg', 'face4_3688.jpg', 'face4_8363.jpg', 'face4_6136.jpg', 'face4_7912.jpg', 'face4_7895.jpg', 'face4_2765.jpg', 'face4_7304.jpg', 'face2_680.jpg', 'face4_9825.jpg', 'face4_12516.jpg', 'face4_3847.jpg', 'face4_4889.jpg', 'face4_1668.jpg', 'face4_8227.jpg', 'face4_6193.jpg', 'face4_4501.jpg', 'face4_1131.jpg', 'face4_5328.jpg', 'face4_1912.jpg', 'face4_10484.jpg', 'face4_3048.jpg', 'face4_9649.jpg', 'face4_5652.jpg', 'face4_4377.jpg', 'face4_6159.jpg', 'face4_2914.jpg', 'face4_7602.jpg', 'face_133.jpg', 'face4_8216.jpg', 'face4_5973.jpg', 'face4_9598.jpg', 'face_145.jpg', 'face3_1479.jpg', 'face4_9851.jpg', 'face4_3003.jpg', 'face4_6918.jpg', 'face4_10146.jpg', 'face4_2219.jpg', 'face4_3134.jpg', 'face4_11173.jpg', 'face4_7865.jpg', 'face4_11955.jpg', 'face4_2352.jpg', 'face4_6352.jpg', 'face4_4680.jpg', 'face4_3124.jpg', 'face4_5202.jpg', 'face3_1571.jpg', 'face4_11194.jpg', 'face4_12136.jpg', 'face_150.jpg', 'face4_3756.jpg', 'face_96.jpg', 'face4_7141.jpg', 'face4_11679.jpg', 'face4_4655.jpg', 'face4_9487.jpg', 'face4_2750.jpg', 'face4_8031.jpg', 'face4_2032.jpg', 'face4_8790.jpg', 'face4_7470.jpg', 'face4_3081.jpg', 'face_92.jpg', 'face4_3877.jpg', 'face4_7491.jpg', 'face4_834.jpg', 'face4_3528.jpg', 'face4_2643.jpg', 'face4_1989.jpg', 'face4_8190.jpg', 'face3_1051.jpg', 'face4_11239.jpg', 'face4_2779.jpg', 'face4_1795.jpg', 'face4_951.jpg', 'face2_42.jpg', 'face4_5333.jpg', 'face4_4760.jpg', 'face3_1528.jpg', 'face4_8682.jpg', 'face4_9549.jpg', 'face4_5917.jpg', 'face4_3280.jpg', 'face4_10419.jpg', 'face4_2213.jpg', 'face2_817.jpg', 'face4_11793.jpg', 'face_20.jpg', 'face4_9992.jpg', 'face4_4332.jpg', 'face3_382.jpg', 'face4_13641.jpg', 'face4_10640.jpg', 'face4_3017.jpg', 'face4_6541.jpg', 'face4_7874.jpg', 'face_184.jpg', 'face4_11145.jpg', 'face3_274.jpg', 'face3_928.jpg', 'face4_2534.jpg', 'face4_12591.jpg', 'face4_2082.jpg', 'face4_11769.jpg', 'face3_1409.jpg', 'face4_3136.jpg', 'face4_3131.jpg', 'face4_5929.jpg', 'face4_8158.jpg', 'face4_12551.jpg', 'face4_12851.jpg', 'face4_11282.jpg', 'face2_772.jpg', 'face4_1835.jpg', 'face4_10874.jpg', 'face4_4596.jpg', 'face2_721.jpg', 'face4_1256.jpg', 'face4_5657.jpg', 'face3_1124.jpg', 'face4_5292.jpg', 'face4_12448.jpg', 'face4_5351.jpg', 'face4_1861.jpg', 'face4_3000.jpg', 'face4_3703.jpg', 'face4_10538.jpg', 'face4_422.jpg', 'face4_6415.jpg', 'face4_7644.jpg', 'face3_21.jpg', 'face4_8017.jpg', 'face4_6768.jpg', 'face2_5.jpg', 'face4_8324.jpg', 'face4_2696.jpg', 'face4_5095.jpg', 'face3_1357.jpg', 'face4_3769.jpg', 'face4_1059.jpg', 'face4_4719.jpg', 'face4_443.jpg', 'face4_8713.jpg', 'face4_4038.jpg', 'face4_3155.jpg', 'face4_1183.jpg', 'face4_2776.jpg', 'face4_1010.jpg', 'face4_11130.jpg', 'face4_4820.jpg', 'face4_13590.jpg', 'face4_4885.jpg', 'face4_3819.jpg', 'face4_13682.jpg', 'face4_5260.jpg', 'face3_1390.jpg', 'face4_13445.jpg', 'face4_2692.jpg', 'face4_3114.jpg', 'face4_7503.jpg', 'face4_1896.jpg', 'face4_3470.jpg', 'face4_9546.jpg', 'face4_6601.jpg', 'face4_785.jpg', 'face4_4088.jpg', 'face3_1430.jpg', 'face4_4534.jpg', 'face4_4146.jpg', 'face4_2159.jpg', 'face4_9277.jpg', 'face4_4757.jpg', 'face4_1661.jpg', 'face4_3256.jpg', 'face4_9615.jpg', 'face4_1638.jpg', 'face4_7932.jpg', 'face4_1289.jpg', 'face4_902.jpg', 'face4_5739.jpg', 'face4_11785.jpg', 'face2_48.jpg', 'face4_4768.jpg', 'face4_8671.jpg', 'face4_4025.jpg', 'face4_6507.jpg', 'face4_1828.jpg', 'face_177.jpg', 'face4_11695.jpg', 'face3_440.jpg', 'face4_6112.jpg', 'face4_2654.jpg', 'face4_12117.jpg', 'face4_6567.jpg', 'face4_2766.jpg', 'face4_2131.jpg', 'face4_4479.jpg', 'face4_10554.jpg', 'face4_3229.jpg', 'face4_5294.jpg', 'face4_4077.jpg', 'face4_11164.jpg', 'face4_6331.jpg', 'face4_1783.jpg', 'face3_1468.jpg', 'face4_7789.jpg', 'face4_9984.jpg', 'face4_759.jpg', 'face4_3005.jpg', 'face4_8131.jpg', 'face4_12336.jpg', 'face3_152.jpg', 'face4_10072.jpg', 'face4_7960.jpg', 'face4_526.jpg', 'face4_6141.jpg', 'face4_12456.jpg', 'face4_8113.jpg', 'face4_7006.jpg', 'face4_2390.jpg', 'face4_2223.jpg', 'face4_10025.jpg', 'face4_4221.jpg', 'face3_206.jpg', 'face4_2500.jpg', 'face4_2725.jpg', 'face4_5935.jpg', 'face4_13167.jpg', 'face3_1494.jpg', 'face4_10261.jpg', 'face4_10001.jpg', 'face4_4794.jpg', 'face4_10580.jpg', 'face4_6777.jpg', 'face_157.jpg', 'face4_2229.jpg', 'face4_3742.jpg', 'face4_924.jpg', 'face4_5553.jpg', 'face4_8154.jpg', 'face4_9858.jpg', 'face4_12244.jpg', 'face4_9925.jpg', 'face4_2659.jpg', 'face4_10279.jpg', 'face4_547.jpg', 'face4_8164.jpg', 'face4_10884.jpg', 'face2_101.jpg', 'face4_11767.jpg', 'face4_10571.jpg', 'face_151.jpg', 'face2_726.jpg', 'face3_80.jpg', 'face4_12949.jpg', 'face4_12280.jpg', 'face4_3213.jpg', 'face2_799.jpg', 'face4_7457.jpg', 'face4_6593.jpg', 'face4_282.jpg', 'face4_6599.jpg', 'face4_9471.jpg', 'face4_10892.jpg', 'face4_1316.jpg', 'face4_7477.jpg', 'face4_2877.jpg', 'face4_4373.jpg', 'face4_3776.jpg', 'face4_13161.jpg', 'face4_10288.jpg', 'face4_13155.jpg', 'face4_11262.jpg', 'face4_3540.jpg', 'face4_4830.jpg', 'face4_933.jpg', 'face4_1779.jpg', 'face4_532.jpg', 'face4_12249.jpg', 'face4_6755.jpg', 'face4_2180.jpg', 'face4_3080.jpg', 'face4_10979.jpg', 'face4_2430.jpg', 'face4_192.jpg', 'face4_8074.jpg', 'face4_10415.jpg', 'face4_11245.jpg', 'face3_1254.jpg', 'face4_9258.jpg', 'face4_6335.jpg', 'face4_13174.jpg', 'face4_10587.jpg', 'face3_1595.jpg', 'face4_5115.jpg', 'face4_5374.jpg', 'face4_11836.jpg', 'face4_12267.jpg', 'face4_5471.jpg', 'face4_3238.jpg', 'face4_13411.jpg', 'face4_1727.jpg', 'face4_10889.jpg', 'face4_4947.jpg', 'face4_12390.jpg', 'face4_13110.jpg', 'face4_2764.jpg', 'face4_8230.jpg', 'face3_744.jpg', 'face4_1632.jpg', 'face4_10565.jpg', 'face4_9252.jpg', 'face_155.jpg', 'face4_6910.jpg', 'face4_3480.jpg', 'face4_6181.jpg', 'face4_10537.jpg', 'face4_13002.jpg', 'face4_1057.jpg', 'face4_11967.jpg', 'face4_3691.jpg', 'face4_10592.jpg', 'face4_7585.jpg', 'face4_6880.jpg', 'face4_8559.jpg', 'face3_1384.jpg', 'face4_12712.jpg', 'face2_121.jpg', 'face4_11486.jpg', 'face4_3348.jpg', 'face4_3464.jpg', 'face4_10543.jpg', 'face2_132.jpg', 'face4_9178.jpg', 'face2_828.jpg', 'face4_8745.jpg', 'face3_30.jpg', 'face_103.jpg', 'face4_5079.jpg', 'face3_496.jpg', 'face4_5215.jpg', 'face4_70.jpg', 'face2_770.jpg', 'face4_1930.jpg', 'face2_779.jpg', 'face_186.jpg', 'face3_1284.jpg', 'face3_1621.jpg', 'face_71.jpg', 'face4_3944.jpg', 'face4_13057.jpg', 'face4_8212.jpg', 'face4_12584.jpg', 'face3_1309.jpg', 'face4_2781.jpg', 'face4_2854.jpg', 'face4_13119.jpg', 'face4_6610.jpg', 'face4_2614.jpg', 'face4_6473.jpg', 'face4_1281.jpg', 'face4_10446.jpg', 'face4_6363.jpg', 'face4_1236.jpg', 'face4_10022.jpg', 'face4_1007.jpg', 'face4_6867.jpg', 'face4_11677.jpg', 'face4_71.jpg', 'face4_4111.jpg', 'face4_1327.jpg', 'face4_2187.jpg', 'face4_4380.jpg', 'face4_11347.jpg', 'face3_516.jpg', 'face4_7426.jpg', 'face3_1183.jpg', 'face4_7564.jpg', 'face4_949.jpg', 'face4_2573.jpg', 'face4_11658.jpg', 'face4_5032.jpg', 'face4_11742.jpg', 'face4_11681.jpg', 'face3_140.jpg', 'face4_10046.jpg', 'face4_7511.jpg', 'face2_102.jpg', 'face3_522.jpg', 'face4_3066.jpg', 'face4_9826.jpg', 'face4_2744.jpg', 'face4_4367.jpg', 'face4_354.jpg', 'face2_851.jpg', 'face4_5580.jpg', 'face4_12502.jpg', 'face4_4923.jpg', 'face3_458.jpg', 'face4_6114.jpg', 'face3_722.jpg', 'face4_9463.jpg', 'face4_4675.jpg', 'face2_730.jpg', 'face4_1718.jpg', 'face4_4245.jpg', 'face4_5602.jpg', 'face4_802.jpg', 'face4_10898.jpg', 'face4_6489.jpg', 'face4_2707.jpg', 'face4_305.jpg', 'face4_883.jpg', 'face4_6365.jpg', 'face4_3961.jpg', 'face3_287.jpg', 'face4_912.jpg', 'face4_2874.jpg', 'face4_9635.jpg', 'face4_4195.jpg', 'face4_2845.jpg', 'face4_2805.jpg', 'face2_729.jpg', 'face4_2318.jpg', 'face4_4810.jpg', 'face4_9675.jpg', 'face2_659.jpg', 'face4_2737.jpg', 'face4_268.jpg', 'face4_2062.jpg', 'face4_12149.jpg', 'face4_2718.jpg', 'face4_6619.jpg', 'face3_1127.jpg', 'face4_12935.jpg', 'face4_12053.jpg', 'face2_16.jpg', 'face4_11168.jpg', 'face4_12299.jpg', 'face4_3302.jpg', 'face4_13173.jpg', 'face4_7306.jpg', 'face3_607.jpg', 'face4_8669.jpg', 'face4_8737.jpg', 'face4_2885.jpg', 'face3_10.jpg', 'face4_5366.jpg', 'face4_4766.jpg', 'face4_11135.jpg', 'face4_8271.jpg', 'face4_5947.jpg', 'face4_8602.jpg', 'face4_5600.jpg', 'face4_2835.jpg', 'face4_12062.jpg', 'face4_9284.jpg', 'face4_748.jpg', 'face4_11733.jpg', 'face_137.jpg', 'face4_3514.jpg', 'face4_9800.jpg', 'face4_11098.jpg', 'face4_5945.jpg', 'face4_7949.jpg', 'face4_11490.jpg', 'face4_13516.jpg', 'face4_12771.jpg', 'face4_8144.jpg', 'face4_2808.jpg', 'face4_736.jpg', 'face_85.jpg', 'face4_7922.jpg', 'face4_3722.jpg', 'face4_5642.jpg', 'face4_9517.jpg', 'face4_2708.jpg', 'face4_4137.jpg', 'face4_9794.jpg', 'face4_7906.jpg', 'face4_9822.jpg', 'face4_3296.jpg', 'face_147.jpg', 'face4_3327.jpg', 'face4_6545.jpg', 'face4_689.jpg', 'face4_12167.jpg', 'face4_4512.jpg', 'face4_5677.jpg', 'face4_11896.jpg', 'face4_7059.jpg', 'face4_4306.jpg', 'face4_5159.jpg', 'face4_2045.jpg', 'face4_8874.jpg', 'face4_4028.jpg', 'face4_7122.jpg', 'face4_12292.jpg', 'face4_5913.jpg', 'face3_288.jpg', 'face4_12548.jpg', 'face4_7934.jpg', 'face4_12963.jpg', 'face4_5551.jpg', 'face4_930.jpg', 'face3_138.jpg', 'face4_6550.jpg', 'face2_678.jpg', 'face3_1156.jpg', 'face4_8208.jpg', 'face4_4147.jpg', 'face4_9568.jpg', 'face4_6367.jpg', 'face4_7113.jpg', 'face4_6024.jpg', 'face4_12997.jpg', 'face4_1021.jpg', 'face4_9776.jpg', 'face4_3257.jpg', 'face4_524.jpg', 'face4_12572.jpg', 'face4_81.jpg', 'face3_202.jpg', 'face4_4061.jpg', 'face4_4843.jpg', 'face3_87.jpg', 'face3_259.jpg', 'face4_7326.jpg', 'face3_798.jpg', 'face4_1919.jpg', 'face4_1956.jpg', 'face4_8022.jpg', 'face4_5379.jpg', 'face2_46.jpg', 'face4_6198.jpg', 'face4_2583.jpg', 'face4_7611.jpg', 'face4_5624.jpg', 'face4_4240.jpg', 'face4_12290.jpg', 'face4_11817.jpg', 'face4_9717.jpg', 'face4_404.jpg', 'face4_11727.jpg', 'face3_563.jpg', 'face4_2967.jpg', 'face4_9450.jpg', 'face4_1319.jpg', 'face4_7822.jpg', 'face4_13443.jpg', 'face4_1109.jpg', 'face_77.jpg', 'face4_2762.jpg', 'face4_11051.jpg', 'face4_7892.jpg', 'face3_584.jpg', 'face4_12830.jpg', 'face4_3762.jpg', 'face4_480.jpg', 'face4_8268.jpg', 'face2_654.jpg', 'face4_11702.jpg', 'face4_9848.jpg', 'face4_4097.jpg', 'face4_3119.jpg', 'face3_1047.jpg', 'face4_13488.jpg', 'face_88.jpg', 'face3_483.jpg', 'face4_5062.jpg', 'face4_19.jpg', 'face4_4391.jpg', 'face4_9764.jpg', 'face4_2726.jpg', 'face4_12947.jpg', 'face4_4498.jpg', 'face4_12524.jpg', 'face4_380.jpg', 'face4_6378.jpg', 'face4_2504.jpg', 'face2_649.jpg', 'face4_7772.jpg', 'face4_149.jpg', 'face4_13187.jpg', 'face4_4334.jpg', 'face4_5490.jpg', 'face4_2060.jpg', 'face4_9891.jpg', 'face4_5685.jpg', 'face4_9638.jpg', 'face3_1350.jpg', 'face4_7001.jpg', 'face4_1098.jpg', 'face4_7371.jpg', 'face4_4402.jpg', 'face3_1178.jpg', 'face_141.jpg', 'face3_1370.jpg', 'face4_7575.jpg', 'face4_13143.jpg', 'face4_4859.jpg', 'face4_409.jpg', 'face4_4299.jpg', 'face4_11841.jpg', 'face4_1101.jpg', 'face4_5707.jpg', 'face4_4960.jpg', 'face3_1537.jpg', 'face4_5296.jpg', 'face4_11294.jpg', 'face4_12327.jpg', 'face4_7125.jpg', 'face4_11861.jpg', 'face4_7613.jpg', 'face4_3859.jpg', 'face4_519.jpg', 'face4_1249.jpg', 'face4_5382.jpg', 'face4_1951.jpg', 'face4_9874.jpg', 'face3_150.jpg', 'face4_9536.jpg', 'face4_8206.jpg', 'face4_10901.jpg', 'face4_12258.jpg', 'face3_1117.jpg', 'face4_2755.jpg', 'face4_12594.jpg', 'face4_5970.jpg', 'face4_4016.jpg', 'face4_2638.jpg', 'face4_6494.jpg', 'face4_506.jpg', 'face4_9292.jpg', 'face3_1035.jpg', 'face4_5464.jpg', 'face4_6247.jpg', 'face4_12749.jpg', 'face4_3019.jpg', 'face4_5338.jpg', 'face4_6002.jpg', 'face3_219.jpg', 'face4_9702.jpg', 'face4_4721.jpg', 'face4_4542.jpg', 'face4_11654.jpg', 'face4_3771.jpg', 'face4_10291.jpg', 'face3_1553.jpg', 'face4_956.jpg', 'face4_3210.jpg', 'face4_13358.jpg', 'face3_467.jpg', 'face_120.jpg', 'face_23.jpg', 'face4_12310.jpg', 'face4_10747.jpg', 'face4_7079.jpg', 'face4_2126.jpg', 'face4_5398.jpg', 'face4_12367.jpg', 'face_159.jpg', 'face4_11296.jpg', 'face4_794.jpg', 'face4_6298.jpg', 'face4_293.jpg', 'face4_7631.jpg', 'face4_7869.jpg', 'face4_5468.jpg', 'face3_612.jpg', 'face4_5427.jpg', 'face4_7577.jpg', 'face3_383.jpg', 'face_207.jpg', 'face4_7967.jpg', 'face3_13.jpg', 'face4_4177.jpg', 'face4_4371.jpg', 'face4_232.jpg', 'face4_12287.jpg', 'face4_1843.jpg', 'face4_5331.jpg', 'face4_3085.jpg', 'face4_9655.jpg', 'face4_1681.jpg', 'face4_8633.jpg', 'face4_13160.jpg', 'face4_3476.jpg', 'face4_3191.jpg', 'face4_2891.jpg', 'face4_2267.jpg', 'face3_462.jpg', 'face3_129.jpg', 'face4_8198.jpg', 'face4_6454.jpg', 'face4_7311.jpg', 'face2_658.jpg', 'face4_465.jpg', 'face4_4533.jpg', 'face4_2444.jpg', 'face4_9754.jpg', 'face4_10366.jpg', 'face4_139.jpg', 'face3_910.jpg', 'face4_7664.jpg', 'face4_2295.jpg', 'face4_3427.jpg', 'face4_2860.jpg', 'face_74.jpg', 'face4_5036.jpg', 'face4_4823.jpg', 'face4_11774.jpg', 'face4_12707.jpg', 'face4_4772.jpg', 'face4_6930.jpg', 'face4_235.jpg', 'face4_12802.jpg', 'face3_801.jpg', 'face4_1576.jpg', 'face3_33.jpg', 'face4_2307.jpg', 'face3_896.jpg', 'face4_8997.jpg', 'face4_12872.jpg', 'face4_5727.jpg', 'face4_2310.jpg', 'face4_12814.jpg', 'face4_5920.jpg', 'face3_905.jpg', 'face3_734.jpg', 'face4_12343.jpg', 'face4_6371.jpg', 'face3_1657.jpg', 'face4_10464.jpg', 'face4_2609.jpg', 'face4_3998.jpg', 'face4_6035.jpg', 'face4_5576.jpg', 'face4_6296.jpg', 'face4_1195.jpg', 'face4_11851.jpg', 'face4_8775.jpg', 'face4_9854.jpg', 'face4_12430.jpg', 'face4_4379.jpg', 'face3_1359.jpg', 'face2_40.jpg', 'face4_743.jpg', 'face4_9839.jpg', 'face4_1923.jpg', 'face4_4217.jpg', 'face4_13195.jpg', 'face4_7019.jpg', 'face4_8658.jpg', 'face4_7860.jpg', 'face4_8104.jpg', 'face4_2263.jpg', 'face3_450.jpg', 'face4_9477.jpg', 'face4_11707.jpg', 'face4_4019.jpg', 'face_33.jpg', 'face3_597.jpg', 'face4_1992.jpg', 'face4_5693.jpg', 'face4_3028.jpg', 'face4_8588.jpg', 'face4_4970.jpg', 'face4_248.jpg', 'face4_3149.jpg', 'face4_1910.jpg', 'face3_404.jpg', 'face4_11317.jpg', 'face4_775.jpg', 'face4_6769.jpg', 'face4_12081.jpg', 'face4_7517.jpg', 'face4_7826.jpg', 'face2_842.jpg', 'face4_11428.jpg', 'face4_9861.jpg', 'face4_3345.jpg', 'face4_921.jpg', 'face4_13159.jpg', 'face4_142.jpg', 'face4_1745.jpg', 'face4_7597.jpg', 'face4_9449.jpg', 'face4_12294.jpg', 'face_26.jpg', 'face4_1900.jpg', 'face4_4826.jpg', 'face4_4876.jpg', 'face4_13157.jpg', 'face3_724.jpg', 'face3_1550.jpg', 'face4_8761.jpg', 'face4_9645.jpg', 'face4_6224.jpg', 'face4_7605.jpg', 'face4_2740.jpg', 'face4_5298.jpg', 'face4_4033.jpg', 'face4_4796.jpg', 'face4_7751.jpg', 'face_76.jpg', 'face4_7463.jpg', 'face4_10924.jpg', 'face4_4150.jpg', 'face4_1967.jpg', 'face4_8171.jpg', 'face4_3488.jpg', 'face4_2997.jpg', 'face4_369.jpg', 'face4_2687.jpg', 'face4_4663.jpg', 'face4_7916.jpg', 'face3_25.jpg', 'face4_13166.jpg', 'face4_2932.jpg', 'face2_856.jpg', 'face4_11936.jpg', 'face4_5540.jpg', 'face4_10451.jpg', 'face4_709.jpg', 'face4_2728.jpg', 'face4_9244.jpg', 'face4_13648.jpg', 'face4_2505.jpg', 'face4_2438.jpg', 'face4_8679.jpg', 'face4_8579.jpg', 'face4_1301.jpg', 'face4_9748.jpg', 'face4_7770.jpg', 'face4_4510.jpg', 'face4_9700.jpg', 'face4_11812.jpg', 'face4_5664.jpg', 'face4_11736.jpg', 'face4_1616.jpg', 'face4_11975.jpg', 'face4_8530.jpg', 'face4_7950.jpg', 'face4_11787.jpg', 'face4_10579.jpg', 'face4_12355.jpg', 'face4_874.jpg', 'face4_2646.jpg', 'face4_8544.jpg', 'face4_3992.jpg', 'face4_8583.jpg', 'face3_756.jpg', 'face4_8603.jpg', 'face4_6424.jpg', 'face4_8249.jpg', 'face4_299.jpg', 'face3_846.jpg']\n",
            "Number of files in the subdirectory: 4622\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check the content of the extracted directory\n",
        "extracted_files = os.listdir(output_dir)\n",
        "print(\"Files in the directory:\", extracted_files)\n",
        "\n",
        "# Check if there's a subdirectory and list its contents\n",
        "subdir_path = os.path.join(output_dir, extracted_files[0])\n",
        "if os.path.isdir(subdir_path):\n",
        "    # List files inside the subdirectory\n",
        "    subdir_files = os.listdir(subdir_path)\n",
        "    print(\"Files in the subdirectory:\", subdir_files)\n",
        "    print(\"Number of files in the subdirectory:\", len(subdir_files))\n",
        "\n",
        "    # Select the first image (or any specific image) to display\n",
        "    img_path = os.path.join(subdir_path, subdir_files[0])  # Update the index if necessary\n",
        "\n",
        "    # Open and display the image\n",
        "    image = Image.open(img_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No subdirectory found, please check the structure of the zip file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y0hQVLsObl_",
        "outputId": "346fa91f-56bc-4edf-d522-6981d8ac149d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images found: 4622\n"
          ]
        }
      ],
      "source": [
        "img_dir = output_dir  # This should match the directory where images were extracted\n",
        "\n",
        "# Create dataset class\n",
        "dataset = GirlfriendDataset(subdir_path)\n",
        "\n",
        "print(\"Number of images found:\", len(dataset))\n",
        "\n",
        "# Create dataloader\n",
        "dataloader = DataLoader(dataset,batch_size=4,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AzfkgZvJHRV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32907667-3437-43a3-b82d-4559606c4adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|| 44.7M/44.7M [00:00<00:00, 128MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Old way (deprecated):\n",
        "# model = models.resnet18(pretrained=True)\n",
        "\n",
        "# New way:\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "# Option 1: Using the default weights (latest and recommended)\n",
        "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# Modify the final layer for binary classification\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs,2) # 2 classes as 'girlfriend' and 'not girlfriend'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y4ao7kwiSBAz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class GirlfriendDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.img_names = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = 1  # Assign label 1 to images of Nethmi\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)  # Apply the transform to the image\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8pEXikOSHIK",
        "outputId": "ee8596ac-16e5-40a4-fcc3-276b4f3d2b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "img_dir = 'path_to_extracted_images'  # Replace with the correct directory path\n",
        "dataset = GirlfriendDataset(subdir_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Example: Load a batch to ensure everything is working\n",
        "for inputs, labels in dataloader:\n",
        "    print(inputs.shape)  # Should print a tensor shape like [4, 3, 224, 224]\n",
        "    print(labels)        # Should print the labels, e.g., tensor([1, 1, 1, 1])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TO54y3OsSo2J"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIScM3BVSuv0",
        "outputId": "d8ee6f96-7134-4146-9811-436e6709f9ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.0000\n",
            "Epoch 2/10, Loss: 0.0000\n",
            "Epoch 3/10, Loss: 0.0000\n",
            "Epoch 4/10, Loss: 0.0000\n",
            "Epoch 5/10, Loss: 0.0000\n",
            "Epoch 6/10, Loss: 0.0000\n",
            "Epoch 7/10, Loss: 0.0000\n",
            "Epoch 8/10, Loss: 0.0000\n",
            "Epoch 9/10, Loss: 0.0000\n",
            "Epoch 10/10, Loss: 0.0000\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10  # Set the number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU if available\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Calculate and print the average loss for this epoch\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Debug prints\n",
        "        print(f\"Outputs: {outputs}\")\n",
        "        print(f\"Labels: {labels}\")\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Debug loss value\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqDyhKIsXXl6",
        "outputId": "432153c3-1cca-4cf6-c13d-f7b108d92f43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7969,  6.7704],\n",
            "        [-7.8320,  7.0678],\n",
            "        [-7.5980,  6.6890],\n",
            "        [-7.5147,  6.6943]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.8600,  7.0499],\n",
            "        [-7.6470,  6.8149],\n",
            "        [-7.7823,  6.7722],\n",
            "        [-7.6813,  6.7845]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6107,  6.7549],\n",
            "        [-7.7898,  6.8666],\n",
            "        [-7.8243,  6.9068],\n",
            "        [-7.7654,  6.8786]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8359,  6.8224],\n",
            "        [-7.6741,  6.8523],\n",
            "        [-7.9953,  7.0756],\n",
            "        [-7.7968,  6.9554]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9417,  6.9671],\n",
            "        [-7.7600,  6.9470],\n",
            "        [-7.8518,  6.8796],\n",
            "        [-7.7267,  6.9072]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.5772,  6.5892],\n",
            "        [-7.8293,  7.0049],\n",
            "        [-7.6335,  6.5891],\n",
            "        [-7.5565,  6.8725]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.6383,  6.8173],\n",
            "        [-7.7438,  6.8759],\n",
            "        [-8.0276,  6.8501],\n",
            "        [-7.5382,  6.8246]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6460,  6.8184],\n",
            "        [-7.6287,  6.7699],\n",
            "        [-7.5992,  6.6500],\n",
            "        [-7.7303,  6.8122]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.9304,  6.9217],\n",
            "        [-7.8714,  6.9921],\n",
            "        [-7.8068,  6.8937],\n",
            "        [-7.7103,  6.9175]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.2355,  6.2927],\n",
            "        [-7.7180,  6.9400],\n",
            "        [-7.5207,  6.6491],\n",
            "        [-7.8386,  6.8731]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 7.152553962441743e-07\n",
            "Outputs: tensor([[-7.7709,  6.9303],\n",
            "        [-7.7016,  6.7904],\n",
            "        [-7.8583,  6.7704],\n",
            "        [-7.7690,  7.0421]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8054,  6.8529],\n",
            "        [-7.7711,  6.8193],\n",
            "        [-7.6886,  6.9006],\n",
            "        [-7.7289,  6.8008]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6697,  6.7762],\n",
            "        [-7.6815,  6.8271],\n",
            "        [-7.7858,  6.7775],\n",
            "        [-7.6298,  6.8057]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7611,  6.7432],\n",
            "        [-7.5770,  6.5410],\n",
            "        [-7.5996,  6.8533],\n",
            "        [-7.5218,  6.8017]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662440116793732e-07\n",
            "Outputs: tensor([[-7.8208,  6.9698],\n",
            "        [-7.9415,  7.0198],\n",
            "        [-7.8772,  6.9371],\n",
            "        [-7.7494,  6.8718]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8322,  6.8371],\n",
            "        [-7.8368,  6.8481],\n",
            "        [-7.6692,  6.9819],\n",
            "        [-7.7259,  6.8519]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6209,  6.8489],\n",
            "        [-7.7835,  6.7442],\n",
            "        [-7.8232,  7.0299],\n",
            "        [-7.7628,  6.8068]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7491,  6.8833],\n",
            "        [-7.4932,  6.7645],\n",
            "        [-7.8262,  6.7692],\n",
            "        [-7.7483,  6.8603]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6500,  6.7876],\n",
            "        [-7.5810,  6.6714],\n",
            "        [-7.4843,  6.4509],\n",
            "        [-7.9023,  7.1481]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.6562,  6.8311],\n",
            "        [-7.6845,  6.7782],\n",
            "        [-7.7339,  6.7720],\n",
            "        [-7.6880,  6.8896]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.4321,  6.6637],\n",
            "        [-7.6911,  6.8419],\n",
            "        [-7.8485,  6.7641],\n",
            "        [-7.6422,  6.7879]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.7266,  6.8463],\n",
            "        [-7.6152,  6.7905],\n",
            "        [-7.5509,  7.0126],\n",
            "        [-7.9185,  6.6323]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6737,  6.8813],\n",
            "        [-7.3750,  6.7440],\n",
            "        [-7.8423,  6.7096],\n",
            "        [-7.6028,  6.6244]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.8826,  6.9167],\n",
            "        [-7.8254,  6.8643],\n",
            "        [-7.9080,  7.1225],\n",
            "        [-7.6542,  6.8020]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.4465,  6.6844],\n",
            "        [-7.5381,  6.6859],\n",
            "        [-7.5907,  6.7789],\n",
            "        [-8.1047,  7.0048]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.6985,  6.8204],\n",
            "        [-7.7737,  6.8532],\n",
            "        [-7.9065,  6.9902],\n",
            "        [-7.6715,  6.8582]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8599,  6.8944],\n",
            "        [-7.6816,  6.8589],\n",
            "        [-7.8268,  6.9183],\n",
            "        [-7.7133,  6.8500]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.6123,  6.7073],\n",
            "        [-7.7319,  6.8445],\n",
            "        [-7.8012,  6.9282],\n",
            "        [-7.6731,  6.7864]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7794,  6.7959],\n",
            "        [-7.8876,  7.0598],\n",
            "        [-7.7857,  6.9540],\n",
            "        [-7.9460,  6.9927]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.6488,  6.8959],\n",
            "        [-7.9024,  6.9855],\n",
            "        [-7.8188,  6.8726],\n",
            "        [-7.7283,  6.7753]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6807,  6.7053],\n",
            "        [-7.8958,  6.9421],\n",
            "        [-7.6877,  6.9438],\n",
            "        [-7.8636,  6.9594]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.5614,  6.8410],\n",
            "        [-7.6157,  6.6574],\n",
            "        [-7.7661,  6.8447],\n",
            "        [-7.6811,  6.7370]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.7623,  6.8294],\n",
            "        [-7.8359,  6.9054],\n",
            "        [-7.7614,  6.8967],\n",
            "        [-7.6654,  6.8367]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.5287,  6.6775],\n",
            "        [-7.8863,  6.8681],\n",
            "        [-7.5399,  6.8210],\n",
            "        [-7.8219,  6.7808]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.7918,  6.8199],\n",
            "        [-7.8605,  7.0074],\n",
            "        [-7.8708,  6.9578],\n",
            "        [-7.7612,  6.9036]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6538,  6.7321],\n",
            "        [-7.6194,  6.7305],\n",
            "        [-7.7052,  6.9618],\n",
            "        [-7.5644,  6.5946]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.3995,  6.6747],\n",
            "        [-7.8332,  6.8989],\n",
            "        [-7.4189,  6.6351],\n",
            "        [-7.6254,  6.6124]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 6.258485427679261e-07\n",
            "Outputs: tensor([[-7.8241,  6.8170],\n",
            "        [-7.7645,  7.0010],\n",
            "        [-7.5264,  6.7322],\n",
            "        [-7.6949,  6.7091]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7728,  6.9864],\n",
            "        [-7.7534,  6.8822],\n",
            "        [-7.7631,  6.8277],\n",
            "        [-7.5576,  6.6257]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6366,  6.8048],\n",
            "        [-7.8031,  6.6507],\n",
            "        [-7.6357,  6.8016],\n",
            "        [-7.5657,  6.8410]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.7163,  6.8583],\n",
            "        [-7.7409,  6.7551],\n",
            "        [-7.5800,  6.8158],\n",
            "        [-7.7318,  6.7834]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7008,  6.8677],\n",
            "        [-7.4862,  6.6005],\n",
            "        [-7.7824,  6.9868],\n",
            "        [-7.9601,  6.9016]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.6217,  6.7571],\n",
            "        [-7.8827,  6.7804],\n",
            "        [-7.4401,  6.7466],\n",
            "        [-7.7643,  6.8925]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.6947,  6.8730],\n",
            "        [-7.7804,  6.9525],\n",
            "        [-7.5850,  6.6173],\n",
            "        [-7.8615,  6.9404]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.8458,  6.9603],\n",
            "        [-7.6984,  6.8819],\n",
            "        [-7.8851,  6.9654],\n",
            "        [-7.9476,  6.9941]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7185,  6.9054],\n",
            "        [-7.7534,  6.7383],\n",
            "        [-7.8625,  6.8769],\n",
            "        [-7.6488,  6.8478]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.6806,  6.9006],\n",
            "        [-7.6382,  6.7028],\n",
            "        [-7.6933,  6.7273],\n",
            "        [-7.6016,  6.8252]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662440116793732e-07\n",
            "Outputs: tensor([[-7.6848,  6.5847],\n",
            "        [-7.6217,  6.8079],\n",
            "        [-7.3881,  6.7358],\n",
            "        [-7.8455,  6.8794]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.8252,  6.9728],\n",
            "        [-7.8306,  6.8228],\n",
            "        [-7.8040,  6.9572],\n",
            "        [-7.7865,  6.9194]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7404,  6.9642],\n",
            "        [-7.7221,  6.9794],\n",
            "        [-7.5646,  6.4202],\n",
            "        [-7.7786,  6.8872]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393100605637e-07\n",
            "Outputs: tensor([[-7.6281,  6.7076],\n",
            "        [-7.8430,  7.0163],\n",
            "        [-7.7101,  6.8258],\n",
            "        [-7.7322,  6.7719]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9353,  6.9448],\n",
            "        [-7.5339,  6.7255],\n",
            "        [-7.8544,  6.9459],\n",
            "        [-7.8412,  7.0053]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7189,  6.8514],\n",
            "        [-7.6600,  6.9775],\n",
            "        [-7.9151,  6.9091],\n",
            "        [-7.9798,  6.9828]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8920,  6.9170],\n",
            "        [-7.6543,  6.8481],\n",
            "        [-7.7415,  6.8286],\n",
            "        [-7.8251,  6.9697]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7747,  6.8624],\n",
            "        [-7.5355,  6.8892],\n",
            "        [-7.7436,  6.8674],\n",
            "        [-7.8855,  6.7777]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-8.1014,  6.9845],\n",
            "        [-7.5397,  7.0492],\n",
            "        [-7.8639,  6.8838],\n",
            "        [-7.7143,  6.7545]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8492,  6.9315],\n",
            "        [-7.6861,  6.9041],\n",
            "        [-7.9167,  6.8904],\n",
            "        [-7.7752,  6.9601]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8943,  6.8791],\n",
            "        [-7.5486,  6.7873],\n",
            "        [-7.5964,  6.5227],\n",
            "        [-7.4338,  6.7560]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.7040,  6.9062],\n",
            "        [-7.9151,  7.0042],\n",
            "        [-7.8625,  6.8631],\n",
            "        [-7.9077,  7.0138]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7516,  6.8984],\n",
            "        [-7.8716,  6.9237],\n",
            "        [-7.7473,  6.8544],\n",
            "        [-7.7493,  6.8933]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8474,  6.8855],\n",
            "        [-7.6643,  6.8616],\n",
            "        [-7.8656,  6.8082],\n",
            "        [-7.6978,  6.9544]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.8574,  6.8871],\n",
            "        [-7.7642,  7.0052],\n",
            "        [-7.7887,  6.8857],\n",
            "        [-7.8467,  6.8885]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7896,  6.9567],\n",
            "        [-7.8146,  6.8268],\n",
            "        [-7.6064,  6.8395],\n",
            "        [-7.8974,  6.9438]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8282,  6.8397],\n",
            "        [-7.8170,  6.8565],\n",
            "        [-7.7795,  6.8716],\n",
            "        [-7.8326,  7.1598]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.6531,  6.7355],\n",
            "        [-7.6864,  6.7918],\n",
            "        [-7.7526,  6.8019],\n",
            "        [-7.7848,  6.9654]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6550,  6.8201],\n",
            "        [-7.7659,  6.9073],\n",
            "        [-7.9052,  6.8922],\n",
            "        [-7.6019,  6.6846]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.5362,  6.6289],\n",
            "        [-7.7021,  6.6543],\n",
            "        [-7.6895,  6.9648],\n",
            "        [-7.5060,  6.6181]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 6.25848599611345e-07\n",
            "Outputs: tensor([[-7.7793,  6.9189],\n",
            "        [-7.7651,  6.8412],\n",
            "        [-7.7240,  6.7853],\n",
            "        [-7.7578,  6.8809]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6552,  6.7881],\n",
            "        [-7.5429,  6.8140],\n",
            "        [-7.9470,  7.0811],\n",
            "        [-7.9544,  6.8628]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6037,  6.7045],\n",
            "        [-7.7265,  6.7410],\n",
            "        [-7.6257,  6.6714],\n",
            "        [-7.5686,  6.8859]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.8430,  7.0036],\n",
            "        [-7.7886,  6.9091],\n",
            "        [-7.7409,  6.8626],\n",
            "        [-7.5640,  6.6088]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7338,  6.8556],\n",
            "        [-7.8611,  7.0598],\n",
            "        [-7.6524,  6.7378],\n",
            "        [-7.7166,  6.7004]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8194,  6.8603],\n",
            "        [-7.9353,  6.9411],\n",
            "        [-7.7524,  6.9648],\n",
            "        [-7.7229,  6.8564]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8069,  6.8925],\n",
            "        [-7.9043,  7.0543],\n",
            "        [-7.8283,  6.9372],\n",
            "        [-7.7709,  6.8594]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7830,  6.7643],\n",
            "        [-7.8889,  7.0247],\n",
            "        [-7.6694,  6.8962],\n",
            "        [-7.9446,  7.0230]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.5788,  6.6600],\n",
            "        [-7.9487,  6.9915],\n",
            "        [-7.7382,  6.8367],\n",
            "        [-7.7057,  6.9048]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6914,  6.9491],\n",
            "        [-7.7238,  7.0750],\n",
            "        [-7.7574,  6.8349],\n",
            "        [-7.8406,  6.5577]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7056,  6.8778],\n",
            "        [-7.7002,  6.8361],\n",
            "        [-7.5713,  6.6777],\n",
            "        [-7.7403,  6.8082]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7058,  6.8819],\n",
            "        [-7.7876,  6.7934],\n",
            "        [-7.4466,  6.7847],\n",
            "        [-7.9877,  6.9536]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.5196,  6.8611],\n",
            "        [-7.9024,  6.8608],\n",
            "        [-7.7916,  6.8202],\n",
            "        [-7.7214,  6.8348]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7819,  6.8948],\n",
            "        [-8.0813,  7.0735],\n",
            "        [-7.6958,  6.8385],\n",
            "        [-7.6565,  6.8403]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9017,  6.7683],\n",
            "        [-7.6110,  6.9374],\n",
            "        [-7.7913,  6.9470],\n",
            "        [-7.8692,  6.9529]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8553,  6.9224],\n",
            "        [-7.8404,  6.9745],\n",
            "        [-7.8336,  6.8494],\n",
            "        [-7.7490,  6.9655]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8795,  6.9744],\n",
            "        [-7.7897,  6.8747],\n",
            "        [-7.7681,  6.7146],\n",
            "        [-7.5754,  6.8525]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6871,  6.9232],\n",
            "        [-7.8831,  6.9788],\n",
            "        [-7.6951,  6.8077],\n",
            "        [-7.9472,  6.9726]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8458,  6.8773],\n",
            "        [-7.5225,  6.7512],\n",
            "        [-7.8103,  6.8798],\n",
            "        [-7.9533,  7.0773]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8583,  7.0135],\n",
            "        [-7.7583,  6.9189],\n",
            "        [-7.8794,  6.8989],\n",
            "        [-7.8093,  6.8950]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.5529,  6.7981],\n",
            "        [-7.6796,  6.6461],\n",
            "        [-7.6713,  6.9536],\n",
            "        [-7.5879,  6.5808]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.8949,  6.8156],\n",
            "        [-7.7669,  6.9172],\n",
            "        [-7.7275,  7.0102],\n",
            "        [-7.3887,  6.5626]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7625,  7.0925],\n",
            "        [-7.7060,  6.7556],\n",
            "        [-7.4277,  6.5438],\n",
            "        [-7.9158,  6.9366]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7115,  6.9056],\n",
            "        [-7.9332,  6.8572],\n",
            "        [-7.6693,  6.8869],\n",
            "        [-7.8126,  6.8960]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7601,  6.6489],\n",
            "        [-7.5419,  6.7924],\n",
            "        [-7.3658,  6.8460],\n",
            "        [-7.8402,  6.6814]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.6357,  6.7061],\n",
            "        [-7.7611,  6.8455],\n",
            "        [-7.5557,  6.8063],\n",
            "        [-7.8362,  6.9278]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.4461,  6.5921],\n",
            "        [-7.9639,  6.9153],\n",
            "        [-7.7191,  6.9139],\n",
            "        [-7.7865,  6.9220]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.5574,  6.7947],\n",
            "        [-7.8386,  6.9348],\n",
            "        [-7.8972,  6.9935],\n",
            "        [-7.9104,  6.8635]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.1723239974089665e-07\n",
            "Outputs: tensor([[-7.8570,  6.8353],\n",
            "        [-7.4223,  6.7800],\n",
            "        [-7.7375,  6.7039],\n",
            "        [-7.4660,  6.5710]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.7683,  6.8832],\n",
            "        [-7.9581,  6.9521],\n",
            "        [-7.6507,  6.8116],\n",
            "        [-7.8325,  6.9911]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9522,  7.0366],\n",
            "        [-7.8618,  6.9733],\n",
            "        [-7.8852,  6.9297],\n",
            "        [-7.6222,  6.8133]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7738,  6.9001],\n",
            "        [-7.6999,  6.7956],\n",
            "        [-7.6671,  6.8300],\n",
            "        [-7.8515,  6.9733]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.9361,  6.9719],\n",
            "        [-7.1582,  6.4447],\n",
            "        [-7.9533,  7.0517],\n",
            "        [-7.9062,  6.9350]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.5527,  6.5647],\n",
            "        [-7.9614,  7.0023],\n",
            "        [-7.4799,  6.6960],\n",
            "        [-7.5673,  6.7355]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.8955,  6.9777],\n",
            "        [-7.8072,  6.8724],\n",
            "        [-8.0180,  7.0087],\n",
            "        [-7.5590,  6.8497]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7597,  6.9563],\n",
            "        [-7.7319,  6.8734],\n",
            "        [-7.6569,  6.6046],\n",
            "        [-7.8059,  6.9956]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703477897201083e-07\n",
            "Outputs: tensor([[-7.9189,  6.9863],\n",
            "        [-7.8504,  7.0199],\n",
            "        [-7.9048,  7.0008],\n",
            "        [-7.8646,  6.9248]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9694,  6.9414],\n",
            "        [-7.5838,  6.8014],\n",
            "        [-7.9298,  7.0494],\n",
            "        [-7.6145,  6.7487]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8704,  6.8064],\n",
            "        [-7.8906,  6.8384],\n",
            "        [-7.5940,  6.9265],\n",
            "        [-7.7052,  6.9231]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8572,  6.9074],\n",
            "        [-7.7010,  6.8749],\n",
            "        [-7.8977,  6.9245],\n",
            "        [-7.6851,  6.9022]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7365,  6.8552],\n",
            "        [-7.6525,  6.7183],\n",
            "        [-7.4037,  6.7682],\n",
            "        [-7.6248,  6.5995]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 6.258485427679261e-07\n",
            "Outputs: tensor([[-7.8537,  6.9600],\n",
            "        [-7.9391,  7.0344],\n",
            "        [-7.7465,  6.7864],\n",
            "        [-7.8209,  6.9797]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.6229,  6.8347],\n",
            "        [-7.6658,  6.8167],\n",
            "        [-7.7621,  6.8198],\n",
            "        [-7.8345,  6.8653]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.5406,  6.8287],\n",
            "        [-7.6369,  6.7338],\n",
            "        [-7.9332,  6.9280],\n",
            "        [-7.9320,  6.9448]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8201,  6.9579],\n",
            "        [-7.8117,  6.8510],\n",
            "        [-7.9619,  6.8997],\n",
            "        [-7.5866,  6.9116]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9217,  7.0115],\n",
            "        [-7.9031,  6.9905],\n",
            "        [-7.8873,  6.9975],\n",
            "        [-7.8606,  6.9815]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7392,  6.9016],\n",
            "        [-7.8646,  6.9595],\n",
            "        [-7.8811,  7.0152],\n",
            "        [-7.8507,  6.8877]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.3256,  6.4341],\n",
            "        [-7.6428,  6.8471],\n",
            "        [-8.1303,  6.9710],\n",
            "        [-7.3272,  6.5891]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 6.854531306998979e-07\n",
            "Outputs: tensor([[-7.6526,  6.7566],\n",
            "        [-7.7121,  6.7844],\n",
            "        [-7.8820,  7.0190],\n",
            "        [-7.8110,  6.9648]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.5599,  6.7097],\n",
            "        [-7.7689,  6.8621],\n",
            "        [-7.4845,  6.6672],\n",
            "        [-7.9595,  6.9621]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.36441632448259e-07\n",
            "Outputs: tensor([[-7.7469,  6.9763],\n",
            "        [-7.8468,  6.9706],\n",
            "        [-7.8095,  6.7813],\n",
            "        [-7.6745,  6.8146]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8236,  6.8196],\n",
            "        [-7.6895,  6.8923],\n",
            "        [-7.6146,  6.8008],\n",
            "        [-7.7387,  6.8425]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8001,  6.9229],\n",
            "        [-7.8525,  6.9346],\n",
            "        [-7.8138,  6.9319],\n",
            "        [-7.8512,  6.9432]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6561,  6.8933],\n",
            "        [-7.6088,  6.8784],\n",
            "        [-7.9160,  6.6399],\n",
            "        [-7.6030,  6.7824]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8188,  6.8768],\n",
            "        [-7.9710,  7.0732],\n",
            "        [-7.9049,  6.8978],\n",
            "        [-7.7179,  6.9944]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9709,  7.0046],\n",
            "        [-7.6147,  6.7785],\n",
            "        [-7.5395,  6.8835],\n",
            "        [-7.8165,  6.7407]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7392,  6.7904],\n",
            "        [-7.7918,  6.9392],\n",
            "        [-7.5646,  6.8162],\n",
            "        [-7.7129,  6.7818]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7340,  6.6368],\n",
            "        [-7.7379,  7.0217],\n",
            "        [-7.7704,  6.8895],\n",
            "        [-7.6809,  6.8001]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8846,  6.8768],\n",
            "        [-7.8786,  6.9355],\n",
            "        [-7.9054,  6.8940],\n",
            "        [-7.6604,  7.0064]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8696,  7.0095],\n",
            "        [-7.6085,  6.7460],\n",
            "        [-7.8412,  6.9350],\n",
            "        [-7.7110,  6.7938]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6164,  6.9046],\n",
            "        [-7.6658,  6.7894],\n",
            "        [-7.8886,  6.8880],\n",
            "        [-7.6899,  6.7271]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6759,  6.6885],\n",
            "        [-7.7547,  6.8710],\n",
            "        [-7.6167,  6.8381],\n",
            "        [-7.7514,  6.8417]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6506,  6.6327],\n",
            "        [-7.8825,  6.9011],\n",
            "        [-7.5569,  6.8705],\n",
            "        [-7.7833,  6.9026]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7910,  6.7789],\n",
            "        [-7.7884,  6.8885],\n",
            "        [-7.7687,  6.9484],\n",
            "        [-7.7862,  6.9274]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6212,  6.6661],\n",
            "        [-7.7467,  6.7565],\n",
            "        [-7.8261,  7.0579],\n",
            "        [-7.7156,  6.8664]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7290,  6.9287],\n",
            "        [-7.9131,  7.0032],\n",
            "        [-7.8332,  6.9252],\n",
            "        [-7.7984,  6.8305]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7596,  6.9424],\n",
            "        [-7.7033,  6.8935],\n",
            "        [-7.7799,  6.6090],\n",
            "        [-7.5593,  6.7849]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6120,  6.8580],\n",
            "        [-7.9196,  6.9716],\n",
            "        [-8.0131,  6.9944],\n",
            "        [-7.6840,  6.8374]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7738,  6.6603],\n",
            "        [-7.7061,  6.8902],\n",
            "        [-7.6294,  6.7958],\n",
            "        [-7.5571,  6.7984]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.5135,  6.9391],\n",
            "        [-7.7499,  6.7935],\n",
            "        [-7.8130,  7.0352],\n",
            "        [-7.8437,  6.6135]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8709,  6.8462],\n",
            "        [-7.7995,  6.8374],\n",
            "        [-7.7859,  6.9666],\n",
            "        [-7.7166,  6.9181]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7173,  6.7691],\n",
            "        [-7.8943,  7.0281],\n",
            "        [-7.7325,  6.7988],\n",
            "        [-7.4955,  6.7192]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.4284,  6.7791],\n",
            "        [-8.0767,  6.9498],\n",
            "        [-7.7210,  6.8430],\n",
            "        [-7.6620,  6.8076]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9686,  7.0949],\n",
            "        [-7.8650,  6.9334],\n",
            "        [-7.9889,  7.0257],\n",
            "        [-7.7371,  6.9324]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7745,  6.7834],\n",
            "        [-7.7928,  7.0912],\n",
            "        [-7.5621,  6.7789],\n",
            "        [-7.8369,  6.7959]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7852,  6.8563],\n",
            "        [-7.6836,  6.7865],\n",
            "        [-8.0028,  7.1542],\n",
            "        [-7.7454,  6.8713]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8580,  6.8524],\n",
            "        [-7.8764,  6.9496],\n",
            "        [-7.8455,  6.9771],\n",
            "        [-7.7171,  6.9614]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.6472,  6.7434],\n",
            "        [-7.7927,  6.8803],\n",
            "        [-7.7709,  6.8049],\n",
            "        [-7.7630,  6.9745]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8301,  6.9187],\n",
            "        [-7.8213,  6.9208],\n",
            "        [-7.7102,  6.8505],\n",
            "        [-7.6504,  6.7068]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.8798,  6.9958],\n",
            "        [-7.7094,  6.8474],\n",
            "        [-7.6867,  6.6631],\n",
            "        [-7.7676,  6.9527]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703477897201083e-07\n",
            "Outputs: tensor([[-7.7640,  6.8554],\n",
            "        [-7.7122,  6.8339],\n",
            "        [-7.9223,  6.8463],\n",
            "        [-7.7814,  7.0557]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8437,  6.7606],\n",
            "        [-7.7829,  6.9358],\n",
            "        [-7.8026,  6.9051],\n",
            "        [-7.6085,  6.9182]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7247,  6.7251],\n",
            "        [-7.7848,  6.8549],\n",
            "        [-7.5878,  6.7257],\n",
            "        [-7.7901,  6.9820]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.8345,  6.8351],\n",
            "        [-7.6754,  6.8668],\n",
            "        [-7.7750,  6.9415],\n",
            "        [-8.0949,  7.1671]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.6440,  6.8053],\n",
            "        [-7.9310,  6.9980],\n",
            "        [-7.8739,  6.9255],\n",
            "        [-7.9267,  7.0932]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.5231,  6.6768],\n",
            "        [-7.8334,  6.8792],\n",
            "        [-7.8747,  7.0016],\n",
            "        [-7.6563,  6.8160]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9593,  7.0658],\n",
            "        [-7.7618,  6.8438],\n",
            "        [-7.8869,  7.0653],\n",
            "        [-7.7409,  6.8400]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8813,  6.8721],\n",
            "        [-7.9090,  7.0756],\n",
            "        [-7.9043,  6.9084],\n",
            "        [-7.6593,  6.8981]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8211,  6.9617],\n",
            "        [-7.6762,  6.8985],\n",
            "        [-7.8706,  6.8914],\n",
            "        [-7.8035,  6.8511]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8081,  6.7980],\n",
            "        [-7.6322,  6.9392],\n",
            "        [-7.7579,  6.8174],\n",
            "        [-7.7594,  6.8474]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.5983,  6.7888],\n",
            "        [-7.9666,  7.0731],\n",
            "        [-8.0171,  7.0803],\n",
            "        [-7.9494,  7.0351]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7944,  6.9201],\n",
            "        [-7.8401,  6.9175],\n",
            "        [-7.7987,  6.8760],\n",
            "        [-7.8451,  6.9544]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8999,  6.9614],\n",
            "        [-7.8005,  6.8894],\n",
            "        [-7.7200,  6.9605],\n",
            "        [-7.8639,  6.9272]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0029,  7.0881],\n",
            "        [-7.9220,  7.0248],\n",
            "        [-7.7996,  6.9432],\n",
            "        [-7.7380,  6.8572]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7360,  6.8222],\n",
            "        [-7.8276,  6.9723],\n",
            "        [-7.8797,  6.8275],\n",
            "        [-7.8829,  7.1238]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9854,  6.9515],\n",
            "        [-7.8265,  6.9498],\n",
            "        [-7.7826,  6.8830],\n",
            "        [-7.8378,  7.0906]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7844,  6.9474],\n",
            "        [-7.7185,  6.9117],\n",
            "        [-7.8475,  6.8841],\n",
            "        [-7.8797,  6.9109]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7411,  6.8372],\n",
            "        [-7.7179,  6.7247],\n",
            "        [-7.7407,  6.8827],\n",
            "        [-7.8055,  6.9627]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8598,  6.8778],\n",
            "        [-7.9744,  7.0997],\n",
            "        [-7.7674,  6.9535],\n",
            "        [-7.8063,  6.9151]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8064,  6.8436],\n",
            "        [-7.7447,  6.8530],\n",
            "        [-7.9044,  7.0404],\n",
            "        [-7.6965,  6.9107]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7149,  6.8214],\n",
            "        [-7.5223,  6.4720],\n",
            "        [-7.6482,  6.8113],\n",
            "        [-7.7354,  6.9244]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.8727,  6.7950],\n",
            "        [-7.5585,  6.7203],\n",
            "        [-7.7228,  7.0230],\n",
            "        [-7.8631,  6.9579]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.5430,  6.6548],\n",
            "        [-7.8550,  6.9682],\n",
            "        [-7.9781,  7.0507],\n",
            "        [-7.8538,  6.9850]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.1723239974089665e-07\n",
            "Outputs: tensor([[-7.8603,  6.9980],\n",
            "        [-7.8966,  6.9116],\n",
            "        [-7.5011,  6.6340],\n",
            "        [-7.5928,  6.7634]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8376,  6.9968],\n",
            "        [-7.7581,  6.7556],\n",
            "        [-7.7444,  6.9276],\n",
            "        [-7.7650,  6.8461]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-8.0497,  7.2096],\n",
            "        [-7.7336,  6.7405],\n",
            "        [-7.7947,  6.8244],\n",
            "        [-7.8113,  7.0426]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7663,  6.8901],\n",
            "        [-7.9234,  6.9548],\n",
            "        [-7.7230,  7.0395],\n",
            "        [-7.7356,  6.7822]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8720,  7.0485],\n",
            "        [-7.8145,  6.7817],\n",
            "        [-7.7737,  6.7834],\n",
            "        [-7.6968,  6.9689]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6060,  6.7495],\n",
            "        [-7.8443,  6.7050],\n",
            "        [-7.5851,  6.7543],\n",
            "        [-7.9729,  7.1717]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7352,  6.9978],\n",
            "        [-7.7701,  6.9833],\n",
            "        [-7.7598,  6.7955],\n",
            "        [-7.8297,  6.7628]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8982,  6.8874],\n",
            "        [-7.8364,  6.7887],\n",
            "        [-7.5333,  6.8808],\n",
            "        [-7.6722,  6.8385]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7937,  6.9780],\n",
            "        [-7.7699,  6.7184],\n",
            "        [-7.7442,  6.9020],\n",
            "        [-7.5966,  6.7526]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6165,  6.8937],\n",
            "        [-7.7920,  6.9110],\n",
            "        [-7.7986,  6.9966],\n",
            "        [-7.8983,  6.7673]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7416,  6.9090],\n",
            "        [-7.6392,  6.7029],\n",
            "        [-7.9340,  6.9939],\n",
            "        [-7.7114,  6.9004]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9677,  7.0069],\n",
            "        [-7.8027,  7.0698],\n",
            "        [-7.4197,  6.5798],\n",
            "        [-7.6308,  6.6927]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.36441632448259e-07\n",
            "Outputs: tensor([[-7.7400,  6.9157],\n",
            "        [-7.5985,  6.8084],\n",
            "        [-7.7288,  6.8598],\n",
            "        [-8.0077,  6.9722]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.7640,  6.7890],\n",
            "        [-7.8455,  6.9755],\n",
            "        [-7.5427,  6.6343],\n",
            "        [-7.7075,  6.8488]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6010,  6.7523],\n",
            "        [-7.7080,  6.7954],\n",
            "        [-7.9105,  6.9980],\n",
            "        [-7.8206,  6.9555]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.8031,  7.0556],\n",
            "        [-7.9608,  6.9010],\n",
            "        [-7.6326,  6.8487],\n",
            "        [-7.9114,  6.9615]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.5985,  6.7800],\n",
            "        [-8.0517,  6.9686],\n",
            "        [-7.6993,  6.8697],\n",
            "        [-7.6457,  6.8319]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7741,  6.8513],\n",
            "        [-7.6675,  6.9595],\n",
            "        [-7.6177,  6.8901],\n",
            "        [-7.9468,  6.7402]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9708,  7.0040],\n",
            "        [-7.8182,  6.9083],\n",
            "        [-7.8449,  7.0304],\n",
            "        [-7.8275,  6.9434]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.4560,  6.8814],\n",
            "        [-7.7955,  6.8982],\n",
            "        [-7.9804,  6.9025],\n",
            "        [-7.8281,  6.8758]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.1723239974089665e-07\n",
            "Outputs: tensor([[-7.7587,  6.8820],\n",
            "        [-7.8478,  6.9237],\n",
            "        [-7.8547,  7.0958],\n",
            "        [-7.7739,  6.7676]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9364,  7.0183],\n",
            "        [-7.7167,  6.9801],\n",
            "        [-7.7757,  6.8779],\n",
            "        [-7.7655,  6.8328]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7765,  6.8839],\n",
            "        [-7.6160,  7.0086],\n",
            "        [-7.7596,  6.6777],\n",
            "        [-7.9469,  6.9673]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.8506,  7.0527],\n",
            "        [-8.0311,  7.0960],\n",
            "        [-7.8683,  6.9620],\n",
            "        [-7.8625,  6.9304]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8548,  6.8842],\n",
            "        [-7.8063,  6.8776],\n",
            "        [-7.8342,  7.1178],\n",
            "        [-7.9242,  6.9837]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8238,  7.0162],\n",
            "        [-7.6749,  6.9594],\n",
            "        [-7.9039,  6.8727],\n",
            "        [-7.9736,  6.9494]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7533,  6.9775],\n",
            "        [-7.6239,  6.9076],\n",
            "        [-8.0746,  6.9721],\n",
            "        [-7.5639,  6.6389]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.8723,  7.0573],\n",
            "        [-7.7293,  6.7265],\n",
            "        [-7.6991,  6.6891],\n",
            "        [-7.6416,  6.9378]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-8.1291,  7.0435],\n",
            "        [-7.7513,  6.8861],\n",
            "        [-7.7346,  6.8531],\n",
            "        [-7.8327,  7.0932]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.6840,  6.7859],\n",
            "        [-7.0102,  6.3830],\n",
            "        [-7.6031,  6.2375],\n",
            "        [-7.6097,  6.9676]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 8.642668944958132e-07\n",
            "Outputs: tensor([[-7.8308,  6.9222],\n",
            "        [-7.6430,  6.8214],\n",
            "        [-7.8106,  6.9337],\n",
            "        [-7.8810,  7.0051]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9555,  7.0148],\n",
            "        [-7.8882,  6.9823],\n",
            "        [-7.7827,  6.8676],\n",
            "        [-7.7172,  6.8807]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9934,  7.0387],\n",
            "        [-7.6839,  6.7835],\n",
            "        [-7.8764,  6.9638],\n",
            "        [-7.6150,  6.8029]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8484,  6.9391],\n",
            "        [-7.8586,  6.9141],\n",
            "        [-7.7834,  6.9436],\n",
            "        [-7.8103,  6.9451]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9009,  6.9969],\n",
            "        [-7.8857,  7.0016],\n",
            "        [-7.6818,  6.6553],\n",
            "        [-7.7216,  6.9891]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7992,  6.8271],\n",
            "        [-7.7680,  7.0256],\n",
            "        [-7.9563,  6.9057],\n",
            "        [-7.7111,  6.9008]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8061,  7.0092],\n",
            "        [-7.8353,  6.8507],\n",
            "        [-7.9231,  6.9002],\n",
            "        [-7.7442,  6.9717]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9182,  7.0052],\n",
            "        [-7.8198,  6.9187],\n",
            "        [-7.7988,  6.8933],\n",
            "        [-7.7383,  6.9018]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8540,  6.8913],\n",
            "        [-7.7498,  6.9843],\n",
            "        [-7.7295,  6.9457],\n",
            "        [-7.7171,  6.7028]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.9214,  6.9892],\n",
            "        [-7.5928,  6.7663],\n",
            "        [-7.7706,  6.8997],\n",
            "        [-7.6310,  6.7934]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7431,  6.6954],\n",
            "        [-7.9874,  6.9623],\n",
            "        [-7.4670,  6.6582],\n",
            "        [-7.9110,  7.3000]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7443,  6.8864],\n",
            "        [-7.6110,  6.7415],\n",
            "        [-7.6475,  6.9070],\n",
            "        [-7.8714,  6.8294]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.7712,  6.9044],\n",
            "        [-7.9688,  6.9090],\n",
            "        [-7.6099,  6.8469],\n",
            "        [-7.5777,  6.6959]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8668,  7.0120],\n",
            "        [-7.8279,  6.9612],\n",
            "        [-8.0440,  7.0895],\n",
            "        [-7.8550,  6.9503]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9640,  7.0955],\n",
            "        [-7.7844,  6.9834],\n",
            "        [-7.7674,  6.8513],\n",
            "        [-7.8603,  6.9052]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8283,  6.8652],\n",
            "        [-7.8431,  7.0598],\n",
            "        [-7.7481,  6.8420],\n",
            "        [-7.7372,  6.8513]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7723,  6.9318],\n",
            "        [-8.0106,  7.1531],\n",
            "        [-7.8714,  6.8832],\n",
            "        [-7.8182,  6.9518]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6988,  6.7735],\n",
            "        [-7.4744,  6.6406],\n",
            "        [-7.7750,  6.9067],\n",
            "        [-7.9814,  7.0511]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7804,  6.7766],\n",
            "        [-7.8514,  7.0096],\n",
            "        [-7.5982,  6.8752],\n",
            "        [-7.9394,  6.9688]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7278,  6.9270],\n",
            "        [-7.6989,  6.7892],\n",
            "        [-7.8553,  6.9050],\n",
            "        [-7.9193,  7.0296]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.5896,  6.9220],\n",
            "        [-7.7194,  6.8143],\n",
            "        [-7.8844,  7.1450],\n",
            "        [-7.6865,  6.4592]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8270,  6.8222],\n",
            "        [-7.6828,  6.8982],\n",
            "        [-7.7757,  6.9778],\n",
            "        [-7.8646,  6.8563]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7806,  6.8593],\n",
            "        [-7.7283,  6.9101],\n",
            "        [-7.6803,  6.8380],\n",
            "        [-7.8823,  6.9128]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7923,  6.8815],\n",
            "        [-7.8964,  7.0827],\n",
            "        [-7.8471,  7.0218],\n",
            "        [-7.8200,  6.8216]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8226,  6.8723],\n",
            "        [-7.8009,  6.8241],\n",
            "        [-7.9869,  7.1593],\n",
            "        [-7.7076,  6.9227]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9677,  6.9972],\n",
            "        [-7.6249,  6.7913],\n",
            "        [-7.9516,  6.9787],\n",
            "        [-7.7732,  6.9885]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.6604,  6.8554],\n",
            "        [-7.5471,  6.6043],\n",
            "        [-7.6638,  6.9311],\n",
            "        [-8.1436,  7.0972]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8515,  6.9945],\n",
            "        [-7.9019,  6.9762],\n",
            "        [-7.8400,  6.9448],\n",
            "        [-7.7788,  6.9032]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9215,  7.0173],\n",
            "        [-7.8142,  6.9011],\n",
            "        [-7.7933,  6.8458],\n",
            "        [-7.6574,  6.9149]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8521,  6.9795],\n",
            "        [-8.0817,  6.9858],\n",
            "        [-7.7206,  7.0452],\n",
            "        [-7.8163,  6.9104]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8546,  7.1141],\n",
            "        [-7.7473,  6.7269],\n",
            "        [-7.6135,  6.8487],\n",
            "        [-7.7710,  6.7546]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6626,  6.8427],\n",
            "        [-7.6839,  6.8481],\n",
            "        [-7.8620,  6.8409],\n",
            "        [-7.8935,  6.9492]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9190,  6.9949],\n",
            "        [-7.7770,  6.9067],\n",
            "        [-7.6463,  6.7700],\n",
            "        [-7.8572,  6.9769]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703477897201083e-07\n",
            "Outputs: tensor([[-7.8763,  7.0950],\n",
            "        [-7.7273,  6.9012],\n",
            "        [-7.9158,  6.9287],\n",
            "        [-7.9042,  6.9838]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.6339,  6.8197],\n",
            "        [-7.8729,  6.8766],\n",
            "        [-7.7031,  6.9226],\n",
            "        [-7.8375,  6.9272]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9461,  6.9314],\n",
            "        [-7.5649,  6.8552],\n",
            "        [-7.9828,  6.8828],\n",
            "        [-7.7765,  7.0225]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.6674,  6.8867],\n",
            "        [-7.8624,  6.7466],\n",
            "        [-7.8946,  7.0395],\n",
            "        [-7.7352,  6.9334]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7544,  6.8649],\n",
            "        [-7.8835,  6.9613],\n",
            "        [-7.8114,  7.0640],\n",
            "        [-8.0031,  7.0104]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-8.1236,  7.1254],\n",
            "        [-7.6836,  6.6763],\n",
            "        [-7.7529,  6.9611],\n",
            "        [-7.6302,  6.8496]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8968,  6.6529],\n",
            "        [-7.7599,  6.9793],\n",
            "        [-7.6644,  6.9407],\n",
            "        [-7.7622,  6.9185]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.9220,  7.0425],\n",
            "        [-7.7907,  6.9108],\n",
            "        [-7.7327,  6.8871],\n",
            "        [-7.8003,  6.8607]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9232,  7.0140],\n",
            "        [-7.7225,  6.7533],\n",
            "        [-7.9980,  7.1564],\n",
            "        [-7.7149,  6.8949]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.6936,  6.8984],\n",
            "        [-7.9431,  6.9652],\n",
            "        [-7.9501,  7.0574],\n",
            "        [-7.7724,  6.8722]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8037,  6.9872],\n",
            "        [-7.8155,  6.9431],\n",
            "        [-7.6659,  6.8956],\n",
            "        [-7.8516,  6.7758]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8933,  6.8490],\n",
            "        [-7.7619,  7.0833],\n",
            "        [-7.8634,  6.8700],\n",
            "        [-7.8229,  6.9743]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6624,  6.6293],\n",
            "        [-7.7963,  7.0582],\n",
            "        [-7.7383,  6.8793],\n",
            "        [-7.7311,  6.7535]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8053,  6.8737],\n",
            "        [-7.7301,  6.8624],\n",
            "        [-7.8705,  6.9045],\n",
            "        [-7.6477,  6.9024]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.5698,  6.7899],\n",
            "        [-7.8252,  6.8103],\n",
            "        [-7.6830,  6.8893],\n",
            "        [-7.7897,  6.8106]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8564,  6.8927],\n",
            "        [-7.7982,  6.9442],\n",
            "        [-7.6001,  6.7279],\n",
            "        [-7.8520,  7.0024]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7693,  6.8562],\n",
            "        [-7.7346,  6.8421],\n",
            "        [-7.7463,  6.8815],\n",
            "        [-7.9648,  7.0889]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7784,  6.9182],\n",
            "        [-7.8796,  6.9296],\n",
            "        [-7.8526,  6.9796],\n",
            "        [-7.8950,  7.0275]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8438,  6.9375],\n",
            "        [-8.1473,  7.0896],\n",
            "        [-7.8671,  7.0476],\n",
            "        [-7.7344,  6.9497]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9177,  6.9801],\n",
            "        [-7.8012,  6.9658],\n",
            "        [-7.8491,  6.8800],\n",
            "        [-7.8222,  7.0040]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7808,  6.9675],\n",
            "        [-7.8533,  6.9589],\n",
            "        [-7.8512,  6.9692],\n",
            "        [-7.7998,  6.7793]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8300,  6.8582],\n",
            "        [-7.8503,  6.9923],\n",
            "        [-7.9321,  6.9809],\n",
            "        [-7.7069,  6.9435]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6284,  6.9037],\n",
            "        [-7.8058,  6.8875],\n",
            "        [-7.6559,  6.6017],\n",
            "        [-7.7150,  6.8642]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.5735,  6.7542],\n",
            "        [-7.5469,  6.8475],\n",
            "        [-8.1076,  6.9250],\n",
            "        [-7.4727,  6.6624]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.36441632448259e-07\n",
            "Outputs: tensor([[-7.8522,  7.0376],\n",
            "        [-7.8111,  6.7526],\n",
            "        [-7.7917,  6.9789],\n",
            "        [-7.7714,  6.8864]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.5932,  6.8664],\n",
            "        [-7.9882,  6.9455],\n",
            "        [-7.7708,  6.8322],\n",
            "        [-7.8126,  6.9687]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7879,  6.8216],\n",
            "        [-7.8317,  7.0341],\n",
            "        [-7.8394,  6.9728],\n",
            "        [-7.7624,  6.8460]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7477,  6.9682],\n",
            "        [-7.7859,  6.9031],\n",
            "        [-7.7949,  6.6573],\n",
            "        [-7.8876,  7.0932]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7970,  6.8719],\n",
            "        [-7.7104,  6.8574],\n",
            "        [-7.7666,  6.9212],\n",
            "        [-7.8258,  6.9441]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.4676,  6.8385],\n",
            "        [-7.8599,  6.7026],\n",
            "        [-7.4968,  6.6857],\n",
            "        [-7.6617,  6.7978]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.6687,  6.8908],\n",
            "        [-7.8103,  7.0406],\n",
            "        [-7.7935,  6.8843],\n",
            "        [-7.6735,  6.5560]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.6534,  6.7219],\n",
            "        [-8.1152,  7.0672],\n",
            "        [-7.7212,  6.8926],\n",
            "        [-7.7177,  6.9367]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6082,  6.7150],\n",
            "        [-7.6457,  6.8962],\n",
            "        [-7.7729,  6.7507],\n",
            "        [-7.8501,  6.9671]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.7080,  6.8730],\n",
            "        [-7.7590,  6.6341],\n",
            "        [-7.7710,  6.8808],\n",
            "        [-7.7229,  6.9675]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370729379967e-07\n",
            "Outputs: tensor([[-7.7177,  6.9021],\n",
            "        [-7.7734,  6.8323],\n",
            "        [-8.0417,  7.0961],\n",
            "        [-7.8552,  7.0265]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8757,  6.8891],\n",
            "        [-7.8703,  7.0345],\n",
            "        [-7.8404,  6.9571],\n",
            "        [-7.9314,  7.0553]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7887,  7.0314],\n",
            "        [-7.8363,  6.9174],\n",
            "        [-7.7167,  6.9306],\n",
            "        [-7.5725,  6.5130]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8617,  7.0492],\n",
            "        [-7.8996,  6.9546],\n",
            "        [-7.7877,  6.9395],\n",
            "        [-7.8169,  6.8655]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8489,  6.9688],\n",
            "        [-7.6609,  6.8721],\n",
            "        [-8.0212,  6.8426],\n",
            "        [-7.7358,  7.0112]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8207,  6.8882],\n",
            "        [-7.7880,  6.7780],\n",
            "        [-7.6862,  6.8633],\n",
            "        [-7.7976,  7.0622]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7060,  6.9056],\n",
            "        [-7.7292,  6.9759],\n",
            "        [-7.8148,  6.5705],\n",
            "        [-7.8090,  7.0148]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.5400,  6.7716],\n",
            "        [-7.7039,  6.7203],\n",
            "        [-7.7343,  6.9217],\n",
            "        [-7.9187,  6.9409]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8341,  6.9547],\n",
            "        [-7.7685,  6.9443],\n",
            "        [-7.8585,  6.9540],\n",
            "        [-7.9344,  6.9499]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0014,  7.0046],\n",
            "        [-7.7723,  7.0600],\n",
            "        [-7.7942,  6.8467],\n",
            "        [-7.6905,  6.7955]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8544,  6.9860],\n",
            "        [-7.8691,  6.9429],\n",
            "        [-7.8578,  6.9121],\n",
            "        [-7.8748,  7.0332]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6321,  6.9235],\n",
            "        [-7.7826,  6.7903],\n",
            "        [-7.8319,  6.7753],\n",
            "        [-7.8024,  6.9256]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.6429,  6.7582],\n",
            "        [-7.6652,  6.9114],\n",
            "        [-7.6544,  6.5878],\n",
            "        [-7.8337,  6.9660]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.9517,  6.9444],\n",
            "        [-7.8210,  7.0503],\n",
            "        [-7.7739,  7.0182],\n",
            "        [-7.9375,  6.9087]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8080,  7.0201],\n",
            "        [-7.7209,  6.7733],\n",
            "        [-7.9264,  6.9944],\n",
            "        [-7.9912,  7.0715]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8262,  6.9933],\n",
            "        [-7.7499,  6.9374],\n",
            "        [-7.8702,  6.9098],\n",
            "        [-8.0044,  7.0741]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8302,  7.0297],\n",
            "        [-7.5325,  6.9392],\n",
            "        [-7.7582,  6.8580],\n",
            "        [-7.8528,  6.6792]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.9448,  6.9654],\n",
            "        [-8.0290,  7.1687],\n",
            "        [-7.7881,  6.8824],\n",
            "        [-7.7729,  6.9265]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6997,  6.8683],\n",
            "        [-7.8087,  6.9840],\n",
            "        [-7.5396,  6.5220],\n",
            "        [-7.8524,  6.9779]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7945,  6.9533],\n",
            "        [-7.8264,  6.9405],\n",
            "        [-7.8516,  6.9214],\n",
            "        [-8.0025,  7.0821]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8579,  6.9476],\n",
            "        [-7.7945,  6.7669],\n",
            "        [-7.6505,  6.7779],\n",
            "        [-7.7454,  6.9836]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703477897201083e-07\n",
            "Outputs: tensor([[-7.9398,  7.0550],\n",
            "        [-7.9385,  7.1146],\n",
            "        [-7.8336,  6.9345],\n",
            "        [-7.8318,  6.8629]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8409,  7.1697],\n",
            "        [-7.7750,  7.0075],\n",
            "        [-7.7892,  6.8723],\n",
            "        [-7.7703,  6.6153]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.8856,  7.0448],\n",
            "        [-7.7598,  6.9092],\n",
            "        [-7.8167,  6.9773],\n",
            "        [-7.9455,  6.8971]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7674,  6.9243],\n",
            "        [-7.8047,  7.0444],\n",
            "        [-7.9782,  6.9531],\n",
            "        [-7.8943,  6.9467]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8231,  6.8518],\n",
            "        [-7.8140,  6.9556],\n",
            "        [-7.7569,  6.8043],\n",
            "        [-7.7303,  6.9425]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7299,  6.9639],\n",
            "        [-7.8258,  6.8485],\n",
            "        [-7.5744,  6.6320],\n",
            "        [-7.5530,  6.7070]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.5911,  6.5950],\n",
            "        [-7.7901,  6.9380],\n",
            "        [-7.8781,  7.0246],\n",
            "        [-7.6297,  6.8337]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8382,  6.9752],\n",
            "        [-7.8771,  6.9650],\n",
            "        [-7.8253,  6.9495],\n",
            "        [-7.8975,  7.0009]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9780,  6.7903],\n",
            "        [-7.8511,  6.9054],\n",
            "        [-7.7067,  6.9872],\n",
            "        [-7.6726,  6.9586]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7296,  6.8091],\n",
            "        [-7.7657,  6.8261],\n",
            "        [-7.9373,  6.8638],\n",
            "        [-7.2755,  6.6701]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.8843,  7.0431],\n",
            "        [-7.8228,  6.9248],\n",
            "        [-7.8821,  6.8559],\n",
            "        [-7.9115,  7.1040]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6743,  6.7536],\n",
            "        [-7.7439,  6.9087],\n",
            "        [-7.9810,  7.1800],\n",
            "        [-7.9832,  7.0017]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.1723239974089665e-07\n",
            "Outputs: tensor([[-7.7314,  6.9397],\n",
            "        [-7.7518,  6.9948],\n",
            "        [-7.9846,  6.9814],\n",
            "        [-7.7788,  6.8201]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8485,  6.9905],\n",
            "        [-7.7084,  6.8983],\n",
            "        [-7.9186,  6.9479],\n",
            "        [-7.8409,  6.9913]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8967,  7.0482],\n",
            "        [-7.8197,  6.9105],\n",
            "        [-7.8375,  6.8537],\n",
            "        [-7.8480,  7.0422]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.4082,  6.6201],\n",
            "        [-7.8890,  7.0098],\n",
            "        [-7.7259,  7.0023],\n",
            "        [-7.8317,  6.7783]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.9418,  6.9288],\n",
            "        [-7.7199,  6.8917],\n",
            "        [-7.9266,  6.9362],\n",
            "        [-7.6544,  6.9609]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7540,  6.9181],\n",
            "        [-7.7692,  6.8354],\n",
            "        [-7.8820,  6.9769],\n",
            "        [-7.8135,  6.9876]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8152,  6.8001],\n",
            "        [-7.7105,  7.0078],\n",
            "        [-7.7246,  6.7857],\n",
            "        [-7.8100,  6.9302]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8767,  6.9821],\n",
            "        [-7.9572,  6.9854],\n",
            "        [-7.8193,  6.9620],\n",
            "        [-7.7880,  6.9529]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9006,  7.0091],\n",
            "        [-7.9426,  7.0888],\n",
            "        [-7.8416,  6.8858],\n",
            "        [-7.8024,  6.9810]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8954,  6.8358],\n",
            "        [-7.7310,  6.8968],\n",
            "        [-7.5665,  6.8250],\n",
            "        [-7.9708,  7.0954]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.6855,  6.8939],\n",
            "        [-7.8580,  6.9455],\n",
            "        [-7.9496,  6.9241],\n",
            "        [-7.5914,  6.7849]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7321,  6.9162],\n",
            "        [-7.8578,  6.9271],\n",
            "        [-7.9516,  6.9409],\n",
            "        [-7.8086,  6.9738]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9002,  7.0379],\n",
            "        [-7.9292,  6.9313],\n",
            "        [-7.8209,  6.9151],\n",
            "        [-7.8090,  6.9743]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8056,  6.9824],\n",
            "        [-7.8605,  6.9123],\n",
            "        [-7.4297,  6.5983],\n",
            "        [-7.9173,  6.9836]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6670,  6.8711],\n",
            "        [-8.0266,  7.0698],\n",
            "        [-7.8574,  6.9531],\n",
            "        [-7.9424,  7.0124]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8022,  6.7159],\n",
            "        [-7.8825,  6.9749],\n",
            "        [-7.8735,  6.8881],\n",
            "        [-7.5903,  6.9732]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8705,  6.9026],\n",
            "        [-7.9247,  6.9235],\n",
            "        [-7.8672,  7.0331],\n",
            "        [-7.7603,  6.9808]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8597,  6.9697],\n",
            "        [-7.7774,  6.9193],\n",
            "        [-7.9637,  6.8685],\n",
            "        [-7.8273,  7.0741]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8356,  6.9349],\n",
            "        [-7.9538,  7.0925],\n",
            "        [-7.8146,  6.8803],\n",
            "        [-7.7167,  6.8954]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7724,  6.9152],\n",
            "        [-7.9043,  7.0526],\n",
            "        [-7.9561,  6.9296],\n",
            "        [-7.8257,  6.9721]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7517,  6.6796],\n",
            "        [-7.5717,  6.9584],\n",
            "        [-7.6165,  6.6396],\n",
            "        [-7.6922,  6.7641]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.8229,  6.8306],\n",
            "        [-7.7504,  6.6724],\n",
            "        [-7.9076,  7.1068],\n",
            "        [-7.7173,  7.0072]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8692,  6.9661],\n",
            "        [-7.8539,  6.8903],\n",
            "        [-7.7270,  6.9461],\n",
            "        [-7.6143,  6.7358]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.7895,  6.9815],\n",
            "        [-7.8805,  6.9510],\n",
            "        [-7.7747,  6.9211],\n",
            "        [-8.0956,  7.1196]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7598,  6.8300],\n",
            "        [-7.7088,  6.9130],\n",
            "        [-7.7786,  6.8802],\n",
            "        [-7.8228,  6.9613]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-8.0058,  6.9925],\n",
            "        [-7.7866,  6.9148],\n",
            "        [-7.7449,  6.8696],\n",
            "        [-7.6908,  6.8461]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7030,  6.8650],\n",
            "        [-7.8230,  7.0652],\n",
            "        [-7.8178,  6.8442],\n",
            "        [-8.0505,  7.0474]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7374,  6.9120],\n",
            "        [-7.9712,  6.9664],\n",
            "        [-8.0286,  7.0971],\n",
            "        [-7.8973,  7.1003]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.4558,  6.7386],\n",
            "        [-7.7734,  6.7827],\n",
            "        [-7.5981,  6.6737],\n",
            "        [-7.8395,  6.9670]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.8763,  6.9198],\n",
            "        [-7.9175,  7.0107],\n",
            "        [-7.8781,  6.9896],\n",
            "        [-7.6464,  6.8264]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7345,  6.9454],\n",
            "        [-7.9338,  7.0412],\n",
            "        [-7.5423,  6.6496],\n",
            "        [-7.5233,  6.4799]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.8400,  7.0001],\n",
            "        [-7.6543,  6.8778],\n",
            "        [-8.0199,  6.9255],\n",
            "        [-7.8487,  6.9635]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9380,  6.9867],\n",
            "        [-7.8857,  7.0646],\n",
            "        [-7.7206,  6.8267],\n",
            "        [-7.6741,  6.8121]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7166,  6.9769],\n",
            "        [-7.9008,  6.8753],\n",
            "        [-7.7902,  6.9152],\n",
            "        [-7.7250,  6.8620]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8737,  6.9871],\n",
            "        [-7.8731,  6.8927],\n",
            "        [-7.8439,  6.9668],\n",
            "        [-7.8939,  7.0768]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9774,  7.0548],\n",
            "        [-7.8281,  6.9378],\n",
            "        [-7.8743,  6.9576],\n",
            "        [-7.8558,  7.0410]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9092,  6.9809],\n",
            "        [-7.9127,  7.1093],\n",
            "        [-7.7913,  6.9555],\n",
            "        [-7.8825,  6.8852]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8944,  7.0214],\n",
            "        [-7.9582,  7.0301],\n",
            "        [-7.8485,  7.0037],\n",
            "        [-7.7914,  6.9056]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9246,  6.9561],\n",
            "        [-7.9480,  7.0438],\n",
            "        [-7.7558,  6.9419],\n",
            "        [-7.8936,  6.9714]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8004,  6.8903],\n",
            "        [-7.7437,  7.0267],\n",
            "        [-8.0337,  7.1527],\n",
            "        [-7.8588,  6.7861]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8337,  6.9985],\n",
            "        [-7.9032,  6.9966],\n",
            "        [-7.6996,  6.8826],\n",
            "        [-7.8732,  6.9266]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8473,  6.8270],\n",
            "        [-7.5462,  6.7712],\n",
            "        [-7.8435,  6.7851],\n",
            "        [-7.6844,  6.9803]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.9093,  6.9876],\n",
            "        [-7.9344,  7.0411],\n",
            "        [-7.9936,  7.0260],\n",
            "        [-7.8039,  7.0345]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7515,  7.0101],\n",
            "        [-7.8199,  7.0023],\n",
            "        [-7.6724,  6.5411],\n",
            "        [-7.8320,  6.9638]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703477897201083e-07\n",
            "Outputs: tensor([[-7.9991,  7.1684],\n",
            "        [-7.6847,  6.7739],\n",
            "        [-7.6859,  7.0033],\n",
            "        [-7.7126,  6.6380]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.6817,  7.0428],\n",
            "        [-7.7572,  6.7490],\n",
            "        [-7.7956,  6.9253],\n",
            "        [-7.8480,  6.7665]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9944,  6.9414],\n",
            "        [-7.5764,  7.0315],\n",
            "        [-7.7113,  6.7243],\n",
            "        [-7.5300,  6.6120]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.7390,  6.9155],\n",
            "        [-7.7223,  7.0290],\n",
            "        [-7.9767,  6.9408],\n",
            "        [-7.8404,  6.8528]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9617,  6.9892],\n",
            "        [-7.7110,  7.0243],\n",
            "        [-7.9617,  6.9924],\n",
            "        [-7.9300,  7.0225]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6831,  6.6688],\n",
            "        [-7.8676,  6.9848],\n",
            "        [-8.0225,  7.1188],\n",
            "        [-7.8294,  7.0776]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7627,  6.9180],\n",
            "        [-7.8829,  7.0365],\n",
            "        [-7.8187,  6.9995],\n",
            "        [-7.9642,  6.9129]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8747,  6.9713],\n",
            "        [-7.7112,  6.8783],\n",
            "        [-7.7088,  6.7002],\n",
            "        [-7.7293,  6.9636]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703477897201083e-07\n",
            "Outputs: tensor([[-7.8870,  7.0538],\n",
            "        [-7.8195,  6.8439],\n",
            "        [-7.8589,  7.0016],\n",
            "        [-8.0527,  7.1530]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7491,  6.9638],\n",
            "        [-7.7674,  6.6349],\n",
            "        [-7.9326,  6.9258],\n",
            "        [-7.7490,  7.1162]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-8.0510,  7.0624],\n",
            "        [-7.7784,  7.0641],\n",
            "        [-7.7271,  6.7253],\n",
            "        [-7.8919,  7.0425]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6846,  6.9521],\n",
            "        [-7.8213,  6.6211],\n",
            "        [-7.6590,  6.8514],\n",
            "        [-7.8056,  7.0163]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8685,  6.8761],\n",
            "        [-7.9692,  7.0382],\n",
            "        [-7.8232,  6.9798],\n",
            "        [-7.7283,  6.9198]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8407,  6.8738],\n",
            "        [-7.9132,  6.8827],\n",
            "        [-7.8627,  7.0979],\n",
            "        [-7.8495,  7.0242]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7253,  7.0000],\n",
            "        [-7.7559,  6.9266],\n",
            "        [-7.8466,  6.8545],\n",
            "        [-7.6818,  6.6760]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.5612,  6.7206],\n",
            "        [-7.9407,  6.9685],\n",
            "        [-7.7366,  6.8601],\n",
            "        [-7.8819,  6.9851]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.7314,  6.9654],\n",
            "        [-7.7162,  6.7660],\n",
            "        [-7.8411,  6.9261],\n",
            "        [-7.8944,  7.0136]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7762,  6.8832],\n",
            "        [-7.5191,  6.6237],\n",
            "        [-7.7550,  6.8743],\n",
            "        [-7.8969,  6.9789]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8843,  6.8576],\n",
            "        [-7.9061,  7.0598],\n",
            "        [-7.8989,  6.9747],\n",
            "        [-7.6950,  6.9276]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8709,  6.9578],\n",
            "        [-7.4365,  6.3262],\n",
            "        [-7.6924,  6.9800],\n",
            "        [-7.8819,  7.0755]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.5368,  6.7498],\n",
            "        [-8.0145,  7.0991],\n",
            "        [-7.8130,  7.0140],\n",
            "        [-7.9846,  6.9224]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.3771,  6.6333],\n",
            "        [-8.0285,  6.9982],\n",
            "        [-7.5952,  6.7703],\n",
            "        [-8.0078,  7.0765]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.7683701609457785e-07\n",
            "Outputs: tensor([[-7.8054,  6.9437],\n",
            "        [-7.8115,  6.9940],\n",
            "        [-7.7260,  6.8829],\n",
            "        [-7.7978,  6.7602]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9076,  6.9770],\n",
            "        [-7.8716,  6.9732],\n",
            "        [-7.9248,  7.0903],\n",
            "        [-8.0261,  7.1099]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7972,  6.9245],\n",
            "        [-7.9139,  6.9779],\n",
            "        [-8.0584,  7.0631],\n",
            "        [-7.7748,  7.0386]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6803,  6.8769],\n",
            "        [-8.0242,  7.1130],\n",
            "        [-8.0216,  7.0375],\n",
            "        [-7.8430,  6.9635]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6588,  6.8414],\n",
            "        [-7.8420,  7.0354],\n",
            "        [-7.8195,  6.7664],\n",
            "        [-7.9891,  7.1348]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8052,  6.8897],\n",
            "        [-7.3732,  6.4457],\n",
            "        [-7.8752,  6.9453],\n",
            "        [-7.8907,  7.1553]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6325,  6.8061],\n",
            "        [-7.9137,  7.0822],\n",
            "        [-7.7295,  6.6775],\n",
            "        [-7.7313,  6.9287]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8358,  6.9955],\n",
            "        [-7.9233,  7.0339],\n",
            "        [-7.8372,  7.0133],\n",
            "        [-7.8974,  6.9130]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9149,  7.0462],\n",
            "        [-7.8579,  6.9566],\n",
            "        [-7.7961,  6.9278],\n",
            "        [-7.9305,  7.0292]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9809,  7.1760],\n",
            "        [-7.7259,  6.9122],\n",
            "        [-7.8364,  6.9073],\n",
            "        [-7.8175,  6.8196]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9023,  6.9859],\n",
            "        [-7.9318,  6.9481],\n",
            "        [-7.8341,  7.0226],\n",
            "        [-7.6830,  6.8408]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8230,  6.9071],\n",
            "        [-7.6310,  6.7890],\n",
            "        [-7.7970,  6.9198],\n",
            "        [-7.8848,  7.0044]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9214,  6.9423],\n",
            "        [-7.7612,  6.9449],\n",
            "        [-7.8147,  6.9701],\n",
            "        [-7.7729,  6.8953]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7375,  6.8650],\n",
            "        [-7.2931,  6.5653],\n",
            "        [-7.5748,  6.8134],\n",
            "        [-8.0657,  6.8944]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462203802308e-07\n",
            "Outputs: tensor([[-7.7850,  7.0890],\n",
            "        [-7.9198,  6.9765],\n",
            "        [-7.5522,  6.7308],\n",
            "        [-7.7708,  6.7342]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.8529,  6.9470],\n",
            "        [-8.0430,  7.0147],\n",
            "        [-7.8207,  7.0469],\n",
            "        [-7.7462,  6.9297]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.5327,  6.3709],\n",
            "        [-7.7377,  6.9433],\n",
            "        [-7.5493,  6.6901],\n",
            "        [-7.6723,  6.8955]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 6.258485427679261e-07\n",
            "Outputs: tensor([[-7.6806,  6.9513],\n",
            "        [-7.6077,  6.7756],\n",
            "        [-7.5153,  6.8991],\n",
            "        [-8.0958,  6.7241]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.8826,  6.9982],\n",
            "        [-7.8775,  7.0238],\n",
            "        [-7.9968,  6.9087],\n",
            "        [-7.6416,  6.9172]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9259,  6.8917],\n",
            "        [-7.8514,  6.9997],\n",
            "        [-7.9074,  7.1054],\n",
            "        [-7.8585,  6.9801]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8266,  6.8606],\n",
            "        [-7.9684,  7.0773],\n",
            "        [-7.7933,  6.9685],\n",
            "        [-7.7778,  6.8382]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7293,  6.6204],\n",
            "        [-7.8602,  7.0345],\n",
            "        [-7.8544,  7.0112],\n",
            "        [-7.6578,  6.9120]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.5632,  6.8921],\n",
            "        [-7.7934,  6.8590],\n",
            "        [-7.9684,  6.7217],\n",
            "        [-7.5679,  6.8591]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9875,  7.0237],\n",
            "        [-7.6986,  6.9059],\n",
            "        [-7.7561,  6.8976],\n",
            "        [-7.7694,  6.8427]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-8.0615,  7.1209],\n",
            "        [-7.9906,  7.0244],\n",
            "        [-7.8161,  6.8829],\n",
            "        [-7.7257,  6.9974]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8548,  6.9017],\n",
            "        [-7.7784,  6.8346],\n",
            "        [-7.9140,  7.2164],\n",
            "        [-7.7886,  6.8639]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0265,  7.0028],\n",
            "        [-7.8825,  7.0577],\n",
            "        [-7.8963,  7.0315],\n",
            "        [-7.9003,  7.0269]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0172,  7.1028],\n",
            "        [-7.8307,  7.0291],\n",
            "        [-7.8069,  7.0439],\n",
            "        [-7.5535,  6.4807]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.9384,  6.9031],\n",
            "        [-7.6914,  6.9187],\n",
            "        [-7.7866,  6.9709],\n",
            "        [-7.9264,  6.9920]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7536,  6.7451],\n",
            "        [-7.7520,  6.5977],\n",
            "        [-7.8124,  7.0990],\n",
            "        [-7.8149,  7.1173]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7606,  6.8801],\n",
            "        [-7.7544,  6.7197],\n",
            "        [-7.8484,  7.0445],\n",
            "        [-7.6297,  6.8260]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.9852,  6.9664],\n",
            "        [-8.1516,  7.0226],\n",
            "        [-7.7187,  7.0401],\n",
            "        [-7.6891,  6.9559]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7774,  6.8531],\n",
            "        [-7.7776,  6.9242],\n",
            "        [-7.3552,  6.5514],\n",
            "        [-7.8756,  6.9843]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.364416892916779e-07\n",
            "Outputs: tensor([[-7.8038,  7.0001],\n",
            "        [-7.9370,  6.8987],\n",
            "        [-7.8909,  7.0498],\n",
            "        [-7.9126,  7.0182]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8248,  6.9190],\n",
            "        [-8.0477,  7.0798],\n",
            "        [-7.6976,  6.9925],\n",
            "        [-7.9098,  6.8723]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9031,  6.9631],\n",
            "        [-7.7463,  6.8547],\n",
            "        [-7.7295,  6.8071],\n",
            "        [-7.9408,  7.1751]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8371,  6.8625],\n",
            "        [-7.6771,  6.8756],\n",
            "        [-7.6052,  6.8327],\n",
            "        [-8.0995,  7.0865]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9045,  7.0035],\n",
            "        [-7.8865,  7.0034],\n",
            "        [-8.0039,  7.1763],\n",
            "        [-7.8884,  6.9335]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6319,  6.8868],\n",
            "        [-7.9694,  6.7408],\n",
            "        [-7.6678,  7.0835],\n",
            "        [-7.7491,  6.7735]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7187,  6.8671],\n",
            "        [-7.9316,  6.9997],\n",
            "        [-7.7031,  6.8432],\n",
            "        [-7.8817,  6.9891]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7567,  7.0277],\n",
            "        [-7.9538,  7.0416],\n",
            "        [-8.0533,  7.0190],\n",
            "        [-7.9970,  7.1232]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.6451,  6.8018],\n",
            "        [-7.9435,  6.9099],\n",
            "        [-7.7906,  6.8432],\n",
            "        [-7.7201,  7.0023]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6121,  6.6917],\n",
            "        [-7.9724,  6.9755],\n",
            "        [-7.8167,  6.9825],\n",
            "        [-7.7387,  6.9439]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.7843,  6.8726],\n",
            "        [-7.9813,  7.0884],\n",
            "        [-7.9811,  7.0733],\n",
            "        [-7.8305,  6.9597]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8810,  7.0119],\n",
            "        [-7.8709,  7.0820],\n",
            "        [-7.9361,  7.0374],\n",
            "        [-7.9480,  6.9634]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7973,  6.8786],\n",
            "        [-7.6292,  6.9471],\n",
            "        [-7.8554,  6.9604],\n",
            "        [-8.0707,  7.1065]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7650,  6.7435],\n",
            "        [-7.9435,  7.0766],\n",
            "        [-7.7947,  7.0132],\n",
            "        [-7.8760,  7.0077]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9870,  7.0357],\n",
            "        [-7.8263,  7.0381],\n",
            "        [-7.9875,  7.0575],\n",
            "        [-7.7726,  6.8689]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8669,  6.9960],\n",
            "        [-7.9900,  7.0586],\n",
            "        [-7.8880,  7.1010],\n",
            "        [-7.6935,  6.7772]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7601,  6.8585],\n",
            "        [-7.6226,  6.9534],\n",
            "        [-7.5867,  6.7739],\n",
            "        [-7.9368,  6.7437]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7750,  6.9420],\n",
            "        [-7.9507,  6.9886],\n",
            "        [-8.0690,  7.0778],\n",
            "        [-7.8737,  7.0876]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7609,  6.9423],\n",
            "        [-7.9537,  7.0475],\n",
            "        [-8.0505,  7.0984],\n",
            "        [-7.8758,  6.9923]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7303,  6.9355],\n",
            "        [-7.6950,  7.0552],\n",
            "        [-7.8955,  6.7364],\n",
            "        [-7.4218,  6.4661]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662438979925355e-07\n",
            "Outputs: tensor([[-7.6782,  6.9266],\n",
            "        [-8.1351,  7.0326],\n",
            "        [-7.7031,  6.8477],\n",
            "        [-7.7254,  6.9449]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7470,  6.9228],\n",
            "        [-7.8460,  7.1241],\n",
            "        [-7.8475,  6.8495],\n",
            "        [-7.7052,  6.6768]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8729,  6.8907],\n",
            "        [-7.8794,  6.7395],\n",
            "        [-7.9185,  7.1554],\n",
            "        [-7.5452,  6.9177]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8802,  6.7952],\n",
            "        [-7.9437,  6.9625],\n",
            "        [-7.6704,  6.9415],\n",
            "        [-7.7543,  7.0173]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9110,  6.9517],\n",
            "        [-7.7839,  6.9974],\n",
            "        [-7.6903,  6.8689],\n",
            "        [-7.8927,  6.9169]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8284,  7.0289],\n",
            "        [-7.9773,  6.9887],\n",
            "        [-7.7597,  7.0244],\n",
            "        [-8.0364,  7.0094]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8597,  7.0152],\n",
            "        [-8.0965,  7.0236],\n",
            "        [-7.7605,  6.9634],\n",
            "        [-7.7624,  6.9235]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9696,  6.9212],\n",
            "        [-7.9862,  7.1105],\n",
            "        [-7.8630,  7.0170],\n",
            "        [-7.6714,  6.8973]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6966,  6.8142],\n",
            "        [-7.8459,  6.9305],\n",
            "        [-8.0172,  7.1733],\n",
            "        [-7.7117,  6.8091]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.6913,  6.7987],\n",
            "        [-7.8159,  6.9629],\n",
            "        [-7.8694,  6.8343],\n",
            "        [-7.7620,  6.9896]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7895,  7.0062],\n",
            "        [-7.9119,  7.0463],\n",
            "        [-8.0201,  7.0426],\n",
            "        [-7.8181,  6.9164]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9111,  7.0286],\n",
            "        [-7.8670,  6.9091],\n",
            "        [-7.7213,  6.8102],\n",
            "        [-7.8932,  7.0849]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7734,  6.9787],\n",
            "        [-7.8044,  7.0185],\n",
            "        [-7.6313,  6.5106],\n",
            "        [-7.7377,  6.9207]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6298,  6.8591],\n",
            "        [-7.7244,  6.7424],\n",
            "        [-7.8025,  6.9587],\n",
            "        [-7.9699,  7.0179]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6760,  6.9287],\n",
            "        [-7.5218,  6.6367],\n",
            "        [-7.8543,  6.7826],\n",
            "        [-7.9326,  7.1275]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8390,  7.0017],\n",
            "        [-7.7426,  6.9352],\n",
            "        [-7.6833,  6.7605],\n",
            "        [-7.8758,  6.8961]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8689,  6.8616],\n",
            "        [-7.8387,  6.9824],\n",
            "        [-8.0532,  7.0486],\n",
            "        [-7.7095,  7.0239]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0158,  7.0477],\n",
            "        [-7.8249,  6.8700],\n",
            "        [-7.6441,  6.8494],\n",
            "        [-7.8146,  6.9629]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8346,  6.8878],\n",
            "        [-7.7920,  6.8926],\n",
            "        [-7.7105,  6.8452],\n",
            "        [-7.9108,  7.0767]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9771,  7.0025],\n",
            "        [-7.8191,  7.0539],\n",
            "        [-7.9011,  7.0559],\n",
            "        [-8.0982,  7.1075]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9215,  7.0737],\n",
            "        [-7.9965,  7.0916],\n",
            "        [-7.8597,  6.9578],\n",
            "        [-7.9968,  7.0817]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9330,  7.0239],\n",
            "        [-7.8731,  6.9924],\n",
            "        [-8.0242,  7.0456],\n",
            "        [-7.8404,  7.0350]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9794,  7.0921],\n",
            "        [-7.9120,  7.0101],\n",
            "        [-7.7457,  6.8653],\n",
            "        [-7.7411,  6.9049]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8416,  7.0141],\n",
            "        [-7.7983,  6.7510],\n",
            "        [-7.7506,  6.9207],\n",
            "        [-7.8937,  7.0496]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9373,  7.0913],\n",
            "        [-7.9214,  7.0551],\n",
            "        [-7.9099,  6.9935],\n",
            "        [-7.8851,  6.9323]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9092,  6.9503],\n",
            "        [-7.9522,  7.0922],\n",
            "        [-7.9439,  7.0383],\n",
            "        [-7.7625,  6.8711]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8374,  6.9332],\n",
            "        [-7.7475,  6.8617],\n",
            "        [-7.8959,  7.0140],\n",
            "        [-7.7731,  6.9153]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7271,  6.8698],\n",
            "        [-7.6740,  6.6543],\n",
            "        [-7.6468,  6.7631],\n",
            "        [-7.5143,  6.8663]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662440116793732e-07\n",
            "Outputs: tensor([[-7.7940,  6.8041],\n",
            "        [-7.4536,  6.7383],\n",
            "        [-7.7384,  6.6546],\n",
            "        [-7.9078,  7.2083]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.7468,  6.8819],\n",
            "        [-8.0534,  7.0401],\n",
            "        [-7.8556,  6.9807],\n",
            "        [-7.9118,  7.1107]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.5929,  6.9245],\n",
            "        [-7.7302,  6.8851],\n",
            "        [-7.8772,  6.6092],\n",
            "        [-7.6337,  6.8263]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8251,  6.9688],\n",
            "        [-7.7000,  7.0241],\n",
            "        [-7.5771,  6.3930],\n",
            "        [-7.9191,  7.0932]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9985,  6.9924],\n",
            "        [-7.8959,  6.9702],\n",
            "        [-7.7292,  6.9847],\n",
            "        [-7.8089,  6.9084]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6378,  6.8329],\n",
            "        [-7.6311,  6.8826],\n",
            "        [-7.7065,  6.9304],\n",
            "        [-7.9607,  6.7697]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.9653,  6.9148],\n",
            "        [-7.9273,  7.1157],\n",
            "        [-7.9490,  7.0851],\n",
            "        [-7.7491,  6.9197]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6507,  6.9366],\n",
            "        [-7.9928,  7.0373],\n",
            "        [-7.8784,  6.9058],\n",
            "        [-7.9149,  7.0069]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7253,  6.8817],\n",
            "        [-7.9921,  7.1105],\n",
            "        [-7.9073,  6.9257],\n",
            "        [-7.6718,  6.8828]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.6085,  6.7850],\n",
            "        [-7.4680,  6.6872],\n",
            "        [-7.4780,  6.5727],\n",
            "        [-8.1985,  7.1650]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462772236497e-07\n",
            "Outputs: tensor([[-7.8649,  7.0307],\n",
            "        [-7.9481,  7.0233],\n",
            "        [-8.0439,  7.0871],\n",
            "        [-7.8133,  6.9355]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8845,  6.8417],\n",
            "        [-7.9149,  7.0176],\n",
            "        [-7.7958,  6.9780],\n",
            "        [-7.8123,  7.0152]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9587,  7.0970],\n",
            "        [-7.7974,  6.8814],\n",
            "        [-7.7603,  6.9911],\n",
            "        [-7.7081,  6.7664]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9945,  7.1044],\n",
            "        [-7.6686,  6.9855],\n",
            "        [-7.7768,  7.0257],\n",
            "        [-7.8583,  6.6167]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8633,  6.7398],\n",
            "        [-7.8513,  6.9813],\n",
            "        [-7.7898,  7.0147],\n",
            "        [-7.7221,  6.9391]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9812,  7.0341],\n",
            "        [-7.8301,  6.9039],\n",
            "        [-7.8581,  6.9306],\n",
            "        [-7.8100,  7.0134]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7448,  7.1092],\n",
            "        [-8.0770,  7.0518],\n",
            "        [-7.8761,  6.9913],\n",
            "        [-7.9386,  6.9335]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6806,  6.8482],\n",
            "        [-8.1444,  7.0429],\n",
            "        [-7.3557,  6.7248],\n",
            "        [-7.7479,  6.7977]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6114,  6.8761],\n",
            "        [-7.9199,  6.7160],\n",
            "        [-7.6810,  7.1582],\n",
            "        [-7.9293,  6.8596]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7517,  6.8978],\n",
            "        [-7.8284,  6.7305],\n",
            "        [-8.0118,  7.0867],\n",
            "        [-7.7198,  7.0898]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9980,  6.9196],\n",
            "        [-7.8620,  6.9999],\n",
            "        [-7.7905,  6.8822],\n",
            "        [-7.8616,  7.1556]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9131,  7.0738],\n",
            "        [-7.9738,  7.1530],\n",
            "        [-7.7998,  6.8066],\n",
            "        [-7.7456,  6.8726]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8822,  6.8679],\n",
            "        [-7.9003,  7.1161],\n",
            "        [-7.7820,  6.8523],\n",
            "        [-7.8016,  7.0212]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8769,  6.7309],\n",
            "        [-7.8131,  6.9053],\n",
            "        [-7.5365,  6.8215],\n",
            "        [-7.3271,  6.5773]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.960462203802308e-07\n",
            "Outputs: tensor([[-7.8939,  7.1182],\n",
            "        [-7.8940,  7.0565],\n",
            "        [-8.0010,  7.0231],\n",
            "        [-7.8807,  6.9128]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7837,  6.7983],\n",
            "        [-7.9167,  7.0262],\n",
            "        [-7.9289,  7.0266],\n",
            "        [-7.7939,  7.0197]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8616,  6.9913],\n",
            "        [-7.8834,  7.1695],\n",
            "        [-7.9128,  6.9843],\n",
            "        [-7.9950,  6.9576]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9585,  7.0240],\n",
            "        [-7.9047,  7.1368],\n",
            "        [-7.8928,  7.0688],\n",
            "        [-7.8811,  6.8683]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8923,  6.9229],\n",
            "        [-7.8107,  7.0095],\n",
            "        [-7.7803,  6.8205],\n",
            "        [-7.8455,  7.0522]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9134,  7.1087],\n",
            "        [-8.0354,  7.0537],\n",
            "        [-7.8188,  7.0035],\n",
            "        [-8.0997,  7.1272]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8774,  6.8756],\n",
            "        [-7.5813,  6.6217],\n",
            "        [-7.7882,  6.9848],\n",
            "        [-7.7141,  6.9400]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8716,  7.0643],\n",
            "        [-7.9966,  7.0208],\n",
            "        [-7.9023,  7.0781],\n",
            "        [-8.0050,  7.0699]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8248,  6.9786],\n",
            "        [-7.8958,  7.1088],\n",
            "        [-8.0433,  7.1285],\n",
            "        [-8.0142,  6.9964]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9301,  6.8767],\n",
            "        [-7.9777,  7.0539],\n",
            "        [-7.8254,  7.0801],\n",
            "        [-7.9162,  7.0557]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9828,  7.0603],\n",
            "        [-7.8770,  7.0466],\n",
            "        [-7.9064,  7.0738],\n",
            "        [-8.0309,  7.0690]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.8770,  6.9711],\n",
            "        [-7.9962,  7.1089],\n",
            "        [-7.8605,  6.9603],\n",
            "        [-7.8743,  7.0080]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7369,  6.8877],\n",
            "        [-7.6146,  6.9308],\n",
            "        [-7.6736,  6.8469],\n",
            "        [-8.2919,  7.1290]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7266,  6.8475],\n",
            "        [-7.9978,  7.2372],\n",
            "        [-8.0907,  7.0171],\n",
            "        [-7.6910,  6.8363]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0004,  7.1817],\n",
            "        [-7.9319,  7.0466],\n",
            "        [-7.8018,  6.9154],\n",
            "        [-7.9129,  6.9263]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7699,  6.9394],\n",
            "        [-7.8533,  7.0356],\n",
            "        [-7.8690,  6.9977],\n",
            "        [-7.9417,  6.8510]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8747,  6.9873],\n",
            "        [-8.0134,  7.2560],\n",
            "        [-7.9220,  6.9373],\n",
            "        [-7.8061,  6.8905]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0455,  7.1367],\n",
            "        [-7.6900,  6.8694],\n",
            "        [-7.9396,  6.9412],\n",
            "        [-7.8135,  6.9971]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9798,  7.0615],\n",
            "        [-7.7899,  7.0792],\n",
            "        [-7.8968,  6.9457],\n",
            "        [-7.9730,  6.9705]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.1025,  7.1916],\n",
            "        [-7.8848,  7.0796],\n",
            "        [-7.9040,  7.0033],\n",
            "        [-7.9565,  7.0058]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9092,  6.9684],\n",
            "        [-7.6998,  6.9192],\n",
            "        [-7.8508,  6.8755],\n",
            "        [-7.7791,  6.9464]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8246,  7.0327],\n",
            "        [-7.9315,  6.9457],\n",
            "        [-7.9785,  6.9423],\n",
            "        [-7.8185,  7.0470]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7418,  6.9022],\n",
            "        [-7.8700,  6.9185],\n",
            "        [-8.1072,  7.2150],\n",
            "        [-7.7528,  6.8767]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8046,  6.8261],\n",
            "        [-7.8855,  6.9908],\n",
            "        [-7.6968,  6.7529],\n",
            "        [-7.6608,  6.8974]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.7416,  6.8026],\n",
            "        [-8.0496,  7.1805],\n",
            "        [-7.8354,  7.1181],\n",
            "        [-7.9401,  6.9466]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8574,  6.9694],\n",
            "        [-7.7837,  6.8207],\n",
            "        [-7.7761,  6.8744],\n",
            "        [-7.8119,  7.0178]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9181,  7.0597],\n",
            "        [-7.9617,  7.0064],\n",
            "        [-7.9754,  7.0196],\n",
            "        [-7.7216,  6.9696]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8094,  6.9534],\n",
            "        [-8.0008,  7.0347],\n",
            "        [-7.7262,  6.9494],\n",
            "        [-7.9261,  6.9845]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0228,  7.1038],\n",
            "        [-7.8391,  6.7976],\n",
            "        [-7.7214,  7.0265],\n",
            "        [-7.8836,  6.9618]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9013,  6.7846],\n",
            "        [-7.8892,  7.0136],\n",
            "        [-7.7220,  6.9524],\n",
            "        [-7.7929,  7.0251]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8406,  7.0219],\n",
            "        [-7.9676,  7.1231],\n",
            "        [-7.9960,  7.0091],\n",
            "        [-7.9330,  7.0500]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8649,  7.0573],\n",
            "        [-8.0939,  7.0849],\n",
            "        [-7.8968,  6.9598],\n",
            "        [-7.8383,  7.0241]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9191,  6.8568],\n",
            "        [-7.7365,  6.8357],\n",
            "        [-7.8887,  7.0881],\n",
            "        [-7.8305,  7.0597]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0230,  7.1082],\n",
            "        [-7.6145,  6.9080],\n",
            "        [-7.8440,  6.9066],\n",
            "        [-8.0118,  7.0076]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9343,  7.0958],\n",
            "        [-7.8511,  6.9340],\n",
            "        [-7.9219,  7.1000],\n",
            "        [-7.8690,  6.8867]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9159,  7.0197],\n",
            "        [-7.8889,  7.0211],\n",
            "        [-7.9903,  7.1489],\n",
            "        [-7.9793,  7.0324]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0369,  6.8460],\n",
            "        [-7.8817,  7.0185],\n",
            "        [-7.7755,  7.0898],\n",
            "        [-7.7722,  6.9722]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9303,  7.0497],\n",
            "        [-8.0643,  7.1790],\n",
            "        [-7.8977,  6.9862],\n",
            "        [-7.9319,  7.0350]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6348,  6.9203],\n",
            "        [-7.2193,  6.4317],\n",
            "        [-7.7422,  6.7359],\n",
            "        [-7.7585,  6.7661]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 6.556508651556214e-07\n",
            "Outputs: tensor([[-7.9210,  7.0012],\n",
            "        [-7.9704,  7.0254],\n",
            "        [-7.7547,  7.0318],\n",
            "        [-7.9279,  6.9560]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9609,  7.0733],\n",
            "        [-7.7451,  6.8907],\n",
            "        [-7.7077,  6.7411],\n",
            "        [-7.6775,  6.8555]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8253,  6.7467],\n",
            "        [-7.7059,  6.9478],\n",
            "        [-7.4111,  6.9272],\n",
            "        [-7.8752,  6.7236]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.9462,  6.9655],\n",
            "        [-7.9644,  7.1335],\n",
            "        [-7.9038,  7.0531],\n",
            "        [-7.7804,  6.9145]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9801,  7.0311],\n",
            "        [-7.9364,  6.9809],\n",
            "        [-7.9483,  7.0639],\n",
            "        [-7.9227,  7.1661]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.6404,  6.7096],\n",
            "        [-7.6121,  6.7899],\n",
            "        [-7.6256,  6.7392],\n",
            "        [-8.0723,  7.1586]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-8.2321,  7.1098],\n",
            "        [-7.4382,  6.7222],\n",
            "        [-7.4860,  6.6217],\n",
            "        [-7.5875,  6.8314]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.9510,  6.9123],\n",
            "        [-7.8839,  6.9059],\n",
            "        [-7.7876,  6.9728],\n",
            "        [-7.7949,  7.0471]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8510,  6.8639],\n",
            "        [-7.7494,  6.8277],\n",
            "        [-7.9164,  6.9882],\n",
            "        [-7.6865,  6.9682]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.8429,  7.0223],\n",
            "        [-7.8670,  6.9234],\n",
            "        [-8.0776,  7.1602],\n",
            "        [-8.0789,  7.1922]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8230,  6.9820],\n",
            "        [-7.9588,  7.1586],\n",
            "        [-7.9341,  6.9921],\n",
            "        [-7.9298,  6.9840]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8692,  7.0545],\n",
            "        [-7.8992,  7.0535],\n",
            "        [-7.8923,  6.8617],\n",
            "        [-7.8768,  7.0072]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7953,  6.9870],\n",
            "        [-8.1189,  7.0198],\n",
            "        [-8.0371,  7.0829],\n",
            "        [-7.6092,  6.8761]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8834,  6.8309],\n",
            "        [-7.7504,  7.1345],\n",
            "        [-7.7982,  6.9118],\n",
            "        [-7.9439,  6.9674]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8161,  6.9784],\n",
            "        [-7.8643,  7.0022],\n",
            "        [-7.8018,  6.8513],\n",
            "        [-7.7314,  6.8898]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7328,  6.7778],\n",
            "        [-7.8971,  6.9445],\n",
            "        [-7.8826,  7.0359],\n",
            "        [-7.7287,  6.9333]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8890,  7.0053],\n",
            "        [-7.7842,  7.0342],\n",
            "        [-7.8420,  6.9626],\n",
            "        [-7.9083,  6.9521]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6481,  6.9393],\n",
            "        [-7.7098,  6.8640],\n",
            "        [-7.7361,  7.0678],\n",
            "        [-8.1074,  6.8103]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6832,  6.9142],\n",
            "        [-7.7797,  6.8836],\n",
            "        [-8.0310,  7.0088],\n",
            "        [-7.9344,  7.0798]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9731,  7.0354],\n",
            "        [-7.8736,  6.9703],\n",
            "        [-7.9324,  7.0515],\n",
            "        [-8.0555,  7.2015]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7720,  6.8758],\n",
            "        [-7.9678,  6.9986],\n",
            "        [-7.8698,  7.1812],\n",
            "        [-7.8679,  6.9129]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0182,  6.9551],\n",
            "        [-7.8858,  6.9587],\n",
            "        [-7.7370,  6.9498],\n",
            "        [-7.7589,  7.0011]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8316,  7.1211],\n",
            "        [-8.0143,  6.9700],\n",
            "        [-8.0380,  7.1516],\n",
            "        [-7.8673,  6.9481]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8403,  7.0124],\n",
            "        [-7.9263,  7.1129],\n",
            "        [-8.0128,  7.0006],\n",
            "        [-7.7791,  6.9030]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7423,  7.0375],\n",
            "        [-7.9181,  6.9937],\n",
            "        [-7.9516,  7.0726],\n",
            "        [-7.9951,  6.8830]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0396,  7.1458],\n",
            "        [-7.6560,  6.8906],\n",
            "        [-7.8102,  6.9579],\n",
            "        [-8.0455,  6.9976]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9120,  6.9720],\n",
            "        [-7.8241,  7.0026],\n",
            "        [-7.8776,  6.9483],\n",
            "        [-7.7816,  6.9113]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6841,  6.8551],\n",
            "        [-7.9064,  6.9506],\n",
            "        [-7.9827,  7.0507],\n",
            "        [-7.9211,  7.0494]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7800,  7.0525],\n",
            "        [-7.9998,  6.9952],\n",
            "        [-7.7879,  6.8103],\n",
            "        [-7.7919,  6.9472]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.7060,  6.8993],\n",
            "        [-7.7531,  6.8936],\n",
            "        [-7.8411,  6.8644],\n",
            "        [-7.7414,  6.8366]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8994,  7.1411],\n",
            "        [-8.0651,  7.0923],\n",
            "        [-7.7979,  6.8848],\n",
            "        [-7.9532,  7.0301]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7854,  6.9475],\n",
            "        [-7.7592,  6.8127],\n",
            "        [-7.7856,  6.9244],\n",
            "        [-7.8848,  6.9148]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.5795,  6.8421],\n",
            "        [-8.1652,  7.1328],\n",
            "        [-7.9893,  7.0044],\n",
            "        [-7.9001,  7.0810]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-8.0152,  7.0266],\n",
            "        [-7.9672,  7.1215],\n",
            "        [-7.8056,  6.9696],\n",
            "        [-7.9934,  7.1065]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.7934,  7.0188],\n",
            "        [-7.7719,  6.7507],\n",
            "        [-7.9603,  7.0884],\n",
            "        [-7.9565,  7.0367]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0157,  7.1476],\n",
            "        [-7.5530,  6.9794],\n",
            "        [-7.8641,  6.9357],\n",
            "        [-7.9081,  6.7251]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8933,  7.1138],\n",
            "        [-7.9316,  6.8384],\n",
            "        [-7.9147,  7.0192],\n",
            "        [-7.8817,  7.0946]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9113,  7.0606],\n",
            "        [-7.8878,  6.9640],\n",
            "        [-7.9557,  7.0715],\n",
            "        [-7.9264,  7.0173]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7288,  6.9616],\n",
            "        [-7.8439,  6.9554],\n",
            "        [-7.9025,  6.9404],\n",
            "        [-7.8471,  6.9904]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8914,  6.9872],\n",
            "        [-7.7729,  7.0637],\n",
            "        [-7.7000,  6.8216],\n",
            "        [-7.8510,  6.8140]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.6765,  7.0037],\n",
            "        [-7.8709,  6.9428],\n",
            "        [-7.9584,  6.7498],\n",
            "        [-7.6808,  6.9608]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8527,  6.9968],\n",
            "        [-7.6670,  6.8786],\n",
            "        [-7.9157,  6.9595],\n",
            "        [-7.7591,  6.7538]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-8.0165,  7.1885],\n",
            "        [-7.9038,  7.0402],\n",
            "        [-7.9168,  6.9752],\n",
            "        [-8.0340,  7.0861]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.5732,  6.9633],\n",
            "        [-7.8404,  6.8847],\n",
            "        [-8.0333,  6.8997],\n",
            "        [-7.9095,  7.0725]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8079,  6.9033],\n",
            "        [-8.0855,  7.2016],\n",
            "        [-8.0539,  7.1334],\n",
            "        [-7.9575,  7.1117]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9731,  6.9452],\n",
            "        [-7.9648,  6.9698],\n",
            "        [-7.8638,  7.1198],\n",
            "        [-7.7461,  6.9502]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8796,  6.9536],\n",
            "        [-7.8159,  6.9493],\n",
            "        [-7.7933,  6.9314],\n",
            "        [-8.0892,  7.2137]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9709,  7.0713],\n",
            "        [-7.9594,  6.7881],\n",
            "        [-7.7453,  7.0679],\n",
            "        [-7.8626,  7.0646]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8877,  7.1603],\n",
            "        [-7.8026,  6.8972],\n",
            "        [-7.8128,  6.8463],\n",
            "        [-7.8780,  6.9047]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7264,  6.8121],\n",
            "        [-8.0158,  6.9640],\n",
            "        [-8.0275,  7.1398],\n",
            "        [-7.7830,  7.0950]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7038,  6.8876],\n",
            "        [-7.6469,  6.7555],\n",
            "        [-7.6165,  6.9440],\n",
            "        [-8.2058,  7.1512]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8851,  7.0707],\n",
            "        [-7.9329,  6.9998],\n",
            "        [-7.8198,  6.9905],\n",
            "        [-7.9003,  6.9415]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8692,  6.9302],\n",
            "        [-7.8173,  6.8982],\n",
            "        [-7.8283,  7.0590],\n",
            "        [-7.9819,  7.0641]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8010,  6.8501],\n",
            "        [-7.9923,  7.0722],\n",
            "        [-7.9023,  7.0599],\n",
            "        [-7.8063,  7.0029]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8199,  6.9986],\n",
            "        [-7.9188,  6.8933],\n",
            "        [-7.7276,  7.0200],\n",
            "        [-7.8509,  6.8352]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0426,  7.0978],\n",
            "        [-7.9661,  7.0604],\n",
            "        [-7.9278,  7.1203],\n",
            "        [-8.0199,  7.1166]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Outputs: tensor([[-7.8376,  6.9503],\n",
            "        [-7.9903,  7.1118],\n",
            "        [-7.7803,  6.7113],\n",
            "        [-7.7138,  6.9747]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.2729,  7.0972],\n",
            "        [-7.8270,  6.9944],\n",
            "        [-7.5224,  6.8614],\n",
            "        [-7.7716,  6.9144]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.6604,  6.8625],\n",
            "        [-7.7563,  6.8747],\n",
            "        [-7.6906,  7.0032],\n",
            "        [-7.8762,  6.7719]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.470347505503014e-07\n",
            "Outputs: tensor([[-7.8781,  7.0366],\n",
            "        [-7.9807,  6.9790],\n",
            "        [-7.8133,  7.0382],\n",
            "        [-7.8481,  6.9169]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8823,  6.9740],\n",
            "        [-8.0541,  7.1598],\n",
            "        [-7.9090,  6.9516],\n",
            "        [-7.8205,  7.0275]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9349,  7.0484],\n",
            "        [-7.6667,  6.9887],\n",
            "        [-7.8448,  6.7497],\n",
            "        [-7.8868,  6.9860]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.7794,  6.8931],\n",
            "        [-7.9223,  7.1181],\n",
            "        [-7.8881,  7.0424],\n",
            "        [-8.0045,  7.0281]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8150,  6.8948],\n",
            "        [-7.8364,  6.9330],\n",
            "        [-7.7625,  7.0962],\n",
            "        [-7.9813,  6.9251]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9283,  7.0211],\n",
            "        [-7.8880,  7.1108],\n",
            "        [-7.9420,  7.0465],\n",
            "        [-7.7823,  6.8106]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8901,  6.8088],\n",
            "        [-7.7929,  6.9817],\n",
            "        [-7.7861,  6.9869],\n",
            "        [-7.5241,  6.5889]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.9750,  6.9645],\n",
            "        [-7.7861,  7.0647],\n",
            "        [-7.9145,  7.0807],\n",
            "        [-7.7615,  6.7995]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8263,  6.9645],\n",
            "        [-7.9521,  6.9875],\n",
            "        [-7.8911,  7.0022],\n",
            "        [-7.8601,  7.0477]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8156,  7.0078],\n",
            "        [-7.7985,  6.9388],\n",
            "        [-7.8823,  6.9612],\n",
            "        [-7.9564,  6.9756]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8872,  7.0276],\n",
            "        [-7.7627,  6.9333],\n",
            "        [-8.1175,  7.0430],\n",
            "        [-7.8095,  7.0116]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9346,  7.0649],\n",
            "        [-8.0096,  7.0708],\n",
            "        [-7.9491,  7.1267],\n",
            "        [-7.9806,  7.0578]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9146,  6.9886],\n",
            "        [-7.9023,  6.9111],\n",
            "        [-7.9872,  7.1500],\n",
            "        [-7.7930,  6.9724]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0493,  7.0290],\n",
            "        [-7.6748,  6.9777],\n",
            "        [-7.9247,  6.9876],\n",
            "        [-7.8353,  6.9628]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6299,  6.8951],\n",
            "        [-7.6731,  6.8531],\n",
            "        [-7.8443,  6.9408],\n",
            "        [-7.9421,  6.9070]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.9637,  7.0820],\n",
            "        [-7.8104,  6.9250],\n",
            "        [-7.9571,  7.1593],\n",
            "        [-8.0472,  7.0534]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9384,  7.0496],\n",
            "        [-7.9954,  7.1203],\n",
            "        [-7.9308,  6.9763],\n",
            "        [-7.8989,  7.0616]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0466,  7.1930],\n",
            "        [-7.7384,  6.8151],\n",
            "        [-7.7451,  6.9486],\n",
            "        [-7.8536,  6.8579]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0823,  6.7902],\n",
            "        [-7.6028,  6.9154],\n",
            "        [-7.7845,  6.9954],\n",
            "        [-7.6860,  6.8616]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-8.0314,  7.1205],\n",
            "        [-7.7996,  6.9427],\n",
            "        [-7.9148,  6.9505],\n",
            "        [-7.9212,  7.0786]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7904,  6.9960],\n",
            "        [-8.0742,  6.7832],\n",
            "        [-7.8097,  7.1036],\n",
            "        [-7.8701,  7.0673]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7998,  6.9612],\n",
            "        [-8.0458,  7.0919],\n",
            "        [-7.9906,  7.0989],\n",
            "        [-7.9442,  7.0873]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9211,  7.1019],\n",
            "        [-7.8193,  6.9489],\n",
            "        [-7.9764,  6.9637],\n",
            "        [-7.8070,  6.9377]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9296,  6.7380],\n",
            "        [-7.9288,  7.0961],\n",
            "        [-8.0122,  7.1188],\n",
            "        [-7.6762,  7.0241]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8783,  6.9404],\n",
            "        [-7.8814,  6.9685],\n",
            "        [-7.7743,  6.9315],\n",
            "        [-8.0374,  7.1817]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9500,  7.0381],\n",
            "        [-7.7714,  6.9132],\n",
            "        [-7.8041,  6.9192],\n",
            "        [-8.0013,  7.0990]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8427,  7.0195],\n",
            "        [-7.9859,  7.0884],\n",
            "        [-8.0529,  7.0744],\n",
            "        [-7.9287,  7.0743]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0321,  7.0256],\n",
            "        [-7.7435,  6.8978],\n",
            "        [-8.0466,  7.2139],\n",
            "        [-7.9563,  7.0827]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.8992,  6.9623],\n",
            "        [-7.7994,  7.0874],\n",
            "        [-8.0990,  7.0473],\n",
            "        [-7.8048,  6.9288]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8798,  6.9590],\n",
            "        [-8.0245,  7.0736],\n",
            "        [-7.7700,  6.9572],\n",
            "        [-7.7539,  6.8989]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9070,  6.9771],\n",
            "        [-7.9110,  6.9507],\n",
            "        [-7.9685,  6.9809],\n",
            "        [-7.8797,  7.2179]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9284,  7.0759],\n",
            "        [-8.0660,  7.0794],\n",
            "        [-7.8588,  6.9379],\n",
            "        [-7.7963,  6.9802]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8901,  6.9989],\n",
            "        [-7.9025,  7.0725],\n",
            "        [-7.8506,  7.0504],\n",
            "        [-7.9649,  6.9812]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9373,  6.7047],\n",
            "        [-7.7472,  7.0454],\n",
            "        [-8.0128,  7.1673],\n",
            "        [-7.8407,  7.0722]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9789,  7.0020],\n",
            "        [-7.9909,  7.0860],\n",
            "        [-7.9299,  7.0570],\n",
            "        [-7.9696,  7.1867]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8886,  6.9310],\n",
            "        [-7.8826,  6.9884],\n",
            "        [-7.8817,  7.1526],\n",
            "        [-8.0004,  7.0581]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9582,  6.8507],\n",
            "        [-7.8447,  7.1099],\n",
            "        [-7.9477,  7.0218],\n",
            "        [-7.7753,  6.9553]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9137,  6.9028],\n",
            "        [-8.0861,  7.1375],\n",
            "        [-7.6975,  6.8482],\n",
            "        [-7.7354,  7.0241]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9927,  7.0860],\n",
            "        [-7.9497,  7.0746],\n",
            "        [-7.9492,  7.0186],\n",
            "        [-7.8750,  7.0117]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9492,  7.1421],\n",
            "        [-7.9833,  7.0648],\n",
            "        [-7.9211,  6.9870],\n",
            "        [-8.0243,  7.1002]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8828,  7.0135],\n",
            "        [-7.9301,  7.1298],\n",
            "        [-8.0502,  7.1107],\n",
            "        [-8.0113,  7.0332]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9356,  7.0704],\n",
            "        [-7.8587,  6.8360],\n",
            "        [-7.9196,  7.0334],\n",
            "        [-7.8871,  7.1094]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9312,  7.1088],\n",
            "        [-7.7521,  6.9134],\n",
            "        [-7.6901,  6.9403],\n",
            "        [-8.1502,  7.0029]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0139,  6.8945],\n",
            "        [-7.8132,  6.9190],\n",
            "        [-7.9575,  7.1203],\n",
            "        [-7.8209,  7.0987]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8663,  7.0447],\n",
            "        [-8.0028,  7.0090],\n",
            "        [-7.8798,  7.0743],\n",
            "        [-8.0347,  7.1029]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0147,  7.0697],\n",
            "        [-8.0149,  7.1137],\n",
            "        [-7.8943,  7.0382],\n",
            "        [-7.9750,  7.1155]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8756,  6.9873],\n",
            "        [-7.7604,  6.9481],\n",
            "        [-7.8699,  6.8852],\n",
            "        [-7.7514,  6.8803]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8946,  7.0357],\n",
            "        [-7.7376,  6.9726],\n",
            "        [-7.9763,  6.8024],\n",
            "        [-7.8555,  7.0572]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8699,  6.9760],\n",
            "        [-7.9260,  6.8275],\n",
            "        [-7.7270,  7.0069],\n",
            "        [-7.8154,  7.0448]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8203,  6.8319],\n",
            "        [-8.0414,  7.0123],\n",
            "        [-7.9631,  7.1296],\n",
            "        [-7.6446,  6.9339]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8207,  6.8770],\n",
            "        [-8.0283,  7.1801],\n",
            "        [-7.9593,  7.0448],\n",
            "        [-7.8963,  7.0632]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9123,  7.1854],\n",
            "        [-8.1777,  7.1674],\n",
            "        [-7.9313,  7.0631],\n",
            "        [-7.9038,  6.9218]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8650,  6.9965],\n",
            "        [-7.7759,  7.0536],\n",
            "        [-7.9438,  6.9136],\n",
            "        [-7.7879,  6.8320]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9264,  6.9299],\n",
            "        [-8.0765,  7.1412],\n",
            "        [-7.9501,  7.1356],\n",
            "        [-7.9299,  7.1082]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9150,  7.1383],\n",
            "        [-7.8342,  6.8256],\n",
            "        [-7.8195,  6.9475],\n",
            "        [-7.9459,  7.1065]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8609,  6.9531],\n",
            "        [-7.7934,  7.0657],\n",
            "        [-7.7718,  6.6998],\n",
            "        [-7.8472,  7.0109]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9618,  7.0323],\n",
            "        [-7.9009,  7.0282],\n",
            "        [-7.8462,  7.0361],\n",
            "        [-8.0771,  7.1326]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9588,  6.9895],\n",
            "        [-8.0607,  7.1386],\n",
            "        [-8.0936,  7.1727],\n",
            "        [-7.7972,  7.0487]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.7286,  6.7014],\n",
            "        [-7.5898,  6.8225],\n",
            "        [-7.6230,  6.8873],\n",
            "        [-8.0764,  7.0580]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9179,  6.9270],\n",
            "        [-7.6963,  6.8745],\n",
            "        [-7.7905,  7.0154],\n",
            "        [-7.5342,  6.6301]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.8492,  6.9709],\n",
            "        [-7.9396,  7.1256],\n",
            "        [-7.6633,  6.9468],\n",
            "        [-8.1294,  7.0194]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.5946,  6.9432],\n",
            "        [-7.8503,  6.7927],\n",
            "        [-7.9413,  6.9562],\n",
            "        [-7.9370,  7.0715]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8475,  6.9653],\n",
            "        [-7.8100,  6.8446],\n",
            "        [-7.9516,  7.0439],\n",
            "        [-7.8458,  7.0339]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8329,  7.0326],\n",
            "        [-7.6655,  7.0152],\n",
            "        [-7.7527,  6.7953],\n",
            "        [-8.0835,  6.9186]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9458,  7.1298],\n",
            "        [-7.6936,  6.8970],\n",
            "        [-7.8516,  7.0003],\n",
            "        [-8.0259,  6.9618]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0222,  6.9394],\n",
            "        [-7.7298,  6.9142],\n",
            "        [-7.8195,  6.9493],\n",
            "        [-7.8973,  7.1381]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8456,  6.7826],\n",
            "        [-7.8834,  6.9905],\n",
            "        [-7.9831,  7.1910],\n",
            "        [-7.8939,  7.0848]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8637,  6.8849],\n",
            "        [-7.9282,  6.9303],\n",
            "        [-7.9107,  7.1757],\n",
            "        [-7.8619,  6.9931]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9277,  6.9045],\n",
            "        [-7.7833,  7.1375],\n",
            "        [-7.8141,  6.9320],\n",
            "        [-8.0358,  7.0951]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9235,  7.0745],\n",
            "        [-7.8708,  6.8921],\n",
            "        [-7.8313,  7.0561],\n",
            "        [-8.1060,  7.1946]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.2226,  7.1973],\n",
            "        [-7.6412,  6.7269],\n",
            "        [-7.7257,  6.7467],\n",
            "        [-7.2687,  6.5864]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.662439548359544e-07\n",
            "Outputs: tensor([[-7.9096,  6.8762],\n",
            "        [-7.8968,  7.0291],\n",
            "        [-7.8705,  6.9906],\n",
            "        [-7.7867,  7.0341]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0218,  7.1048],\n",
            "        [-7.8028,  7.1802],\n",
            "        [-7.9702,  6.9755],\n",
            "        [-7.9613,  6.9600]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7588,  6.8226],\n",
            "        [-7.7841,  6.9335],\n",
            "        [-7.9972,  7.0989],\n",
            "        [-7.7710,  6.9040]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9307,  6.8911],\n",
            "        [-7.9207,  7.0099],\n",
            "        [-7.9128,  7.0340],\n",
            "        [-7.8013,  7.0398]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0744,  7.1154],\n",
            "        [-8.0275,  7.1679],\n",
            "        [-7.9069,  7.0460],\n",
            "        [-8.0090,  7.1176]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.7364,  6.8682],\n",
            "        [-7.7809,  6.9726],\n",
            "        [-7.8013,  6.9863],\n",
            "        [-7.9178,  6.8532]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8740,  7.0593],\n",
            "        [-8.0412,  7.0953],\n",
            "        [-7.9972,  7.1429],\n",
            "        [-7.9982,  7.0591]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.8580,  6.9249],\n",
            "        [-7.9800,  7.0613],\n",
            "        [-7.8150,  7.0732],\n",
            "        [-7.8374,  6.9333]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9794,  7.0929],\n",
            "        [-7.7722,  7.0111],\n",
            "        [-8.0100,  7.1151],\n",
            "        [-8.0491,  7.0776]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9304,  7.1787],\n",
            "        [-7.9131,  6.9153],\n",
            "        [-7.9768,  7.0225],\n",
            "        [-7.9055,  7.0311]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8796,  6.8752],\n",
            "        [-7.7882,  6.7993],\n",
            "        [-8.0360,  7.1591],\n",
            "        [-7.7478,  7.0985]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9768,  6.9521],\n",
            "        [-7.8557,  7.0424],\n",
            "        [-7.8243,  7.0599],\n",
            "        [-8.0227,  7.0693]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8895,  6.9588],\n",
            "        [-7.9999,  7.0459],\n",
            "        [-7.8857,  6.9210],\n",
            "        [-8.0269,  7.3135]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8053,  6.7990],\n",
            "        [-7.7353,  7.0105],\n",
            "        [-7.9935,  7.1555],\n",
            "        [-7.9773,  7.0189]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9689,  7.1026],\n",
            "        [-7.8292,  6.9710],\n",
            "        [-8.0740,  7.0377],\n",
            "        [-7.7549,  6.9074]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8203,  7.0856],\n",
            "        [-7.9854,  6.8950],\n",
            "        [-7.7476,  6.8951],\n",
            "        [-7.9512,  7.0594]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9396,  7.0341],\n",
            "        [-7.9877,  7.2097],\n",
            "        [-7.9088,  7.0282],\n",
            "        [-7.9302,  6.9547]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0714,  7.0815],\n",
            "        [-7.7720,  6.9195],\n",
            "        [-7.8813,  6.9192],\n",
            "        [-7.9160,  7.1604]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.8884,  7.0149],\n",
            "        [-7.9348,  6.9771],\n",
            "        [-7.7039,  6.8351],\n",
            "        [-7.8181,  7.0003]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8794,  6.9857],\n",
            "        [-8.0034,  6.9365],\n",
            "        [-7.7068,  7.0732],\n",
            "        [-7.9048,  6.9450]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9569,  7.0431],\n",
            "        [-7.9147,  6.9882],\n",
            "        [-7.9204,  7.1484],\n",
            "        [-7.9149,  6.9389]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0962,  7.1140],\n",
            "        [-7.8471,  7.0626],\n",
            "        [-8.0386,  7.0404],\n",
            "        [-7.7739,  6.9860]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.7589,  6.7897],\n",
            "        [-8.0282,  7.0347],\n",
            "        [-7.8579,  7.1188],\n",
            "        [-8.0594,  7.2382]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0103,  7.0679],\n",
            "        [-7.9458,  7.0235],\n",
            "        [-7.9017,  7.0579],\n",
            "        [-7.8997,  7.0231]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0060,  7.0432],\n",
            "        [-8.0454,  7.0978],\n",
            "        [-8.0602,  7.1467],\n",
            "        [-7.7803,  7.0488]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9944,  6.9984],\n",
            "        [-7.8406,  6.9659],\n",
            "        [-7.8656,  7.0308],\n",
            "        [-7.9248,  7.1291]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9541,  6.9782],\n",
            "        [-8.0227,  7.1303],\n",
            "        [-7.9575,  7.1330],\n",
            "        [-7.9410,  7.0469]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8802,  7.1040],\n",
            "        [-8.1327,  7.1308],\n",
            "        [-7.9292,  7.1380],\n",
            "        [-7.9644,  7.0003]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8789,  6.9813],\n",
            "        [-7.9034,  7.0859],\n",
            "        [-8.0124,  7.1172],\n",
            "        [-8.0009,  7.0899]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0783,  7.1571],\n",
            "        [-8.0857,  7.1354],\n",
            "        [-7.9584,  7.1587],\n",
            "        [-7.8902,  6.9818]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8999,  6.9694],\n",
            "        [-8.0762,  7.1816],\n",
            "        [-8.0265,  7.1928],\n",
            "        [-7.9604,  7.0778]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.8667,  6.8922],\n",
            "        [-7.8065,  6.9843],\n",
            "        [-7.8405,  6.8754],\n",
            "        [-7.8078,  6.9586]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8613,  7.0111],\n",
            "        [-7.8794,  7.0108],\n",
            "        [-7.9580,  7.0546],\n",
            "        [-8.0863,  7.1742]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9865,  6.9898],\n",
            "        [-7.8660,  6.9554],\n",
            "        [-7.9253,  7.1372],\n",
            "        [-7.9084,  7.0172]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9319,  6.9859],\n",
            "        [-8.0414,  7.0663],\n",
            "        [-7.9822,  7.1438],\n",
            "        [-7.9228,  7.0910]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.7871,  6.9506],\n",
            "        [-7.8953,  6.9073],\n",
            "        [-8.1992,  7.3196],\n",
            "        [-7.9090,  7.0292]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7325,  6.9994],\n",
            "        [-7.7312,  6.8142],\n",
            "        [-8.0105,  6.7583],\n",
            "        [-7.6884,  6.9989]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-8.1246,  7.1093],\n",
            "        [-7.7418,  6.6633],\n",
            "        [-7.7417,  7.0112],\n",
            "        [-7.6347,  6.9675]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.8756,  7.1100],\n",
            "        [-7.9614,  6.9188],\n",
            "        [-7.9381,  7.0489],\n",
            "        [-7.8927,  7.0153]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8112,  6.9350],\n",
            "        [-7.8220,  6.9861],\n",
            "        [-7.7712,  6.8782],\n",
            "        [-7.8807,  6.9189]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0415,  7.1902],\n",
            "        [-7.7757,  6.8982],\n",
            "        [-7.8678,  7.1536],\n",
            "        [-7.7750,  6.7109]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8348,  7.0173],\n",
            "        [-7.9019,  7.0827],\n",
            "        [-7.9123,  6.9142],\n",
            "        [-7.9562,  7.0547]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9045,  6.9045],\n",
            "        [-8.1159,  7.0581],\n",
            "        [-7.7896,  6.9704],\n",
            "        [-7.5909,  6.9041]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8115,  6.9763],\n",
            "        [-8.0800,  7.1469],\n",
            "        [-7.8633,  7.0309],\n",
            "        [-7.9300,  6.9771]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0236,  7.1031],\n",
            "        [-7.9307,  7.0851],\n",
            "        [-7.8535,  6.9523],\n",
            "        [-7.9568,  7.0907]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.8024,  6.9216],\n",
            "        [-8.0265,  7.1235],\n",
            "        [-7.9360,  6.9965],\n",
            "        [-7.7819,  6.9513]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7340,  6.9356],\n",
            "        [-7.8122,  6.8644],\n",
            "        [-7.8865,  6.9750],\n",
            "        [-7.8260,  6.9545]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324281626061e-07\n",
            "Outputs: tensor([[-7.7325,  6.9094],\n",
            "        [-7.6669,  6.6749],\n",
            "        [-7.7589,  7.0412],\n",
            "        [-7.7784,  6.7654]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.9076,  6.9153],\n",
            "        [-7.8531,  7.0161],\n",
            "        [-7.7686,  7.0259],\n",
            "        [-8.0359,  7.0221]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9309,  7.0859],\n",
            "        [-8.0036,  7.0433],\n",
            "        [-8.0151,  7.0067],\n",
            "        [-7.7159,  7.0217]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9181,  6.9767],\n",
            "        [-7.9813,  7.0803],\n",
            "        [-7.5683,  6.6355],\n",
            "        [-7.7100,  6.9450]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.7838,  6.9626],\n",
            "        [-7.6271,  6.5136],\n",
            "        [-7.8409,  7.0460],\n",
            "        [-7.9971,  7.2044]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.9358,  7.0151],\n",
            "        [-7.9752,  7.0186],\n",
            "        [-7.9968,  7.1078],\n",
            "        [-7.8618,  7.0390]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9349,  6.9756],\n",
            "        [-8.1202,  7.1967],\n",
            "        [-8.0619,  7.0877],\n",
            "        [-7.7272,  7.0272]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8640,  7.1137],\n",
            "        [-7.9164,  6.9674],\n",
            "        [-7.9000,  7.1216],\n",
            "        [-7.9102,  6.8745]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9058,  7.0694],\n",
            "        [-8.0053,  7.1012],\n",
            "        [-7.9572,  7.1381],\n",
            "        [-8.1129,  7.1142]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.6056,  6.8304],\n",
            "        [-8.1327,  7.2960],\n",
            "        [-7.8415,  6.7864],\n",
            "        [-7.9024,  7.0224]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.1723239974089665e-07\n",
            "Outputs: tensor([[-7.9978,  6.8473],\n",
            "        [-7.7128,  7.0471],\n",
            "        [-7.8099,  7.1400],\n",
            "        [-8.0219,  6.9463]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9602,  6.9727],\n",
            "        [-7.7909,  6.9521],\n",
            "        [-7.8385,  7.1145],\n",
            "        [-7.8668,  6.9307]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0132,  7.0192],\n",
            "        [-7.9974,  7.1067],\n",
            "        [-7.9518,  7.0867],\n",
            "        [-7.9262,  7.0976]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8923,  7.0942],\n",
            "        [-7.8744,  6.9823],\n",
            "        [-7.9457,  7.1631],\n",
            "        [-8.0761,  7.0153]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9344,  7.0429],\n",
            "        [-8.0428,  6.9859],\n",
            "        [-8.0395,  7.1214],\n",
            "        [-7.9707,  7.2320]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-8.1063,  7.0271],\n",
            "        [-7.9512,  7.0801],\n",
            "        [-7.7826,  6.9839],\n",
            "        [-7.8470,  7.0612]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9885,  7.0531],\n",
            "        [-7.7213,  6.9949],\n",
            "        [-7.8590,  6.8227],\n",
            "        [-7.7125,  6.8446]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8892,  6.9919],\n",
            "        [-7.8271,  6.9349],\n",
            "        [-8.1932,  7.2973],\n",
            "        [-8.0725,  7.1762]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9302,  7.1854],\n",
            "        [-7.8781,  6.9693],\n",
            "        [-7.9165,  6.9465],\n",
            "        [-7.8984,  7.0019]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8961,  7.0006],\n",
            "        [-8.0202,  7.1909],\n",
            "        [-8.0584,  7.0423],\n",
            "        [-7.9314,  7.1113]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9443,  6.9678],\n",
            "        [-7.8420,  7.1833],\n",
            "        [-7.9381,  7.0317],\n",
            "        [-7.7459,  6.7878]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8339,  7.0158],\n",
            "        [-8.0413,  6.9235],\n",
            "        [-7.9080,  7.0235],\n",
            "        [-7.6758,  6.9318]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0317,  7.1254],\n",
            "        [-7.8915,  6.9574],\n",
            "        [-7.9159,  7.0909],\n",
            "        [-8.0681,  7.1951]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-8.0063,  7.0933],\n",
            "        [-7.9904,  7.0571],\n",
            "        [-8.1009,  7.1466],\n",
            "        [-7.9135,  7.1825]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Outputs: tensor([[-7.8218,  6.9528],\n",
            "        [-7.5764,  6.7616],\n",
            "        [-7.8042,  6.8754],\n",
            "        [-8.0517,  7.1958]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-7.6479,  6.8871],\n",
            "        [-7.8486,  7.0175],\n",
            "        [-7.5817,  6.7000],\n",
            "        [-7.8562,  6.8089]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.768370445162873e-07\n",
            "Outputs: tensor([[-7.6355,  6.8169],\n",
            "        [-7.9253,  7.1136],\n",
            "        [-7.7292,  6.9709],\n",
            "        [-7.9572,  6.8583]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0197,  7.1166],\n",
            "        [-7.7383,  6.8627],\n",
            "        [-7.9400,  7.0074],\n",
            "        [-7.9254,  7.0631]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8395,  7.0013],\n",
            "        [-7.9214,  7.0296],\n",
            "        [-7.9899,  7.0683],\n",
            "        [-7.9837,  7.1375]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9170,  7.0264],\n",
            "        [-7.9083,  7.1645],\n",
            "        [-8.0916,  7.1403],\n",
            "        [-7.6345,  6.6879]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0767,  7.0146],\n",
            "        [-7.8866,  7.0592],\n",
            "        [-7.8514,  7.0824],\n",
            "        [-7.9351,  7.0064]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.7247,  6.8629],\n",
            "        [-8.0274,  7.2186],\n",
            "        [-7.9223,  6.9699],\n",
            "        [-7.6929,  6.8167]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9159,  7.0443],\n",
            "        [-7.8958,  7.1071],\n",
            "        [-7.9719,  6.9601],\n",
            "        [-7.8629,  6.9846]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.1082,  7.1970],\n",
            "        [-7.9788,  7.0987],\n",
            "        [-7.9017,  6.9903],\n",
            "        [-7.9640,  7.1276]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8668,  7.0465],\n",
            "        [-7.7307,  6.7594],\n",
            "        [-7.7204,  6.9968],\n",
            "        [-7.8500,  6.9069]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.0056,  7.0132],\n",
            "        [-7.8163,  7.0090],\n",
            "        [-7.8459,  6.9415],\n",
            "        [-7.9250,  7.0654]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9185,  7.0209],\n",
            "        [-8.1842,  7.3105],\n",
            "        [-7.9236,  7.1371],\n",
            "        [-7.8360,  6.8745]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8739,  6.9960],\n",
            "        [-7.8771,  7.0164],\n",
            "        [-7.9676,  7.0363],\n",
            "        [-8.0121,  7.1723]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9094,  7.1030],\n",
            "        [-7.9884,  7.0657],\n",
            "        [-7.6950,  6.8688],\n",
            "        [-8.1262,  7.1251]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9902,  7.1281],\n",
            "        [-7.9527,  7.0539],\n",
            "        [-7.7011,  6.8563],\n",
            "        [-7.8396,  6.8954]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0744,  7.0857],\n",
            "        [-7.8038,  7.1260],\n",
            "        [-7.9867,  6.9805],\n",
            "        [-8.0088,  7.1719]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.9946,  7.0697],\n",
            "        [-8.2068,  7.1452],\n",
            "        [-7.8268,  6.9962],\n",
            "        [-7.8845,  7.1421]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9047,  7.0505],\n",
            "        [-7.8396,  7.0435],\n",
            "        [-8.1564,  7.1672],\n",
            "        [-7.9685,  7.0208]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8714,  6.7975],\n",
            "        [-8.0480,  7.0677],\n",
            "        [-7.7622,  7.0637],\n",
            "        [-7.7617,  6.9254]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.9318,  7.0951],\n",
            "        [-8.1032,  7.0501],\n",
            "        [-7.8603,  6.8395],\n",
            "        [-7.8008,  7.1412]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0788,  7.0906],\n",
            "        [-7.9709,  7.0785],\n",
            "        [-7.9683,  7.1459],\n",
            "        [-7.7737,  6.9398]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.1745,  7.0915],\n",
            "        [-7.9270,  7.1114],\n",
            "        [-7.9072,  7.0717],\n",
            "        [-8.0081,  7.2014]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.0736,  7.1949],\n",
            "        [-7.8375,  6.9637],\n",
            "        [-8.0907,  7.1559],\n",
            "        [-8.0198,  7.1419]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.7015,  7.0124],\n",
            "        [-7.9075,  7.1222],\n",
            "        [-8.1121,  7.0243],\n",
            "        [-8.0011,  6.9657]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8621,  7.0573],\n",
            "        [-8.0818,  7.0902],\n",
            "        [-8.0353,  7.1077],\n",
            "        [-7.9466,  7.1002]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-8.0353,  7.1020],\n",
            "        [-8.0135,  7.0383],\n",
            "        [-7.8929,  7.0675],\n",
            "        [-7.8285,  7.0139]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.7843,  7.0568],\n",
            "        [-7.6166,  6.8314],\n",
            "        [-7.9144,  7.0452],\n",
            "        [-8.0063,  6.8701]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9103,  7.2057],\n",
            "        [-7.9621,  7.1140],\n",
            "        [-7.9697,  6.8699],\n",
            "        [-7.9438,  7.0439]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8480,  7.0778],\n",
            "        [-7.7577,  6.9400],\n",
            "        [-7.9285,  6.9580],\n",
            "        [-7.9319,  6.9355]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8527,  6.9897],\n",
            "        [-7.8492,  6.9236],\n",
            "        [-7.8703,  6.9596],\n",
            "        [-7.8946,  7.0319]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.1818,  7.0218],\n",
            "        [-7.7647,  6.9610],\n",
            "        [-7.5208,  6.8018],\n",
            "        [-8.1066,  7.2328]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0877,  7.1021],\n",
            "        [-7.9092,  7.2364],\n",
            "        [-7.9037,  7.0197],\n",
            "        [-8.0175,  6.9834]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0841,  7.0901],\n",
            "        [-8.0073,  7.0956],\n",
            "        [-7.9410,  7.0563],\n",
            "        [-7.8987,  7.1104]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9161,  7.0888],\n",
            "        [-7.8710,  7.0314],\n",
            "        [-7.8272,  7.0968],\n",
            "        [-7.9964,  6.8557]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6128,  6.7998],\n",
            "        [-8.0775,  7.1437],\n",
            "        [-7.9696,  6.9953],\n",
            "        [-7.9381,  7.1295]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8484,  7.0582],\n",
            "        [-7.9841,  7.1187],\n",
            "        [-7.8906,  7.0202],\n",
            "        [-8.1437,  7.0998]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0094,  7.1306],\n",
            "        [-8.0278,  7.1665],\n",
            "        [-7.9566,  7.1638],\n",
            "        [-7.9936,  6.9705]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9359,  7.0542],\n",
            "        [-8.0648,  7.1989],\n",
            "        [-7.9420,  7.1500],\n",
            "        [-8.1231,  7.0977]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9796,  7.1674],\n",
            "        [-8.0948,  7.0418],\n",
            "        [-7.9077,  7.0338],\n",
            "        [-7.9252,  7.1232]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9045,  6.9804],\n",
            "        [-8.1457,  7.2152],\n",
            "        [-7.8261,  6.9617],\n",
            "        [-8.0275,  7.2110]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.1231,  7.1919],\n",
            "        [-7.8063,  6.9489],\n",
            "        [-8.0061,  7.1386],\n",
            "        [-7.9248,  7.0816]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9422,  6.9831],\n",
            "        [-7.8313,  6.9795],\n",
            "        [-7.8281,  6.9733],\n",
            "        [-7.9707,  7.1160]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9154,  7.1721],\n",
            "        [-7.9724,  7.0574],\n",
            "        [-8.0757,  7.0745],\n",
            "        [-7.9420,  7.0660]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.0630,  7.1137],\n",
            "        [-8.0065,  7.0699],\n",
            "        [-7.8735,  7.1029],\n",
            "        [-8.1131,  7.2186]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9373,  6.9794],\n",
            "        [-7.6094,  6.7052],\n",
            "        [-7.7876,  7.0214],\n",
            "        [-7.9646,  7.1233]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.8487,  7.0148],\n",
            "        [-7.9573,  7.0783],\n",
            "        [-8.0660,  7.1186],\n",
            "        [-7.9404,  7.0813]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0896,  7.0745],\n",
            "        [-7.8978,  7.1594],\n",
            "        [-7.8496,  7.0205],\n",
            "        [-7.8236,  6.8956]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8490,  6.9799],\n",
            "        [-7.7537,  6.8338],\n",
            "        [-8.1072,  7.1032],\n",
            "        [-7.6674,  6.9682]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9350,  6.9390],\n",
            "        [-7.9111,  7.0181],\n",
            "        [-7.8024,  6.9142],\n",
            "        [-7.8984,  7.1091]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.8481,  7.0151],\n",
            "        [-7.9565,  7.0279],\n",
            "        [-7.8773,  7.0930],\n",
            "        [-7.9844,  6.9976]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9296,  7.1158],\n",
            "        [-7.8576,  6.9617],\n",
            "        [-8.1689,  7.2479],\n",
            "        [-7.9424,  7.0156]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9099,  7.0210],\n",
            "        [-8.0226,  7.0960],\n",
            "        [-7.9242,  7.1900],\n",
            "        [-8.0171,  7.0223]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.8488,  7.0727],\n",
            "        [-7.9027,  7.0852],\n",
            "        [-7.6893,  6.7341],\n",
            "        [-7.8806,  6.8561]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.172324565843155e-07\n",
            "Outputs: tensor([[-8.0514,  7.0864],\n",
            "        [-7.9600,  7.0909],\n",
            "        [-7.9455,  7.1074],\n",
            "        [-7.8580,  7.0146]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.0269,  7.2607],\n",
            "        [-7.9212,  7.0785],\n",
            "        [-8.0090,  7.0624],\n",
            "        [-7.9925,  7.0184]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0787,  7.2513],\n",
            "        [-7.9485,  7.0087],\n",
            "        [-7.9612,  7.0158],\n",
            "        [-7.9518,  7.0848]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.9910,  7.1219],\n",
            "        [-7.8338,  7.0136],\n",
            "        [-8.0232,  7.1032],\n",
            "        [-8.0827,  7.0999]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9767,  7.0369],\n",
            "        [-7.9703,  7.0675],\n",
            "        [-7.9275,  7.0083],\n",
            "        [-7.9775,  7.1615]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0246,  7.0870],\n",
            "        [-7.5273,  6.8647],\n",
            "        [-8.0597,  7.1099],\n",
            "        [-7.9470,  7.0237]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0737,  7.0355],\n",
            "        [-8.0594,  7.1353],\n",
            "        [-7.7115,  7.0739],\n",
            "        [-7.8213,  6.9095]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.1701,  7.1541],\n",
            "        [-7.7149,  7.0841],\n",
            "        [-7.9272,  6.9760],\n",
            "        [-8.0253,  7.1115]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-7.9220,  7.1655],\n",
            "        [-7.9018,  6.8892],\n",
            "        [-7.8789,  6.9745],\n",
            "        [-8.0670,  7.1594]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-8.1037,  7.2158],\n",
            "        [-7.9256,  7.1364],\n",
            "        [-8.0217,  7.0586],\n",
            "        [-7.9792,  7.0669]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Outputs: tensor([[-8.0681,  7.1445],\n",
            "        [-8.0273,  7.0999],\n",
            "        [-7.9312,  7.0467],\n",
            "        [-7.9810,  7.1737]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.0108,  7.0144],\n",
            "        [-7.8585,  6.9366],\n",
            "        [-7.6070,  6.8547],\n",
            "        [-7.9861,  7.1227]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9718,  7.0734],\n",
            "        [-8.0584,  7.2569],\n",
            "        [-8.0144,  7.1501],\n",
            "        [-8.1110,  7.1103]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Outputs: tensor([[-8.1582,  7.1751],\n",
            "        [-7.9862,  7.1334],\n",
            "        [-7.9047,  7.0737],\n",
            "        [-7.9847,  7.1100]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8525,  6.9513],\n",
            "        [-7.9077,  6.8562],\n",
            "        [-7.8221,  7.0741],\n",
            "        [-7.7692,  6.9090]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9528,  7.1172],\n",
            "        [-7.8272,  7.0688],\n",
            "        [-7.9194,  6.8507],\n",
            "        [-8.0511,  7.2137]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.980231954552437e-07\n",
            "Outputs: tensor([[-8.1802,  7.1818],\n",
            "        [-8.0359,  7.0947],\n",
            "        [-7.9049,  7.1751],\n",
            "        [-7.9260,  7.0184]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.0257,  7.1558],\n",
            "        [-7.9507,  7.0495],\n",
            "        [-7.9772,  7.1141],\n",
            "        [-7.9355,  7.0324]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.7260,  6.9846],\n",
            "        [-7.9365,  6.9885],\n",
            "        [-7.8704,  7.1052],\n",
            "        [-8.0457,  6.9452]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.9334,  6.9831],\n",
            "        [-7.9799,  7.1964],\n",
            "        [-8.1335,  7.1390],\n",
            "        [-8.0948,  7.2829]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9464,  7.1799],\n",
            "        [-8.1455,  7.1537],\n",
            "        [-7.9826,  7.0848],\n",
            "        [-7.9646,  7.0633]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Outputs: tensor([[-8.0894,  7.1836],\n",
            "        [-7.8666,  7.0273],\n",
            "        [-7.9836,  7.1045],\n",
            "        [-8.0731,  7.1273]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-8.1478,  7.1023],\n",
            "        [-7.7731,  6.8837],\n",
            "        [-7.9034,  7.1553],\n",
            "        [-7.9288,  7.0731]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8676,  6.8465],\n",
            "        [-7.9059,  7.2162],\n",
            "        [-8.1310,  7.1446],\n",
            "        [-7.7883,  6.9776]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9973,  6.9923],\n",
            "        [-8.0277,  7.1806],\n",
            "        [-7.8770,  7.1764],\n",
            "        [-7.9652,  6.9996]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0274,  7.1729],\n",
            "        [-7.8716,  6.9676],\n",
            "        [-8.0588,  7.2233],\n",
            "        [-7.9813,  6.9997]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.6893,  6.9511],\n",
            "        [-7.7184,  6.8596],\n",
            "        [-7.9580,  6.9662],\n",
            "        [-8.2289,  7.2616]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.7351,  6.9486],\n",
            "        [-7.9538,  7.0542],\n",
            "        [-7.9020,  7.0423],\n",
            "        [-7.9960,  6.9827]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8004,  7.0318],\n",
            "        [-7.9903,  7.0092],\n",
            "        [-7.9454,  6.9999],\n",
            "        [-8.1317,  7.2297]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.9535,  7.0688],\n",
            "        [-7.7495,  6.9115],\n",
            "        [-7.8591,  7.0122],\n",
            "        [-7.9964,  7.0277]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9676,  7.1540],\n",
            "        [-7.8482,  7.0094],\n",
            "        [-7.5726,  6.6103],\n",
            "        [-8.0697,  7.1895]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-7.9005,  6.9416],\n",
            "        [-7.9468,  7.2000],\n",
            "        [-8.0473,  7.0749],\n",
            "        [-7.9980,  7.1296]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.6822084464583895e-07\n",
            "Outputs: tensor([[-7.9644,  6.8623],\n",
            "        [-7.8917,  7.0950],\n",
            "        [-8.0160,  7.2207],\n",
            "        [-8.0610,  7.1766]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0248,  7.1748],\n",
            "        [-7.9170,  7.0311],\n",
            "        [-7.8892,  6.9301],\n",
            "        [-7.7703,  6.8740]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0867,  7.1696],\n",
            "        [-7.7718,  7.0179],\n",
            "        [-8.0336,  7.1026],\n",
            "        [-7.9263,  7.0143]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8994,  7.0783],\n",
            "        [-7.9363,  7.0769],\n",
            "        [-7.9924,  7.0838],\n",
            "        [-8.0207,  7.0742]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0844,  7.1856],\n",
            "        [-7.9902,  7.1698],\n",
            "        [-8.0111,  7.0559],\n",
            "        [-7.8706,  7.0020]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9520,  7.0178],\n",
            "        [-7.9992,  7.0647],\n",
            "        [-7.7640,  6.9487],\n",
            "        [-7.9447,  7.0809]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0061,  7.1444],\n",
            "        [-7.9717,  7.1359],\n",
            "        [-8.0526,  7.1495],\n",
            "        [-8.1280,  7.1403]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Outputs: tensor([[-8.1118,  7.1683],\n",
            "        [-7.8199,  7.0909],\n",
            "        [-8.0607,  7.0388],\n",
            "        [-7.9697,  7.1078]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.7076,  6.6092],\n",
            "        [-8.0399,  7.2570],\n",
            "        [-7.9631,  7.1060],\n",
            "        [-7.8274,  7.0365]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.6380,  6.6719],\n",
            "        [-7.3156,  6.8198],\n",
            "        [-8.1490,  6.8808],\n",
            "        [-7.4551,  6.8308]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.36441632448259e-07\n",
            "Outputs: tensor([[-8.0199,  6.9515],\n",
            "        [-7.5524,  6.6313],\n",
            "        [-7.5994,  6.9223],\n",
            "        [-8.0952,  7.2138]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 4.4703472212859197e-07\n",
            "Outputs: tensor([[-7.9927,  7.1204],\n",
            "        [-7.7810,  6.9147],\n",
            "        [-8.0184,  7.0576],\n",
            "        [-8.0473,  7.1892]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9253,  7.1156],\n",
            "        [-7.9272,  7.0725],\n",
            "        [-7.9239,  7.0294],\n",
            "        [-7.8060,  6.8189]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.1775,  7.0253],\n",
            "        [-7.8592,  7.0571],\n",
            "        [-7.7276,  7.0232],\n",
            "        [-7.7606,  6.9397]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8346,  7.1510],\n",
            "        [-7.9045,  7.0278],\n",
            "        [-7.8547,  7.0915],\n",
            "        [-7.9982,  6.7990]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.1146,  7.1796],\n",
            "        [-7.9539,  7.0637],\n",
            "        [-8.0110,  7.1675],\n",
            "        [-8.1060,  7.2111]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.7067,  6.8609],\n",
            "        [-8.0160,  6.9049],\n",
            "        [-7.7667,  7.0292],\n",
            "        [-7.8182,  6.9763]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.8743010577491077e-07\n",
            "Outputs: tensor([[-7.8682,  7.0779],\n",
            "        [-7.9566,  7.1609],\n",
            "        [-8.0899,  7.1760],\n",
            "        [-7.9413,  6.8866]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9520,  7.1237],\n",
            "        [-7.9307,  7.1187],\n",
            "        [-8.0440,  7.0453],\n",
            "        [-7.8260,  6.8827]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8476,  7.0370],\n",
            "        [-7.9452,  7.0710],\n",
            "        [-7.9665,  7.0751],\n",
            "        [-8.0062,  7.0107]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-7.8126,  6.9639],\n",
            "        [-8.3089,  7.1888],\n",
            "        [-7.8419,  7.0017],\n",
            "        [-7.6873,  6.9806]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.7913,  7.0615],\n",
            "        [-8.1027,  6.9467],\n",
            "        [-7.9046,  7.0087],\n",
            "        [-7.9937,  7.1859]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.7147,  6.6419],\n",
            "        [-7.8564,  7.0544],\n",
            "        [-7.9629,  7.1095],\n",
            "        [-7.9225,  7.1135]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-8.0006,  7.1683],\n",
            "        [-8.2008,  7.2637],\n",
            "        [-7.8666,  7.0150],\n",
            "        [-7.9440,  7.0303]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.1333,  7.1811],\n",
            "        [-8.0671,  7.0840],\n",
            "        [-7.9367,  7.0651],\n",
            "        [-7.8620,  7.0833]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0109,  7.1681],\n",
            "        [-7.9227,  6.9433],\n",
            "        [-8.0756,  7.2402],\n",
            "        [-7.8322,  6.9759]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8672,  6.8900],\n",
            "        [-7.9204,  6.8815],\n",
            "        [-7.8402,  7.0086],\n",
            "        [-7.6597,  6.9939]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.874301341966202e-07\n",
            "Outputs: tensor([[-8.1486,  7.0507],\n",
            "        [-7.9798,  7.1133],\n",
            "        [-8.0228,  7.1380],\n",
            "        [-7.7563,  7.0373]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.9485,  7.0468],\n",
            "        [-7.9334,  7.1889],\n",
            "        [-7.9885,  7.0042],\n",
            "        [-8.0219,  7.0908]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-8.0174,  7.0992],\n",
            "        [-7.9882,  7.2232],\n",
            "        [-7.9825,  6.9543],\n",
            "        [-8.0172,  7.1893]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.682208730675484e-07\n",
            "Outputs: tensor([[-7.8087,  7.2082],\n",
            "        [-7.9750,  6.9867],\n",
            "        [-8.1714,  7.2281],\n",
            "        [-7.8615,  6.8974]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.278254894212296e-07\n",
            "Outputs: tensor([[-8.0464,  7.1576],\n",
            "        [-8.1002,  6.9879],\n",
            "        [-7.9196,  7.0857],\n",
            "        [-7.8331,  7.0759]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.9496,  7.0762],\n",
            "        [-7.8978,  7.0927],\n",
            "        [-8.0874,  7.1878],\n",
            "        [-8.0246,  7.0460]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 2.9802316703353426e-07\n",
            "Outputs: tensor([[-7.8979,  6.9557],\n",
            "        [-7.8662,  7.0859],\n",
            "        [-7.7797,  7.0643],\n",
            "        [-7.9681,  6.8296]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 3.576278118089249e-07\n",
            "Outputs: tensor([[-7.3055,  6.8359],\n",
            "        [-7.9470,  6.8635],\n",
            "        [-8.0512,  7.2258],\n",
            "        [-7.6205,  6.4981]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1, 1, 1])\n",
            "Loss: 5.066393669039826e-07\n",
            "Outputs: tensor([[-7.9846,  7.1044],\n",
            "        [-8.1502,  7.2311]], grad_fn=<AddmmBackward0>)\n",
            "Labels: tensor([1, 1])\n",
            "Loss: 2.3841855067985307e-07\n",
            "Epoch 5/5, Loss: 0.0000\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# To store predictions and labels\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Disable gradient calculation for inference\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Get the predicted class (for classification tasks)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Store predictions and labels\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Example: Print first 10 predictions and corresponding labels\n",
        "for i in range(10):\n",
        "    print(f\"Prediction: {all_predictions[i]}, Actual Label: {all_labels[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma3P2_4VW-Ti",
        "outputId": "f5c02e5c-3f91-4210-f070-86e137149836"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n",
            "Prediction: 1, Actual Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state dictionary\n",
        "save_path = \"model.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n"
      ],
      "metadata": {
        "id": "TsJAJOTNI79Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the saved model file\n",
        "files.download(\"model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aWz5P7KVJrIC",
        "outputId": "331ed59e-faf6-4062-b39e-11e42e79e732"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_524591ff-db47-4fb0-a33c-505bbfdb438b\", \"model.pth\", 44780546)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnx-tf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNDCM7KnLSBI",
        "outputId": "13d8da8f-2fb0-4db4-b7d6-d886e8bb7902"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx-tf)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->onnx-tf) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx-tf)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, onnx, tensorflow-addons, onnx-tf\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.3.1 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.16.2 onnx-tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx\n",
        "\n",
        "# Dummy input for the model (adjust the size to match your model's input)\n",
        "dummy_input = torch.randn(1, 3, 224, 224)  # Example for a model expecting 3x224x224 images\n",
        "\n",
        "# Convert to ONNX\n",
        "torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
      ],
      "metadata": {
        "id": "J2TPgQzRLBRs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the ONNX model file\n",
        "files.download(\"model.onnx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8Emcv-SVLt-R",
        "outputId": "635920e4-17ff-4db4-a5d1-6eb60c568ff2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fbb81927-1162-4909-bd67-66caf1b7edde\", \"model.onnx\", 44700645)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a random image to make preditions\n",
        "uploaded2 = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fWGrBLLKgN-1",
        "outputId": "936996d1-b747-44db-e9d8-c1e9c56c683b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-17cb8320-6ca6-4769-8bfa-e7629265e63c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-17cb8320-6ca6-4769-8bfa-e7629265e63c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving face_43.jpg to face_43.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "random_path = \"/content/face_43.jpg\"\n",
        "random_image = Image.open(random_path)\n",
        "random_img = transform(random_image)\n",
        "random_img = random_img.unsqueeze(0)\n",
        "\n",
        "#making predictions\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(random_img)\n",
        "\n",
        "_, predicted = torch.max(output,1)\n",
        "print(f\"Prediction: {predicted.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqLFquZ3hEKb",
        "outputId": "d4c4c285-f21d-479a-f2d9-9200cd401623"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}